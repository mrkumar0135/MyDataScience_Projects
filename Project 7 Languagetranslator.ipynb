{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "CODES = {'<PAD>': 0, '<EOS>': 1, '<UNK>': 2, '<GO>': 3 }\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load Dataset from File\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def preprocess_and_save_data(source_path, target_path, text_to_ids):\n",
    "    \"\"\"\n",
    "    Preprocess Text Data.  Save to to file.\n",
    "    \"\"\"\n",
    "    # Preprocess\n",
    "    source_text = load_data(source_path)\n",
    "    target_text = load_data(target_path)\n",
    "\n",
    "    source_text = source_text.lower()\n",
    "    target_text = target_text.lower()\n",
    "\n",
    "    source_vocab_to_int, source_int_to_vocab = create_lookup_tables(source_text)\n",
    "    target_vocab_to_int, target_int_to_vocab = create_lookup_tables(target_text)\n",
    "\n",
    "    source_text, target_text = text_to_ids(source_text, target_text, source_vocab_to_int, target_vocab_to_int)\n",
    "\n",
    "    # Save Data\n",
    "    pickle.dump((\n",
    "        (source_text, target_text),\n",
    "        (source_vocab_to_int, target_vocab_to_int),\n",
    "        (source_int_to_vocab, target_int_to_vocab)), open('preprocess.p', 'wb'))\n",
    "\n",
    "\n",
    "def load_preprocess():\n",
    "    \"\"\"\n",
    "    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n",
    "    \"\"\"\n",
    "    return pickle.load(open('preprocess.p', mode='rb'))\n",
    "\n",
    "\n",
    "def create_lookup_tables(text):\n",
    "    \"\"\"\n",
    "    Create lookup tables for vocabulary\n",
    "    \"\"\"\n",
    "    vocab = set(text.split())\n",
    "    vocab_to_int = copy.copy(CODES)\n",
    "\n",
    "    for v_i, v in enumerate(vocab, len(CODES)):\n",
    "        vocab_to_int[v] = v_i\n",
    "\n",
    "    int_to_vocab = {v_i: v for v, v_i in vocab_to_int.items()}\n",
    "\n",
    "    return vocab_to_int, int_to_vocab\n",
    "\n",
    "\n",
    "def save_params(params):\n",
    "    \"\"\"\n",
    "    Save parameters to file\n",
    "    \"\"\"\n",
    "    pickle.dump(params, open('params.p', 'wb'))\n",
    "\n",
    "\n",
    "def load_params():\n",
    "    \"\"\"\n",
    "    Load parameters from file\n",
    "    \"\"\"\n",
    "    return pickle.load(open('params.p', mode='rb'))\n",
    "\n",
    "\n",
    "def batch_data(source, target, batch_size):\n",
    "    \"\"\"\n",
    "    Batch source and target together\n",
    "    \"\"\"\n",
    "    for batch_i in range(0, len(source)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "        source_batch = source[start_i:start_i + batch_size]\n",
    "        target_batch = target[start_i:start_i + batch_size]\n",
    "        yield np.array(pad_sentence_batch(source_batch)), np.array(pad_sentence_batch(target_batch))\n",
    "\n",
    "\n",
    "def pad_sentence_batch(sentence_batch):\n",
    "    \"\"\"\n",
    "    Pad sentence with <PAD> id\n",
    "    \"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    print(max_sentence)\n",
    "    return [sentence + [CODES['<PAD>']] * (max_sentence - len(sentence))\n",
    "            for sentence in sentence_batch]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "import problem_unittests as tests\n",
    "\n",
    "source_path = 'data/small_vocab_en'\n",
    "target_path = 'data/small_vocab_fr'\n",
    "source_text = load_data(source_path)\n",
    "target_text = load_data(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 227\n",
      "Number of sentences: 137861\n",
      "Average number of words in a sentence: 13.225277634719028\n",
      "\n",
      "English sentences 0 to 10:\n",
      "new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "the united states is usually chilly during july , and it is usually freezing in november .\n",
      "california is usually quiet during march , and it is usually hot in june .\n",
      "the united states is sometimes mild during june , and it is cold in september .\n",
      "your least liked fruit is the grape , but my least liked is the apple .\n",
      "his favorite fruit is the orange , but my favorite is the grape .\n",
      "paris is relaxing during december , but it is usually chilly in july .\n",
      "new jersey is busy during spring , and it is never hot in march .\n",
      "our least liked fruit is the lemon , but my least liked is the grape .\n",
      "the united states is sometimes busy during january , and it is sometimes warm in november .\n",
      "\n",
      "French sentences 0 to 10:\n",
      "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
      "california est généralement calme en mars , et il est généralement chaud en juin .\n",
      "les états-unis est parfois légère en juin , et il fait froid en septembre .\n",
      "votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .\n",
      "son fruit préféré est l'orange , mais mon préféré est le raisin .\n",
      "paris est relaxant en décembre , mais il est généralement froid en juillet .\n",
      "new jersey est occupé au printemps , et il est jamais chaude en mars .\n",
      "notre fruit est moins aimé le citron , mais mon moins aimé est le raisin .\n",
      "les états-unis est parfois occupé en janvier , et il est parfois chaud en novembre .\n"
     ]
    }
   ],
   "source": [
    "view_sentence_range = (0, 10)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in source_text.split()})))\n",
    "\n",
    "\n",
    "sentences = source_text.split('\\n')\n",
    "word_counts = [len(sentence.split()) for sentence in sentences]\n",
    "print('Number of sentences: {}'.format(len(sentences)))\n",
    "print('Average number of words in a sentence: {}'.format(np.average(word_counts)))\n",
    "\n",
    "print()\n",
    "print('English sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(source_text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))\n",
    "print()\n",
    "print('French sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(target_text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_to_ids(source_text, target_text, source_vocab_to_int, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    Convert source and target text to proper word ids\n",
    "    :param source_text: String that contains all the source text.\n",
    "    :param target_text: String that contains all the target text.\n",
    "    :param source_vocab_to_int: Dictionary to go from the source words to an id\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :return: A tuple of lists (source_id_text, target_id_text)\n",
    "    \"\"\"\n",
    "    # Just go through the text and transform it.\n",
    "    source_id_text = []\n",
    "    for idx, line in enumerate(source_text.split('\\n')):\n",
    "        source_id_text.append([])\n",
    "        for word in line.split():\n",
    "            source_id_text[idx].append(source_vocab_to_int[word])\n",
    "        \n",
    "    target_id_text = []\n",
    "    for idx, line in enumerate(target_text.split('\\n')):\n",
    "        target_id_text.append([])\n",
    "        for word in line.split():\n",
    "            target_id_text[idx].append(target_vocab_to_int[word])\n",
    "        target_id_text[idx].append(target_vocab_to_int['<EOS>'])\n",
    "\n",
    "    return (source_id_text, target_id_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "preprocess_and_save_data(source_path, target_path, text_to_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), _ = load_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_inputs():\n",
    "    \"\"\"\n",
    "    Create TF Placeholders for input, targets, learning rate, and lengths of source and target sequences.\n",
    "    :return: Tuple (input, targets, learning rate, keep probability, target sequence length,\n",
    "    max target sequence length, source sequence length)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    inputs = tf.placeholder(tf.int32, shape=[None,None], name= \"input\")\n",
    "    targets = tf.placeholder(tf.int32, shape=[None,None], name= \"targets\")\n",
    "    lrate = tf.placeholder(tf.float32, name= \"learning_rate\")\n",
    "    keep_prob = tf.placeholder(tf.float32, name= \"keep_prob\")\n",
    "    target_seq_lenth = tf.placeholder(tf.int32, shape=[None], name= \"target_sequence_length\")\n",
    "    max_target_len = tf.reduce_max(target_seq_lenth, name= 'max_target_len')\n",
    "    source_seq_length = tf.placeholder(tf.int32, shape=[None], name= \"source_sequence_length\")\n",
    "    return (inputs, targets, lrate, keep_prob, target_seq_lenth, max_target_len, source_seq_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_decoder_input(target_data, target_vocab_to_int, batch_size):\n",
    "    \"\"\"\n",
    "    Preprocess target data for encoding\n",
    "    :param target_data: Target Placehoder\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :param batch_size: Batch Size\n",
    "    :return: Preprocessed target data\n",
    "    \"\"\"\n",
    "    # Create a constant tensor with the 'go id'.\n",
    "    go_id = tf.constant(target_vocab_to_int['<GO>'], shape=(batch_size,1), dtype=tf.int32)\n",
    "    # Concatenate the vector without the last word id with the go ids vector\n",
    "    processed_input = tf.concat([go_id,target_data[:,:-1]],1)\n",
    "    return processed_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding\n",
    "Implement `encoding_layer()` to create a Encoder RNN layer using [`tf.nn.dynamic_rnn()`](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imp import reload\n",
    "reload(tests)\n",
    "\n",
    "def encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob, \n",
    "                   source_sequence_length, source_vocab_size, \n",
    "                   encoding_embedding_size):\n",
    "    \"\"\"\n",
    "    Create encoding layer\n",
    "    :param rnn_inputs: Inputs for the RNN\n",
    "    :param rnn_size: RNN Size\n",
    "    :param num_layers: Number of layers\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :param source_sequence_length: a list of the lengths of each sequence in the batch\n",
    "    :param source_vocab_size: vocabulary size of source data\n",
    "    :param encoding_embedding_size: embedding size of source data\n",
    "    :return: tuple (RNN output, RNN state)\n",
    "    \"\"\"\n",
    "    # Build the lstm cells wrapped in dropout\n",
    "    def build_cell(rnn_size, keep_prob):\n",
    "        lstm = tf.contrib.rnn.LSTMCell(rnn_size)\n",
    "        lstm_drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        return lstm_drop\n",
    "    # Stack them all\n",
    "    stacked_lstm = tf.contrib.rnn.MultiRNNCell([build_cell(rnn_size, keep_prob) for _ in range(num_layers)])\n",
    "    # Creathe embedding layer.\n",
    "    embed_encoder = tf.contrib.layers.embed_sequence(rnn_inputs, vocab_size = source_vocab_size, embed_dim = encoding_embedding_size)\n",
    "    # If we don't have an initial zero state, provide a dtype.\n",
    "    output, state = tf.nn.dynamic_rnn(stacked_lstm, embed_encoder, source_sequence_length, dtype=tf.float32)\n",
    "    return (output, state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding - Training\n",
    "Create training logits using [`tf.contrib.seq2seq.simple_decoder_fn_train()`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_train) and [`tf.contrib.seq2seq.dynamic_rnn_decoder()`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder).  Apply the `output_fn` to the [`tf.contrib.seq2seq.dynamic_rnn_decoder()`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder) outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoding_layer_train(encoder_state, dec_cell, dec_embed_input, \n",
    "                         target_sequence_length, max_summary_length, \n",
    "                         output_layer, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a decoding layer for training\n",
    "    :param encoder_state: Encoder State\n",
    "    :param dec_cell: Decoder RNN Cell\n",
    "    :param dec_embed_input: Decoder embedded input\n",
    "    :param target_sequence_length: The lengths of each sequence in the target batch\n",
    "    :param max_summary_length: The length of the longest sequence in the batch\n",
    "    :param output_layer: Function to apply the output layer\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :return: BasicDecoderOutput containing training logits and sample_id\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    trainig_helper = tf.contrib.seq2seq.TrainingHelper(dec_embed_input, target_sequence_length)\n",
    "    basic_decoder = tf.contrib.seq2seq.BasicDecoder(dec_cell, trainig_helper, encoder_state, output_layer)\n",
    "    f_output, _, _ = tf.contrib.seq2seq.dynamic_decode(basic_decoder,maximum_iterations=max_summary_length)\n",
    "    return f_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding - Inference\n",
    "Create inference logits using [`tf.contrib.seq2seq.simple_decoder_fn_inference()`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_inference) and [`tf.contrib.seq2seq.dynamic_rnn_decoder()`](https://www.tensorflow.org/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id,\n",
    "                         end_of_sequence_id, max_target_sequence_length,\n",
    "                         vocab_size, output_layer, batch_size, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a decoding layer for inference\n",
    "    :param encoder_state: Encoder state\n",
    "    :param dec_cell: Decoder RNN Cell\n",
    "    :param dec_embeddings: Decoder embeddings\n",
    "    :param start_of_sequence_id: GO ID\n",
    "    :param end_of_sequence_id: EOS Id\n",
    "    :param max_target_sequence_length: Maximum length of target sequences\n",
    "    :param vocab_size: Size of decoder/target vocabulary\n",
    "    :param decoding_scope: TenorFlow Variable Scope for decoding\n",
    "    :param output_layer: Function to apply the output layer\n",
    "    :param batch_size: Batch size\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :return: BasicDecoderOutput containing inference logits and sample_id\n",
    "    \"\"\"\n",
    "    # Convert the start_ids to be a vector with batch size (the go id repeated batch size times)\n",
    "    start_ids = tf.tile([start_of_sequence_id], [batch_size])\n",
    "    # Create the embedding helper.\n",
    "    embedding_helper = tf.contrib.seq2seq.GreedyEmbeddingHelper(\n",
    "        dec_embeddings, start_ids, end_of_sequence_id)\n",
    "    basic_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "        dec_cell, embedding_helper, encoder_state, output_layer)\n",
    "    f_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "        basic_decoder,maximum_iterations=max_target_sequence_length)\n",
    "    return f_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Decoding Layer\n",
    "Implement `decoding_layer()` to create a Decoder RNN layer.\n",
    "\n",
    "- Create RNN cell for decoding using `rnn_size` and `num_layers`.\n",
    "- Create the output fuction using [`lambda`](https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions) to transform it's input, logits, to class logits.\n",
    "- Use the your `decoding_layer_train(encoder_state, dec_cell, dec_embed_input, sequence_length, decoding_scope, output_fn, keep_prob)` function to get the training logits.\n",
    "- Use your `decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, maximum_length, vocab_size, decoding_scope, output_fn, keep_prob)` function to get the inference logits.\n",
    "\n",
    "Note: You'll need to use [tf.variable_scope](https://www.tensorflow.org/api_docs/python/tf/variable_scope) to share variables between training and inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decoding_layer(dec_input, encoder_state,\n",
    "                   target_sequence_length, max_target_sequence_length,\n",
    "                   rnn_size,\n",
    "                   num_layers, target_vocab_to_int, target_vocab_size,\n",
    "                   batch_size, keep_prob, decoding_embedding_size):\n",
    "    \"\"\"\n",
    "    Create decoding layer\n",
    "    :param dec_input: Decoder input\n",
    "    :param encoder_state: Encoder state\n",
    "    :param target_sequence_length: The lengths of each sequence in the target batch\n",
    "    :param max_target_sequence_length: Maximum length of target sequences\n",
    "    :param rnn_size: RNN Size\n",
    "    :param num_layers: Number of layers\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :param target_vocab_size: Size of target vocabulary\n",
    "    :param batch_size: The size of the batch\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :param decoding_embedding_size: Decoding embedding size\n",
    "    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "    \"\"\"\n",
    "    # Use the same proess as in the encoding layer.\n",
    "    def build_cell(rnn_size, keep_prob):\n",
    "        lstm = tf.contrib.rnn.LSTMCell(rnn_size)\n",
    "        lstm_drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
    "        return lstm_drop\n",
    "    # Stack them all\n",
    "    stacked_lstm = tf.contrib.rnn.MultiRNNCell([build_cell(rnn_size, keep_prob) for _ in range(num_layers)])\n",
    "    \n",
    "    dec_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, decoding_embedding_size]))\n",
    "    dec_embed_input = tf.nn.embedding_lookup(dec_embeddings, dec_input)\n",
    "\n",
    "    dense_layer = Dense(target_vocab_size,\n",
    "                         kernel_initializer = tf.truncated_normal_initializer(mean = 0.0, stddev=0.1))\n",
    "    \n",
    "    with tf.variable_scope(\"decode\") as scope:\n",
    "        tr_decoder_output = decoding_layer_train(\n",
    "            encoder_state, stacked_lstm, dec_embed_input, \n",
    "            target_sequence_length, max_target_sequence_length, \n",
    "            dense_layer, keep_prob)\n",
    "        scope.reuse_variables()\n",
    "        inf_decoder_output = decoding_layer_infer(\n",
    "            encoder_state, stacked_lstm, dec_embeddings, \n",
    "            target_vocab_to_int['<GO>'], target_vocab_to_int['<EOS>'], \n",
    "            max_target_sequence_length, target_vocab_size, \n",
    "            dense_layer, batch_size, keep_prob)\n",
    "    \n",
    "    return tr_decoder_output, inf_decoder_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Neural Network\n",
    "Apply the functions you implemented above to:\n",
    "\n",
    "- Apply embedding to the input data for the encoder.\n",
    "- Encode the input using your `encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob)`.\n",
    "- Process target data using your `process_decoding_input(target_data, target_vocab_to_int, batch_size)` function.\n",
    "- Apply embedding to the target data for the decoder.\n",
    "- Decode the encoded input using your `decoding_layer(dec_embed_input, dec_embeddings, encoder_state, vocab_size, sequence_length, rnn_size, num_layers, target_vocab_to_int, keep_prob)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def seq2seq_model(input_data, target_data, keep_prob, batch_size,\n",
    "                  source_sequence_length, target_sequence_length,\n",
    "                  max_target_sentence_length,\n",
    "                  source_vocab_size, target_vocab_size,\n",
    "                  enc_embedding_size, dec_embedding_size,\n",
    "                  rnn_size, num_layers, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    Build the Sequence-to-Sequence part of the neural network\n",
    "    :param input_data: Input placeholder\n",
    "    :param target_data: Target placeholder\n",
    "    :param keep_prob: Dropout keep probability placeholder\n",
    "    :param batch_size: Batch Size\n",
    "    :param source_sequence_length: Sequence Lengths of source sequences in the batch\n",
    "    :param target_sequence_length: Sequence Lengths of target sequences in the batch\n",
    "    :param source_vocab_size: Source vocabulary size\n",
    "    :param target_vocab_size: Target vocabulary size\n",
    "    :param enc_embedding_size: Decoder embedding size\n",
    "    :param dec_embedding_size: Encoder embedding size\n",
    "    :param rnn_size: RNN Size\n",
    "    :param num_layers: Number of layers\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :return: Tuple of (Training BasicDecoderOutput, Inference BasicDecoderOutput)\n",
    "    \"\"\"\n",
    "    output, state = encoding_layer(input_data, rnn_size, num_layers, keep_prob, \n",
    "                   source_sequence_length, source_vocab_size, \n",
    "                   enc_embedding_size)\n",
    "    \n",
    "    processed_input = process_decoder_input(target_data, target_vocab_to_int, batch_size)\n",
    "    \n",
    "    tr_decoder_output, inf_decoder_output = decoding_layer(processed_input, state,\n",
    "                   target_sequence_length, max_target_sentence_length,\n",
    "                   rnn_size, num_layers, target_vocab_to_int, target_vocab_size,\n",
    "                   batch_size, keep_prob, dec_embedding_size)\n",
    "    \n",
    "    return tr_decoder_output, inf_decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Training\n",
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "\n",
    "- Set `epochs` to the number of epochs.\n",
    "- Set `batch_size` to the batch size.\n",
    "- Set `rnn_size` to the size of the RNNs.\n",
    "- Set `num_layers` to the number of layers.\n",
    "- Set `encoding_embedding_size` to the size of the embedding for the encoder.\n",
    "- Set `decoding_embedding_size` to the size of the embedding for the decoder.\n",
    "- Set `learning_rate` to the learning rate.\n",
    "- Set `keep_probability` to the Dropout keep probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "epochs = 10\n",
    "# Batch Size\n",
    "batch_size = 512\n",
    "# RNN Size\n",
    "rnn_size = 128\n",
    "# Number of Layers\n",
    "num_layers = 2\n",
    "# Embedding Size\n",
    "encoding_embedding_size = 128\n",
    "decoding_embedding_size = 128\n",
    "# Learning Rate\n",
    "learning_rate = 0.001\n",
    "# Dropout Keep Probability\n",
    "keep_probability = 0.55\n",
    "display_step = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Graph\n",
    "Build the graph using the neural network you implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_path = 'checkpoints/dev'\n",
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), _ = load_preprocess()\n",
    "max_target_sentence_length = max([len(sentence) for sentence in source_int_text])\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    input_data, targets, lr, keep_prob, target_sequence_length, max_target_sequence_length, source_sequence_length = model_inputs()\n",
    "\n",
    "    #sequence_length = tf.placeholder_with_default(max_target_sentence_length, None, name='sequence_length')\n",
    "    input_shape = tf.shape(input_data)\n",
    "\n",
    "    train_logits, inference_logits = seq2seq_model(tf.reverse(input_data, [-1]),\n",
    "                                                   targets,\n",
    "                                                   keep_prob,\n",
    "                                                   batch_size,\n",
    "                                                   source_sequence_length,\n",
    "                                                   target_sequence_length,\n",
    "                                                   max_target_sequence_length,\n",
    "                                                   len(source_vocab_to_int),\n",
    "                                                   len(target_vocab_to_int),\n",
    "                                                   encoding_embedding_size,\n",
    "                                                   decoding_embedding_size,\n",
    "                                                   rnn_size,\n",
    "                                                   num_layers,\n",
    "                                                   target_vocab_to_int)\n",
    "\n",
    "\n",
    "    training_logits = tf.identity(train_logits.rnn_output, name='logits')\n",
    "    inference_logits = tf.identity(inference_logits.sample_id, name='predictions')\n",
    "\n",
    "    masks = tf.sequence_mask(target_sequence_length, max_target_sequence_length, dtype=tf.float32, name='masks')\n",
    "\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        # Loss function\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            training_logits,\n",
    "            targets,\n",
    "            masks)\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    \"\"\"Pad sentences with <PAD> so that each sentence of a batch has the same length\"\"\"\n",
    "    max_sentence = max([len(sentence) for sentence in sentence_batch])\n",
    "    return [sentence + [pad_int] * (max_sentence - len(sentence)) for sentence in sentence_batch]\n",
    "\n",
    "\n",
    "def get_batches(sources, targets, batch_size, source_pad_int, target_pad_int):\n",
    "    \"\"\"Batch targets, sources, and the lengths of their sentences together\"\"\"\n",
    "    for batch_i in range(0, len(sources)//batch_size):\n",
    "        start_i = batch_i * batch_size\n",
    "\n",
    "        # Slice the right amount for the batch\n",
    "        sources_batch = sources[start_i:start_i + batch_size]\n",
    "        targets_batch = targets[start_i:start_i + batch_size]\n",
    "\n",
    "        # Pad\n",
    "        pad_sources_batch = np.array(pad_sentence_batch(sources_batch, source_pad_int))\n",
    "        pad_targets_batch = np.array(pad_sentence_batch(targets_batch, target_pad_int))\n",
    "\n",
    "        # Need the lengths for the _lengths parameters\n",
    "        pad_targets_lengths = []\n",
    "        for target in pad_targets_batch:\n",
    "            pad_targets_lengths.append(len(target))\n",
    "\n",
    "        pad_source_lengths = []\n",
    "        for source in pad_sources_batch:\n",
    "            pad_source_lengths.append(len(source))\n",
    "\n",
    "        yield pad_sources_batch, pad_targets_batch, pad_source_lengths, pad_targets_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train\n",
    "Train the neural network on the preprocessed data. If you have a hard time getting a good loss, check the forms to see if anyone is having the same problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch    1/269 - Train Accuracy: 0.2329, Validation Accuracy: 0.3096, Loss: 5.6859\n",
      "Epoch   0 Batch    2/269 - Train Accuracy: 0.2655, Validation Accuracy: 0.3096, Loss: 5.4589\n",
      "Epoch   0 Batch    3/269 - Train Accuracy: 0.2444, Validation Accuracy: 0.3096, Loss: 5.3048\n",
      "Epoch   0 Batch    4/269 - Train Accuracy: 0.2317, Validation Accuracy: 0.3096, Loss: 5.1488\n",
      "Epoch   0 Batch    5/269 - Train Accuracy: 0.2325, Validation Accuracy: 0.3097, Loss: 4.9733\n",
      "Epoch   0 Batch    6/269 - Train Accuracy: 0.2867, Validation Accuracy: 0.3184, Loss: 4.6426\n",
      "Epoch   0 Batch    7/269 - Train Accuracy: 0.2877, Validation Accuracy: 0.3220, Loss: 4.5144\n",
      "Epoch   0 Batch    8/269 - Train Accuracy: 0.2558, Validation Accuracy: 0.3237, Loss: 4.5537\n",
      "Epoch   0 Batch    9/269 - Train Accuracy: 0.2984, Validation Accuracy: 0.3399, Loss: 4.3468\n",
      "Epoch   0 Batch   10/269 - Train Accuracy: 0.2680, Validation Accuracy: 0.3411, Loss: 4.3995\n",
      "Epoch   0 Batch   11/269 - Train Accuracy: 0.3065, Validation Accuracy: 0.3421, Loss: 4.1221\n",
      "Epoch   0 Batch   12/269 - Train Accuracy: 0.2805, Validation Accuracy: 0.3427, Loss: 4.1631\n",
      "Epoch   0 Batch   13/269 - Train Accuracy: 0.3440, Validation Accuracy: 0.3426, Loss: 3.7831\n",
      "Epoch   0 Batch   14/269 - Train Accuracy: 0.3053, Validation Accuracy: 0.3426, Loss: 3.8955\n",
      "Epoch   0 Batch   15/269 - Train Accuracy: 0.2960, Validation Accuracy: 0.3426, Loss: 3.8388\n",
      "Epoch   0 Batch   16/269 - Train Accuracy: 0.3116, Validation Accuracy: 0.3426, Loss: 3.7143\n",
      "Epoch   0 Batch   17/269 - Train Accuracy: 0.3148, Validation Accuracy: 0.3547, Loss: 3.7000\n",
      "Epoch   0 Batch   18/269 - Train Accuracy: 0.3002, Validation Accuracy: 0.3687, Loss: 3.7987\n",
      "Epoch   0 Batch   19/269 - Train Accuracy: 0.3703, Validation Accuracy: 0.3702, Loss: 3.4398\n",
      "Epoch   0 Batch   20/269 - Train Accuracy: 0.3099, Validation Accuracy: 0.3737, Loss: 3.6802\n",
      "Epoch   0 Batch   21/269 - Train Accuracy: 0.3110, Validation Accuracy: 0.3728, Loss: 3.6629\n",
      "Epoch   0 Batch   22/269 - Train Accuracy: 0.3436, Validation Accuracy: 0.3706, Loss: 3.4454\n",
      "Epoch   0 Batch   23/269 - Train Accuracy: 0.3553, Validation Accuracy: 0.3771, Loss: 3.4004\n",
      "Epoch   0 Batch   24/269 - Train Accuracy: 0.3210, Validation Accuracy: 0.3851, Loss: 3.5393\n",
      "Epoch   0 Batch   25/269 - Train Accuracy: 0.3230, Validation Accuracy: 0.3847, Loss: 3.5000\n",
      "Epoch   0 Batch   26/269 - Train Accuracy: 0.3828, Validation Accuracy: 0.3814, Loss: 3.1793\n",
      "Epoch   0 Batch   27/269 - Train Accuracy: 0.3628, Validation Accuracy: 0.3945, Loss: 3.2895\n",
      "Epoch   0 Batch   28/269 - Train Accuracy: 0.3270, Validation Accuracy: 0.4003, Loss: 3.4415\n",
      "Epoch   0 Batch   29/269 - Train Accuracy: 0.3335, Validation Accuracy: 0.3993, Loss: 3.3768\n",
      "Epoch   0 Batch   30/269 - Train Accuracy: 0.3666, Validation Accuracy: 0.4004, Loss: 3.2052\n",
      "Epoch   0 Batch   31/269 - Train Accuracy: 0.3757, Validation Accuracy: 0.3998, Loss: 3.1625\n",
      "Epoch   0 Batch   32/269 - Train Accuracy: 0.3643, Validation Accuracy: 0.3987, Loss: 3.1692\n",
      "Epoch   0 Batch   33/269 - Train Accuracy: 0.3766, Validation Accuracy: 0.4035, Loss: 3.0915\n",
      "Epoch   0 Batch   34/269 - Train Accuracy: 0.3797, Validation Accuracy: 0.4080, Loss: 3.0974\n",
      "Epoch   0 Batch   35/269 - Train Accuracy: 0.3791, Validation Accuracy: 0.4061, Loss: 3.0674\n",
      "Epoch   0 Batch   36/269 - Train Accuracy: 0.3762, Validation Accuracy: 0.4088, Loss: 3.0677\n",
      "Epoch   0 Batch   37/269 - Train Accuracy: 0.3863, Validation Accuracy: 0.4118, Loss: 3.0426\n",
      "Epoch   0 Batch   38/269 - Train Accuracy: 0.3804, Validation Accuracy: 0.4102, Loss: 3.0376\n",
      "Epoch   0 Batch   39/269 - Train Accuracy: 0.3769, Validation Accuracy: 0.4081, Loss: 3.0166\n",
      "Epoch   0 Batch   40/269 - Train Accuracy: 0.3562, Validation Accuracy: 0.4156, Loss: 3.1337\n",
      "Epoch   0 Batch   41/269 - Train Accuracy: 0.3905, Validation Accuracy: 0.4204, Loss: 2.9860\n",
      "Epoch   0 Batch   42/269 - Train Accuracy: 0.4181, Validation Accuracy: 0.4202, Loss: 2.8487\n",
      "Epoch   0 Batch   43/269 - Train Accuracy: 0.3735, Validation Accuracy: 0.4264, Loss: 3.0639\n",
      "Epoch   0 Batch   44/269 - Train Accuracy: 0.4032, Validation Accuracy: 0.4282, Loss: 2.9304\n",
      "Epoch   0 Batch   45/269 - Train Accuracy: 0.3696, Validation Accuracy: 0.4245, Loss: 3.0642\n",
      "Epoch   0 Batch   46/269 - Train Accuracy: 0.3692, Validation Accuracy: 0.4271, Loss: 3.0897\n",
      "Epoch   0 Batch   47/269 - Train Accuracy: 0.4321, Validation Accuracy: 0.4307, Loss: 2.7680\n",
      "Epoch   0 Batch   48/269 - Train Accuracy: 0.4109, Validation Accuracy: 0.4348, Loss: 2.8643\n",
      "Epoch   0 Batch   49/269 - Train Accuracy: 0.3788, Validation Accuracy: 0.4310, Loss: 2.9967\n",
      "Epoch   0 Batch   50/269 - Train Accuracy: 0.3869, Validation Accuracy: 0.4423, Loss: 2.9827\n",
      "Epoch   0 Batch   51/269 - Train Accuracy: 0.4097, Validation Accuracy: 0.4426, Loss: 2.8742\n",
      "Epoch   0 Batch   52/269 - Train Accuracy: 0.4189, Validation Accuracy: 0.4420, Loss: 2.8243\n",
      "Epoch   0 Batch   53/269 - Train Accuracy: 0.3899, Validation Accuracy: 0.4476, Loss: 2.9592\n",
      "Epoch   0 Batch   54/269 - Train Accuracy: 0.3953, Validation Accuracy: 0.4466, Loss: 2.9401\n",
      "Epoch   0 Batch   55/269 - Train Accuracy: 0.4198, Validation Accuracy: 0.4482, Loss: 2.8007\n",
      "Epoch   0 Batch   56/269 - Train Accuracy: 0.4357, Validation Accuracy: 0.4589, Loss: 2.7835\n",
      "Epoch   0 Batch   57/269 - Train Accuracy: 0.4299, Validation Accuracy: 0.4529, Loss: 2.7738\n",
      "Epoch   0 Batch   58/269 - Train Accuracy: 0.4387, Validation Accuracy: 0.4586, Loss: 2.7725\n",
      "Epoch   0 Batch   59/269 - Train Accuracy: 0.4317, Validation Accuracy: 0.4579, Loss: 2.7440\n",
      "Epoch   0 Batch   60/269 - Train Accuracy: 0.4387, Validation Accuracy: 0.4560, Loss: 2.6658\n",
      "Epoch   0 Batch   61/269 - Train Accuracy: 0.4608, Validation Accuracy: 0.4590, Loss: 2.6061\n",
      "Epoch   0 Batch   62/269 - Train Accuracy: 0.4381, Validation Accuracy: 0.4276, Loss: 2.6343\n",
      "Epoch   0 Batch   63/269 - Train Accuracy: 0.4166, Validation Accuracy: 0.4477, Loss: 2.7382\n",
      "Epoch   0 Batch   64/269 - Train Accuracy: 0.4321, Validation Accuracy: 0.4569, Loss: 2.7454\n",
      "Epoch   0 Batch   65/269 - Train Accuracy: 0.4089, Validation Accuracy: 0.4322, Loss: 2.6698\n",
      "Epoch   0 Batch   66/269 - Train Accuracy: 0.4441, Validation Accuracy: 0.4542, Loss: 2.6200\n",
      "Epoch   0 Batch   67/269 - Train Accuracy: 0.4253, Validation Accuracy: 0.4570, Loss: 2.6994\n",
      "Epoch   0 Batch   68/269 - Train Accuracy: 0.4190, Validation Accuracy: 0.4373, Loss: 2.6765\n",
      "Epoch   0 Batch   69/269 - Train Accuracy: 0.4023, Validation Accuracy: 0.4577, Loss: 2.8307\n",
      "Epoch   0 Batch   70/269 - Train Accuracy: 0.4311, Validation Accuracy: 0.4512, Loss: 2.6261\n",
      "Epoch   0 Batch   71/269 - Train Accuracy: 0.4099, Validation Accuracy: 0.4609, Loss: 2.7849\n",
      "Epoch   0 Batch   72/269 - Train Accuracy: 0.4386, Validation Accuracy: 0.4413, Loss: 2.5369\n",
      "Epoch   0 Batch   73/269 - Train Accuracy: 0.4390, Validation Accuracy: 0.4623, Loss: 2.6454\n",
      "Epoch   0 Batch   74/269 - Train Accuracy: 0.4050, Validation Accuracy: 0.4565, Loss: 2.7029\n",
      "Epoch   0 Batch   75/269 - Train Accuracy: 0.4439, Validation Accuracy: 0.4705, Loss: 2.6043\n",
      "Epoch   0 Batch   76/269 - Train Accuracy: 0.4292, Validation Accuracy: 0.4647, Loss: 2.6337\n",
      "Epoch   0 Batch   77/269 - Train Accuracy: 0.4590, Validation Accuracy: 0.4756, Loss: 2.5881\n",
      "Epoch   0 Batch   78/269 - Train Accuracy: 0.4431, Validation Accuracy: 0.4725, Loss: 2.6050\n",
      "Epoch   0 Batch   79/269 - Train Accuracy: 0.4453, Validation Accuracy: 0.4717, Loss: 2.5817\n",
      "Epoch   0 Batch   80/269 - Train Accuracy: 0.4566, Validation Accuracy: 0.4743, Loss: 2.5156\n",
      "Epoch   0 Batch   81/269 - Train Accuracy: 0.4388, Validation Accuracy: 0.4648, Loss: 2.5639\n",
      "Epoch   0 Batch   82/269 - Train Accuracy: 0.4638, Validation Accuracy: 0.4788, Loss: 2.4944\n",
      "Epoch   0 Batch   83/269 - Train Accuracy: 0.4713, Validation Accuracy: 0.4858, Loss: 2.4847\n",
      "Epoch   0 Batch   84/269 - Train Accuracy: 0.4600, Validation Accuracy: 0.4847, Loss: 2.5129\n",
      "Epoch   0 Batch   85/269 - Train Accuracy: 0.4521, Validation Accuracy: 0.4817, Loss: 2.5246\n",
      "Epoch   0 Batch   86/269 - Train Accuracy: 0.4611, Validation Accuracy: 0.4863, Loss: 2.5135\n",
      "Epoch   0 Batch   87/269 - Train Accuracy: 0.4140, Validation Accuracy: 0.4809, Loss: 2.6601\n",
      "Epoch   0 Batch   88/269 - Train Accuracy: 0.4603, Validation Accuracy: 0.4837, Loss: 2.4668\n",
      "Epoch   0 Batch   89/269 - Train Accuracy: 0.4743, Validation Accuracy: 0.4901, Loss: 2.4599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch   90/269 - Train Accuracy: 0.4322, Validation Accuracy: 0.4899, Loss: 2.6045\n",
      "Epoch   0 Batch   91/269 - Train Accuracy: 0.4550, Validation Accuracy: 0.4846, Loss: 2.4578\n",
      "Epoch   0 Batch   92/269 - Train Accuracy: 0.4658, Validation Accuracy: 0.4925, Loss: 2.4381\n",
      "Epoch   0 Batch   93/269 - Train Accuracy: 0.4869, Validation Accuracy: 0.4893, Loss: 2.3445\n",
      "Epoch   0 Batch   94/269 - Train Accuracy: 0.4547, Validation Accuracy: 0.4827, Loss: 2.4198\n",
      "Epoch   0 Batch   95/269 - Train Accuracy: 0.4736, Validation Accuracy: 0.4896, Loss: 2.4187\n",
      "Epoch   0 Batch   96/269 - Train Accuracy: 0.4648, Validation Accuracy: 0.4889, Loss: 2.4030\n",
      "Epoch   0 Batch   97/269 - Train Accuracy: 0.4642, Validation Accuracy: 0.4901, Loss: 2.3944\n",
      "Epoch   0 Batch   98/269 - Train Accuracy: 0.4855, Validation Accuracy: 0.4894, Loss: 2.3608\n",
      "Epoch   0 Batch   99/269 - Train Accuracy: 0.4370, Validation Accuracy: 0.4875, Loss: 2.5079\n",
      "Epoch   0 Batch  100/269 - Train Accuracy: 0.4876, Validation Accuracy: 0.4902, Loss: 2.3142\n",
      "Epoch   0 Batch  101/269 - Train Accuracy: 0.4359, Validation Accuracy: 0.4885, Loss: 2.4814\n",
      "Epoch   0 Batch  102/269 - Train Accuracy: 0.4654, Validation Accuracy: 0.4906, Loss: 2.3544\n",
      "Epoch   0 Batch  103/269 - Train Accuracy: 0.4654, Validation Accuracy: 0.4885, Loss: 2.3426\n",
      "Epoch   0 Batch  104/269 - Train Accuracy: 0.4573, Validation Accuracy: 0.4819, Loss: 2.3558\n",
      "Epoch   0 Batch  105/269 - Train Accuracy: 0.4561, Validation Accuracy: 0.4875, Loss: 2.3518\n",
      "Epoch   0 Batch  106/269 - Train Accuracy: 0.4488, Validation Accuracy: 0.4812, Loss: 2.3557\n",
      "Epoch   0 Batch  107/269 - Train Accuracy: 0.4171, Validation Accuracy: 0.4839, Loss: 2.4690\n",
      "Epoch   0 Batch  108/269 - Train Accuracy: 0.4604, Validation Accuracy: 0.4875, Loss: 2.3322\n",
      "Epoch   0 Batch  109/269 - Train Accuracy: 0.4600, Validation Accuracy: 0.4898, Loss: 2.3236\n",
      "Epoch   0 Batch  110/269 - Train Accuracy: 0.4521, Validation Accuracy: 0.4858, Loss: 2.3027\n",
      "Epoch   0 Batch  111/269 - Train Accuracy: 0.4306, Validation Accuracy: 0.4831, Loss: 2.4395\n",
      "Epoch   0 Batch  112/269 - Train Accuracy: 0.4599, Validation Accuracy: 0.4884, Loss: 2.2751\n",
      "Epoch   0 Batch  113/269 - Train Accuracy: 0.4885, Validation Accuracy: 0.4925, Loss: 2.1725\n",
      "Epoch   0 Batch  114/269 - Train Accuracy: 0.4646, Validation Accuracy: 0.4887, Loss: 2.2606\n",
      "Epoch   0 Batch  115/269 - Train Accuracy: 0.4216, Validation Accuracy: 0.4824, Loss: 2.3590\n",
      "Epoch   0 Batch  116/269 - Train Accuracy: 0.4642, Validation Accuracy: 0.4827, Loss: 2.2603\n",
      "Epoch   0 Batch  117/269 - Train Accuracy: 0.4498, Validation Accuracy: 0.4862, Loss: 2.2648\n",
      "Epoch   0 Batch  118/269 - Train Accuracy: 0.4772, Validation Accuracy: 0.4878, Loss: 2.1733\n",
      "Epoch   0 Batch  119/269 - Train Accuracy: 0.4494, Validation Accuracy: 0.4908, Loss: 2.3343\n",
      "Epoch   0 Batch  120/269 - Train Accuracy: 0.4333, Validation Accuracy: 0.4886, Loss: 2.3298\n",
      "Epoch   0 Batch  121/269 - Train Accuracy: 0.4662, Validation Accuracy: 0.4946, Loss: 2.2060\n",
      "Epoch   0 Batch  122/269 - Train Accuracy: 0.4696, Validation Accuracy: 0.4876, Loss: 2.1822\n",
      "Epoch   0 Batch  123/269 - Train Accuracy: 0.4206, Validation Accuracy: 0.4866, Loss: 2.3155\n",
      "Epoch   0 Batch  124/269 - Train Accuracy: 0.4781, Validation Accuracy: 0.4996, Loss: 2.1886\n",
      "Epoch   0 Batch  125/269 - Train Accuracy: 0.4725, Validation Accuracy: 0.4943, Loss: 2.1567\n",
      "Epoch   0 Batch  126/269 - Train Accuracy: 0.4649, Validation Accuracy: 0.4842, Loss: 2.1434\n",
      "Epoch   0 Batch  127/269 - Train Accuracy: 0.4385, Validation Accuracy: 0.4962, Loss: 2.2722\n",
      "Epoch   0 Batch  128/269 - Train Accuracy: 0.4820, Validation Accuracy: 0.4925, Loss: 2.1350\n",
      "Epoch   0 Batch  129/269 - Train Accuracy: 0.4539, Validation Accuracy: 0.4819, Loss: 2.1759\n",
      "Epoch   0 Batch  130/269 - Train Accuracy: 0.4383, Validation Accuracy: 0.4957, Loss: 2.3031\n",
      "Epoch   0 Batch  131/269 - Train Accuracy: 0.4516, Validation Accuracy: 0.4919, Loss: 2.2429\n",
      "Epoch   0 Batch  132/269 - Train Accuracy: 0.4481, Validation Accuracy: 0.4802, Loss: 2.1443\n",
      "Epoch   0 Batch  133/269 - Train Accuracy: 0.4625, Validation Accuracy: 0.4891, Loss: 2.1315\n",
      "Epoch   0 Batch  134/269 - Train Accuracy: 0.4298, Validation Accuracy: 0.4858, Loss: 2.1995\n",
      "Epoch   0 Batch  135/269 - Train Accuracy: 0.4218, Validation Accuracy: 0.4849, Loss: 2.2513\n",
      "Epoch   0 Batch  136/269 - Train Accuracy: 0.4389, Validation Accuracy: 0.4964, Loss: 2.2236\n",
      "Epoch   0 Batch  137/269 - Train Accuracy: 0.4384, Validation Accuracy: 0.4885, Loss: 2.2055\n",
      "Epoch   0 Batch  138/269 - Train Accuracy: 0.4520, Validation Accuracy: 0.4949, Loss: 2.1363\n",
      "Epoch   0 Batch  139/269 - Train Accuracy: 0.4726, Validation Accuracy: 0.4908, Loss: 2.0548\n",
      "Epoch   0 Batch  140/269 - Train Accuracy: 0.4618, Validation Accuracy: 0.4859, Loss: 2.0702\n",
      "Epoch   0 Batch  141/269 - Train Accuracy: 0.4726, Validation Accuracy: 0.5043, Loss: 2.1012\n",
      "Epoch   0 Batch  142/269 - Train Accuracy: 0.4841, Validation Accuracy: 0.5033, Loss: 2.0425\n",
      "Epoch   0 Batch  143/269 - Train Accuracy: 0.4727, Validation Accuracy: 0.4999, Loss: 2.0561\n",
      "Epoch   0 Batch  144/269 - Train Accuracy: 0.4853, Validation Accuracy: 0.5048, Loss: 2.0388\n",
      "Epoch   0 Batch  145/269 - Train Accuracy: 0.4594, Validation Accuracy: 0.4939, Loss: 2.0373\n",
      "Epoch   0 Batch  146/269 - Train Accuracy: 0.4649, Validation Accuracy: 0.4908, Loss: 2.0210\n",
      "Epoch   0 Batch  147/269 - Train Accuracy: 0.4956, Validation Accuracy: 0.4973, Loss: 1.9423\n",
      "Epoch   0 Batch  148/269 - Train Accuracy: 0.4562, Validation Accuracy: 0.4958, Loss: 2.0577\n",
      "Epoch   0 Batch  149/269 - Train Accuracy: 0.4654, Validation Accuracy: 0.4904, Loss: 2.0017\n",
      "Epoch   0 Batch  150/269 - Train Accuracy: 0.4716, Validation Accuracy: 0.5003, Loss: 2.0084\n",
      "Epoch   0 Batch  151/269 - Train Accuracy: 0.5008, Validation Accuracy: 0.4980, Loss: 1.9070\n",
      "Epoch   0 Batch  152/269 - Train Accuracy: 0.4549, Validation Accuracy: 0.4844, Loss: 1.9862\n",
      "Epoch   0 Batch  153/269 - Train Accuracy: 0.4742, Validation Accuracy: 0.4972, Loss: 1.9798\n",
      "Epoch   0 Batch  154/269 - Train Accuracy: 0.4316, Validation Accuracy: 0.4948, Loss: 2.0859\n",
      "Epoch   0 Batch  155/269 - Train Accuracy: 0.4975, Validation Accuracy: 0.4921, Loss: 1.8587\n",
      "Epoch   0 Batch  156/269 - Train Accuracy: 0.4709, Validation Accuracy: 0.5058, Loss: 2.0083\n",
      "Epoch   0 Batch  157/269 - Train Accuracy: 0.4711, Validation Accuracy: 0.4974, Loss: 1.9409\n",
      "Epoch   0 Batch  158/269 - Train Accuracy: 0.4626, Validation Accuracy: 0.4874, Loss: 1.9168\n",
      "Epoch   0 Batch  159/269 - Train Accuracy: 0.4765, Validation Accuracy: 0.4994, Loss: 1.9370\n",
      "Epoch   0 Batch  160/269 - Train Accuracy: 0.4669, Validation Accuracy: 0.4919, Loss: 1.9412\n",
      "Epoch   0 Batch  161/269 - Train Accuracy: 0.4541, Validation Accuracy: 0.4874, Loss: 1.9358\n",
      "Epoch   0 Batch  162/269 - Train Accuracy: 0.4803, Validation Accuracy: 0.5046, Loss: 1.9022\n",
      "Epoch   0 Batch  163/269 - Train Accuracy: 0.4765, Validation Accuracy: 0.4996, Loss: 1.9047\n",
      "Epoch   0 Batch  164/269 - Train Accuracy: 0.4715, Validation Accuracy: 0.4976, Loss: 1.8886\n",
      "Epoch   0 Batch  165/269 - Train Accuracy: 0.4407, Validation Accuracy: 0.5008, Loss: 1.9632\n",
      "Epoch   0 Batch  166/269 - Train Accuracy: 0.5044, Validation Accuracy: 0.5007, Loss: 1.7759\n",
      "Epoch   0 Batch  167/269 - Train Accuracy: 0.4793, Validation Accuracy: 0.4980, Loss: 1.8627\n",
      "Epoch   0 Batch  168/269 - Train Accuracy: 0.4761, Validation Accuracy: 0.5034, Loss: 1.8739\n",
      "Epoch   0 Batch  169/269 - Train Accuracy: 0.4698, Validation Accuracy: 0.4999, Loss: 1.8684\n",
      "Epoch   0 Batch  170/269 - Train Accuracy: 0.4759, Validation Accuracy: 0.4990, Loss: 1.8464\n",
      "Epoch   0 Batch  171/269 - Train Accuracy: 0.4568, Validation Accuracy: 0.5016, Loss: 1.9073\n",
      "Epoch   0 Batch  172/269 - Train Accuracy: 0.4720, Validation Accuracy: 0.4944, Loss: 1.8481\n",
      "Epoch   0 Batch  173/269 - Train Accuracy: 0.4770, Validation Accuracy: 0.4998, Loss: 1.8406\n",
      "Epoch   0 Batch  174/269 - Train Accuracy: 0.4762, Validation Accuracy: 0.5013, Loss: 1.8355\n",
      "Epoch   0 Batch  175/269 - Train Accuracy: 0.4780, Validation Accuracy: 0.5001, Loss: 1.8305\n",
      "Epoch   0 Batch  176/269 - Train Accuracy: 0.4560, Validation Accuracy: 0.5036, Loss: 1.9007\n",
      "Epoch   0 Batch  177/269 - Train Accuracy: 0.4925, Validation Accuracy: 0.5033, Loss: 1.7535\n",
      "Epoch   0 Batch  178/269 - Train Accuracy: 0.4560, Validation Accuracy: 0.4977, Loss: 1.8728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch  179/269 - Train Accuracy: 0.4825, Validation Accuracy: 0.5025, Loss: 1.7978\n",
      "Epoch   0 Batch  180/269 - Train Accuracy: 0.4772, Validation Accuracy: 0.5022, Loss: 1.7781\n",
      "Epoch   0 Batch  181/269 - Train Accuracy: 0.4696, Validation Accuracy: 0.4966, Loss: 1.7763\n",
      "Epoch   0 Batch  182/269 - Train Accuracy: 0.4776, Validation Accuracy: 0.5045, Loss: 1.7828\n",
      "Epoch   0 Batch  183/269 - Train Accuracy: 0.5478, Validation Accuracy: 0.5063, Loss: 1.5442\n",
      "Epoch   0 Batch  184/269 - Train Accuracy: 0.4408, Validation Accuracy: 0.4923, Loss: 1.8302\n",
      "Epoch   0 Batch  185/269 - Train Accuracy: 0.5016, Validation Accuracy: 0.5122, Loss: 1.7545\n",
      "Epoch   0 Batch  186/269 - Train Accuracy: 0.4562, Validation Accuracy: 0.5093, Loss: 1.8217\n",
      "Epoch   0 Batch  187/269 - Train Accuracy: 0.4857, Validation Accuracy: 0.4982, Loss: 1.7026\n",
      "Epoch   0 Batch  188/269 - Train Accuracy: 0.5007, Validation Accuracy: 0.5075, Loss: 1.6914\n",
      "Epoch   0 Batch  189/269 - Train Accuracy: 0.4932, Validation Accuracy: 0.5148, Loss: 1.7213\n",
      "Epoch   0 Batch  190/269 - Train Accuracy: 0.4931, Validation Accuracy: 0.5124, Loss: 1.7062\n",
      "Epoch   0 Batch  191/269 - Train Accuracy: 0.4918, Validation Accuracy: 0.5144, Loss: 1.7272\n",
      "Epoch   0 Batch  192/269 - Train Accuracy: 0.4893, Validation Accuracy: 0.5173, Loss: 1.7238\n",
      "Epoch   0 Batch  193/269 - Train Accuracy: 0.4833, Validation Accuracy: 0.5089, Loss: 1.7165\n",
      "Epoch   0 Batch  194/269 - Train Accuracy: 0.4883, Validation Accuracy: 0.5071, Loss: 1.7038\n",
      "Epoch   0 Batch  195/269 - Train Accuracy: 0.4807, Validation Accuracy: 0.5132, Loss: 1.7298\n",
      "Epoch   0 Batch  196/269 - Train Accuracy: 0.4790, Validation Accuracy: 0.5137, Loss: 1.6880\n",
      "Epoch   0 Batch  197/269 - Train Accuracy: 0.4467, Validation Accuracy: 0.5039, Loss: 1.7639\n",
      "Epoch   0 Batch  198/269 - Train Accuracy: 0.4640, Validation Accuracy: 0.5154, Loss: 1.8038\n",
      "Epoch   0 Batch  199/269 - Train Accuracy: 0.4825, Validation Accuracy: 0.5154, Loss: 1.7142\n",
      "Epoch   0 Batch  200/269 - Train Accuracy: 0.4602, Validation Accuracy: 0.5003, Loss: 1.7368\n",
      "Epoch   0 Batch  201/269 - Train Accuracy: 0.4873, Validation Accuracy: 0.5123, Loss: 1.6771\n",
      "Epoch   0 Batch  202/269 - Train Accuracy: 0.4804, Validation Accuracy: 0.5107, Loss: 1.6807\n",
      "Epoch   0 Batch  203/269 - Train Accuracy: 0.4669, Validation Accuracy: 0.5099, Loss: 1.7366\n",
      "Epoch   0 Batch  204/269 - Train Accuracy: 0.4573, Validation Accuracy: 0.5081, Loss: 1.7175\n",
      "Epoch   0 Batch  205/269 - Train Accuracy: 0.4829, Validation Accuracy: 0.5151, Loss: 1.6462\n",
      "Epoch   0 Batch  206/269 - Train Accuracy: 0.4554, Validation Accuracy: 0.5110, Loss: 1.7503\n",
      "Epoch   0 Batch  207/269 - Train Accuracy: 0.5012, Validation Accuracy: 0.5091, Loss: 1.5809\n",
      "Epoch   0 Batch  208/269 - Train Accuracy: 0.4637, Validation Accuracy: 0.5146, Loss: 1.7419\n",
      "Epoch   0 Batch  209/269 - Train Accuracy: 0.4651, Validation Accuracy: 0.5170, Loss: 1.6970\n",
      "Epoch   0 Batch  210/269 - Train Accuracy: 0.4848, Validation Accuracy: 0.5105, Loss: 1.6263\n",
      "Epoch   0 Batch  211/269 - Train Accuracy: 0.4889, Validation Accuracy: 0.5106, Loss: 1.6189\n",
      "Epoch   0 Batch  212/269 - Train Accuracy: 0.5072, Validation Accuracy: 0.5150, Loss: 1.5901\n",
      "Epoch   0 Batch  213/269 - Train Accuracy: 0.4910, Validation Accuracy: 0.5148, Loss: 1.5952\n",
      "Epoch   0 Batch  214/269 - Train Accuracy: 0.4956, Validation Accuracy: 0.5142, Loss: 1.6007\n",
      "Epoch   0 Batch  215/269 - Train Accuracy: 0.5265, Validation Accuracy: 0.5194, Loss: 1.5202\n",
      "Epoch   0 Batch  216/269 - Train Accuracy: 0.4639, Validation Accuracy: 0.5178, Loss: 1.7063\n",
      "Epoch   0 Batch  217/269 - Train Accuracy: 0.4616, Validation Accuracy: 0.5131, Loss: 1.6763\n",
      "Epoch   0 Batch  218/269 - Train Accuracy: 0.4729, Validation Accuracy: 0.5147, Loss: 1.6693\n",
      "Epoch   0 Batch  219/269 - Train Accuracy: 0.4779, Validation Accuracy: 0.5176, Loss: 1.6433\n",
      "Epoch   0 Batch  220/269 - Train Accuracy: 0.5027, Validation Accuracy: 0.5125, Loss: 1.5266\n",
      "Epoch   0 Batch  221/269 - Train Accuracy: 0.4858, Validation Accuracy: 0.5067, Loss: 1.5772\n",
      "Epoch   0 Batch  222/269 - Train Accuracy: 0.5046, Validation Accuracy: 0.5162, Loss: 1.5442\n",
      "Epoch   0 Batch  223/269 - Train Accuracy: 0.5046, Validation Accuracy: 0.5186, Loss: 1.5345\n",
      "Epoch   0 Batch  224/269 - Train Accuracy: 0.4980, Validation Accuracy: 0.5143, Loss: 1.5752\n",
      "Epoch   0 Batch  225/269 - Train Accuracy: 0.4730, Validation Accuracy: 0.5158, Loss: 1.6319\n",
      "Epoch   0 Batch  226/269 - Train Accuracy: 0.4928, Validation Accuracy: 0.5174, Loss: 1.5487\n",
      "Epoch   0 Batch  227/269 - Train Accuracy: 0.5576, Validation Accuracy: 0.5105, Loss: 1.3680\n",
      "Epoch   0 Batch  228/269 - Train Accuracy: 0.4820, Validation Accuracy: 0.5090, Loss: 1.5728\n",
      "Epoch   0 Batch  229/269 - Train Accuracy: 0.4986, Validation Accuracy: 0.5171, Loss: 1.5441\n",
      "Epoch   0 Batch  230/269 - Train Accuracy: 0.4902, Validation Accuracy: 0.5213, Loss: 1.5579\n",
      "Epoch   0 Batch  231/269 - Train Accuracy: 0.4579, Validation Accuracy: 0.5095, Loss: 1.6220\n",
      "Epoch   0 Batch  232/269 - Train Accuracy: 0.4638, Validation Accuracy: 0.5213, Loss: 1.6044\n",
      "Epoch   0 Batch  233/269 - Train Accuracy: 0.5079, Validation Accuracy: 0.5265, Loss: 1.5474\n",
      "Epoch   0 Batch  234/269 - Train Accuracy: 0.4826, Validation Accuracy: 0.5087, Loss: 1.5471\n",
      "Epoch   0 Batch  235/269 - Train Accuracy: 0.4940, Validation Accuracy: 0.5135, Loss: 1.5408\n",
      "Epoch   0 Batch  236/269 - Train Accuracy: 0.4982, Validation Accuracy: 0.5251, Loss: 1.5287\n",
      "Epoch   0 Batch  237/269 - Train Accuracy: 0.4875, Validation Accuracy: 0.5086, Loss: 1.5275\n",
      "Epoch   0 Batch  238/269 - Train Accuracy: 0.4840, Validation Accuracy: 0.5099, Loss: 1.5210\n",
      "Epoch   0 Batch  239/269 - Train Accuracy: 0.5084, Validation Accuracy: 0.5280, Loss: 1.5031\n",
      "Epoch   0 Batch  240/269 - Train Accuracy: 0.5470, Validation Accuracy: 0.5278, Loss: 1.4113\n",
      "Epoch   0 Batch  241/269 - Train Accuracy: 0.4801, Validation Accuracy: 0.5075, Loss: 1.5082\n",
      "Epoch   0 Batch  242/269 - Train Accuracy: 0.4855, Validation Accuracy: 0.5201, Loss: 1.5097\n",
      "Epoch   0 Batch  243/269 - Train Accuracy: 0.5190, Validation Accuracy: 0.5259, Loss: 1.4739\n",
      "Epoch   0 Batch  244/269 - Train Accuracy: 0.4866, Validation Accuracy: 0.5148, Loss: 1.4820\n",
      "Epoch   0 Batch  245/269 - Train Accuracy: 0.4722, Validation Accuracy: 0.5161, Loss: 1.5709\n",
      "Epoch   0 Batch  246/269 - Train Accuracy: 0.5019, Validation Accuracy: 0.5279, Loss: 1.4999\n",
      "Epoch   0 Batch  247/269 - Train Accuracy: 0.4664, Validation Accuracy: 0.5077, Loss: 1.5370\n",
      "Epoch   0 Batch  248/269 - Train Accuracy: 0.4741, Validation Accuracy: 0.5039, Loss: 1.4850\n",
      "Epoch   0 Batch  249/269 - Train Accuracy: 0.5371, Validation Accuracy: 0.5181, Loss: 1.4214\n",
      "Epoch   0 Batch  250/269 - Train Accuracy: 0.4838, Validation Accuracy: 0.5143, Loss: 1.5325\n",
      "Epoch   0 Batch  251/269 - Train Accuracy: 0.4873, Validation Accuracy: 0.5035, Loss: 1.4588\n",
      "Epoch   0 Batch  252/269 - Train Accuracy: 0.4975, Validation Accuracy: 0.5197, Loss: 1.4909\n",
      "Epoch   0 Batch  253/269 - Train Accuracy: 0.4904, Validation Accuracy: 0.5148, Loss: 1.4689\n",
      "Epoch   0 Batch  254/269 - Train Accuracy: 0.4886, Validation Accuracy: 0.5057, Loss: 1.4421\n",
      "Epoch   0 Batch  255/269 - Train Accuracy: 0.5217, Validation Accuracy: 0.5233, Loss: 1.4139\n",
      "Epoch   0 Batch  256/269 - Train Accuracy: 0.4848, Validation Accuracy: 0.5233, Loss: 1.4863\n",
      "Epoch   0 Batch  257/269 - Train Accuracy: 0.4924, Validation Accuracy: 0.5249, Loss: 1.4564\n",
      "Epoch   0 Batch  258/269 - Train Accuracy: 0.4904, Validation Accuracy: 0.5232, Loss: 1.4679\n",
      "Epoch   0 Batch  259/269 - Train Accuracy: 0.5144, Validation Accuracy: 0.5292, Loss: 1.4470\n",
      "Epoch   0 Batch  260/269 - Train Accuracy: 0.4858, Validation Accuracy: 0.5229, Loss: 1.5075\n",
      "Epoch   0 Batch  261/269 - Train Accuracy: 0.4605, Validation Accuracy: 0.5178, Loss: 1.5315\n",
      "Epoch   0 Batch  262/269 - Train Accuracy: 0.5059, Validation Accuracy: 0.5256, Loss: 1.4526\n",
      "Epoch   0 Batch  263/269 - Train Accuracy: 0.4905, Validation Accuracy: 0.5266, Loss: 1.4998\n",
      "Epoch   0 Batch  264/269 - Train Accuracy: 0.4713, Validation Accuracy: 0.5185, Loss: 1.5072\n",
      "Epoch   0 Batch  265/269 - Train Accuracy: 0.4938, Validation Accuracy: 0.5323, Loss: 1.4717\n",
      "Epoch   0 Batch  266/269 - Train Accuracy: 0.5115, Validation Accuracy: 0.5263, Loss: 1.4148\n",
      "Epoch   0 Batch  267/269 - Train Accuracy: 0.4847, Validation Accuracy: 0.5122, Loss: 1.4458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 Batch    1/269 - Train Accuracy: 0.4810, Validation Accuracy: 0.5305, Loss: 1.4724\n",
      "Epoch   1 Batch    2/269 - Train Accuracy: 0.4864, Validation Accuracy: 0.5273, Loss: 1.4426\n",
      "Epoch   1 Batch    3/269 - Train Accuracy: 0.4788, Validation Accuracy: 0.5231, Loss: 1.4698\n",
      "Epoch   1 Batch    4/269 - Train Accuracy: 0.4829, Validation Accuracy: 0.5305, Loss: 1.4539\n",
      "Epoch   1 Batch    5/269 - Train Accuracy: 0.4730, Validation Accuracy: 0.5294, Loss: 1.4723\n",
      "Epoch   1 Batch    6/269 - Train Accuracy: 0.5099, Validation Accuracy: 0.5273, Loss: 1.3476\n",
      "Epoch   1 Batch    7/269 - Train Accuracy: 0.5156, Validation Accuracy: 0.5344, Loss: 1.3889\n",
      "Epoch   1 Batch    8/269 - Train Accuracy: 0.4892, Validation Accuracy: 0.5352, Loss: 1.4508\n",
      "Epoch   1 Batch    9/269 - Train Accuracy: 0.4983, Validation Accuracy: 0.5336, Loss: 1.3987\n",
      "Epoch   1 Batch   10/269 - Train Accuracy: 0.4748, Validation Accuracy: 0.5323, Loss: 1.4205\n",
      "Epoch   1 Batch   11/269 - Train Accuracy: 0.5099, Validation Accuracy: 0.5375, Loss: 1.3984\n",
      "Epoch   1 Batch   12/269 - Train Accuracy: 0.4861, Validation Accuracy: 0.5347, Loss: 1.4465\n",
      "Epoch   1 Batch   13/269 - Train Accuracy: 0.5384, Validation Accuracy: 0.5313, Loss: 1.2884\n",
      "Epoch   1 Batch   14/269 - Train Accuracy: 0.5043, Validation Accuracy: 0.5326, Loss: 1.3713\n",
      "Epoch   1 Batch   15/269 - Train Accuracy: 0.5007, Validation Accuracy: 0.5366, Loss: 1.3706\n",
      "Epoch   1 Batch   16/269 - Train Accuracy: 0.5218, Validation Accuracy: 0.5322, Loss: 1.3732\n",
      "Epoch   1 Batch   17/269 - Train Accuracy: 0.5153, Validation Accuracy: 0.5397, Loss: 1.3447\n",
      "Epoch   1 Batch   18/269 - Train Accuracy: 0.4899, Validation Accuracy: 0.5336, Loss: 1.4140\n",
      "Epoch   1 Batch   19/269 - Train Accuracy: 0.5402, Validation Accuracy: 0.5338, Loss: 1.2932\n",
      "Epoch   1 Batch   20/269 - Train Accuracy: 0.5044, Validation Accuracy: 0.5353, Loss: 1.4077\n",
      "Epoch   1 Batch   21/269 - Train Accuracy: 0.5064, Validation Accuracy: 0.5393, Loss: 1.4490\n",
      "Epoch   1 Batch   22/269 - Train Accuracy: 0.5080, Validation Accuracy: 0.5335, Loss: 1.3447\n",
      "Epoch   1 Batch   23/269 - Train Accuracy: 0.5380, Validation Accuracy: 0.5525, Loss: 1.3584\n",
      "Epoch   1 Batch   24/269 - Train Accuracy: 0.4995, Validation Accuracy: 0.5390, Loss: 1.3916\n",
      "Epoch   1 Batch   25/269 - Train Accuracy: 0.4939, Validation Accuracy: 0.5321, Loss: 1.4050\n",
      "Epoch   1 Batch   26/269 - Train Accuracy: 0.5556, Validation Accuracy: 0.5471, Loss: 1.2573\n",
      "Epoch   1 Batch   27/269 - Train Accuracy: 0.5144, Validation Accuracy: 0.5403, Loss: 1.3432\n",
      "Epoch   1 Batch   28/269 - Train Accuracy: 0.4854, Validation Accuracy: 0.5399, Loss: 1.4236\n",
      "Epoch   1 Batch   29/269 - Train Accuracy: 0.5012, Validation Accuracy: 0.5377, Loss: 1.3750\n",
      "Epoch   1 Batch   30/269 - Train Accuracy: 0.5242, Validation Accuracy: 0.5430, Loss: 1.3211\n",
      "Epoch   1 Batch   31/269 - Train Accuracy: 0.5220, Validation Accuracy: 0.5331, Loss: 1.3081\n",
      "Epoch   1 Batch   32/269 - Train Accuracy: 0.5108, Validation Accuracy: 0.5457, Loss: 1.3204\n",
      "Epoch   1 Batch   33/269 - Train Accuracy: 0.5259, Validation Accuracy: 0.5396, Loss: 1.2856\n",
      "Epoch   1 Batch   34/269 - Train Accuracy: 0.5135, Validation Accuracy: 0.5366, Loss: 1.3049\n",
      "Epoch   1 Batch   35/269 - Train Accuracy: 0.5320, Validation Accuracy: 0.5399, Loss: 1.2993\n",
      "Epoch   1 Batch   36/269 - Train Accuracy: 0.5189, Validation Accuracy: 0.5509, Loss: 1.3094\n",
      "Epoch   1 Batch   37/269 - Train Accuracy: 0.5108, Validation Accuracy: 0.5289, Loss: 1.3234\n",
      "Epoch   1 Batch   38/269 - Train Accuracy: 0.5105, Validation Accuracy: 0.5352, Loss: 1.3206\n",
      "Epoch   1 Batch   39/269 - Train Accuracy: 0.5406, Validation Accuracy: 0.5556, Loss: 1.2923\n",
      "Epoch   1 Batch   40/269 - Train Accuracy: 0.4867, Validation Accuracy: 0.5308, Loss: 1.3472\n",
      "Epoch   1 Batch   41/269 - Train Accuracy: 0.5193, Validation Accuracy: 0.5448, Loss: 1.3127\n",
      "Epoch   1 Batch   42/269 - Train Accuracy: 0.5329, Validation Accuracy: 0.5401, Loss: 1.2242\n",
      "Epoch   1 Batch   43/269 - Train Accuracy: 0.4976, Validation Accuracy: 0.5297, Loss: 1.3245\n",
      "Epoch   1 Batch   44/269 - Train Accuracy: 0.5385, Validation Accuracy: 0.5428, Loss: 1.2899\n",
      "Epoch   1 Batch   45/269 - Train Accuracy: 0.5126, Validation Accuracy: 0.5521, Loss: 1.3315\n",
      "Epoch   1 Batch   46/269 - Train Accuracy: 0.4703, Validation Accuracy: 0.5197, Loss: 1.3407\n",
      "Epoch   1 Batch   47/269 - Train Accuracy: 0.5536, Validation Accuracy: 0.5479, Loss: 1.1912\n",
      "Epoch   1 Batch   48/269 - Train Accuracy: 0.5342, Validation Accuracy: 0.5480, Loss: 1.2414\n",
      "Epoch   1 Batch   49/269 - Train Accuracy: 0.4835, Validation Accuracy: 0.5260, Loss: 1.3088\n",
      "Epoch   1 Batch   50/269 - Train Accuracy: 0.4973, Validation Accuracy: 0.5413, Loss: 1.3266\n",
      "Epoch   1 Batch   51/269 - Train Accuracy: 0.5249, Validation Accuracy: 0.5488, Loss: 1.2859\n",
      "Epoch   1 Batch   52/269 - Train Accuracy: 0.5246, Validation Accuracy: 0.5500, Loss: 1.2503\n",
      "Epoch   1 Batch   53/269 - Train Accuracy: 0.5057, Validation Accuracy: 0.5461, Loss: 1.3257\n",
      "Epoch   1 Batch   54/269 - Train Accuracy: 0.5244, Validation Accuracy: 0.5537, Loss: 1.3153\n",
      "Epoch   1 Batch   55/269 - Train Accuracy: 0.5343, Validation Accuracy: 0.5578, Loss: 1.2428\n",
      "Epoch   1 Batch   56/269 - Train Accuracy: 0.5433, Validation Accuracy: 0.5548, Loss: 1.2519\n",
      "Epoch   1 Batch   57/269 - Train Accuracy: 0.5349, Validation Accuracy: 0.5565, Loss: 1.2596\n",
      "Epoch   1 Batch   58/269 - Train Accuracy: 0.5360, Validation Accuracy: 0.5526, Loss: 1.2428\n",
      "Epoch   1 Batch   59/269 - Train Accuracy: 0.5452, Validation Accuracy: 0.5616, Loss: 1.2195\n",
      "Epoch   1 Batch   60/269 - Train Accuracy: 0.5466, Validation Accuracy: 0.5539, Loss: 1.1904\n",
      "Epoch   1 Batch   61/269 - Train Accuracy: 0.5559, Validation Accuracy: 0.5517, Loss: 1.1709\n",
      "Epoch   1 Batch   62/269 - Train Accuracy: 0.5573, Validation Accuracy: 0.5582, Loss: 1.1915\n",
      "Epoch   1 Batch   63/269 - Train Accuracy: 0.5268, Validation Accuracy: 0.5583, Loss: 1.2316\n",
      "Epoch   1 Batch   64/269 - Train Accuracy: 0.5206, Validation Accuracy: 0.5539, Loss: 1.2151\n",
      "Epoch   1 Batch   65/269 - Train Accuracy: 0.5387, Validation Accuracy: 0.5590, Loss: 1.2015\n",
      "Epoch   1 Batch   66/269 - Train Accuracy: 0.5354, Validation Accuracy: 0.5482, Loss: 1.1906\n",
      "Epoch   1 Batch   67/269 - Train Accuracy: 0.5262, Validation Accuracy: 0.5525, Loss: 1.2347\n",
      "Epoch   1 Batch   68/269 - Train Accuracy: 0.5180, Validation Accuracy: 0.5523, Loss: 1.2290\n",
      "Epoch   1 Batch   69/269 - Train Accuracy: 0.5051, Validation Accuracy: 0.5558, Loss: 1.3169\n",
      "Epoch   1 Batch   70/269 - Train Accuracy: 0.5452, Validation Accuracy: 0.5557, Loss: 1.2060\n",
      "Epoch   1 Batch   71/269 - Train Accuracy: 0.5228, Validation Accuracy: 0.5657, Loss: 1.2607\n",
      "Epoch   1 Batch   72/269 - Train Accuracy: 0.5542, Validation Accuracy: 0.5703, Loss: 1.1783\n",
      "Epoch   1 Batch   73/269 - Train Accuracy: 0.5299, Validation Accuracy: 0.5575, Loss: 1.2280\n",
      "Epoch   1 Batch   74/269 - Train Accuracy: 0.5308, Validation Accuracy: 0.5600, Loss: 1.2236\n",
      "Epoch   1 Batch   75/269 - Train Accuracy: 0.5319, Validation Accuracy: 0.5576, Loss: 1.2039\n",
      "Epoch   1 Batch   76/269 - Train Accuracy: 0.5205, Validation Accuracy: 0.5510, Loss: 1.2204\n",
      "Epoch   1 Batch   77/269 - Train Accuracy: 0.5391, Validation Accuracy: 0.5534, Loss: 1.1886\n",
      "Epoch   1 Batch   78/269 - Train Accuracy: 0.5325, Validation Accuracy: 0.5645, Loss: 1.1952\n",
      "Epoch   1 Batch   79/269 - Train Accuracy: 0.5366, Validation Accuracy: 0.5610, Loss: 1.1840\n",
      "Epoch   1 Batch   80/269 - Train Accuracy: 0.5512, Validation Accuracy: 0.5523, Loss: 1.1607\n",
      "Epoch   1 Batch   81/269 - Train Accuracy: 0.5379, Validation Accuracy: 0.5631, Loss: 1.2054\n",
      "Epoch   1 Batch   82/269 - Train Accuracy: 0.5424, Validation Accuracy: 0.5590, Loss: 1.1502\n",
      "Epoch   1 Batch   83/269 - Train Accuracy: 0.5473, Validation Accuracy: 0.5479, Loss: 1.1639\n",
      "Epoch   1 Batch   84/269 - Train Accuracy: 0.5429, Validation Accuracy: 0.5592, Loss: 1.1600\n",
      "Epoch   1 Batch   85/269 - Train Accuracy: 0.5407, Validation Accuracy: 0.5588, Loss: 1.1813\n",
      "Epoch   1 Batch   86/269 - Train Accuracy: 0.5107, Validation Accuracy: 0.5493, Loss: 1.1855\n",
      "Epoch   1 Batch   87/269 - Train Accuracy: 0.5109, Validation Accuracy: 0.5586, Loss: 1.2533\n",
      "Epoch   1 Batch   88/269 - Train Accuracy: 0.5478, Validation Accuracy: 0.5628, Loss: 1.1672\n",
      "Epoch   1 Batch   89/269 - Train Accuracy: 0.5365, Validation Accuracy: 0.5513, Loss: 1.1569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 Batch   90/269 - Train Accuracy: 0.5029, Validation Accuracy: 0.5509, Loss: 1.2408\n",
      "Epoch   1 Batch   91/269 - Train Accuracy: 0.5272, Validation Accuracy: 0.5506, Loss: 1.1536\n",
      "Epoch   1 Batch   92/269 - Train Accuracy: 0.5298, Validation Accuracy: 0.5456, Loss: 1.1548\n",
      "Epoch   1 Batch   93/269 - Train Accuracy: 0.5431, Validation Accuracy: 0.5498, Loss: 1.1148\n",
      "Epoch   1 Batch   94/269 - Train Accuracy: 0.5310, Validation Accuracy: 0.5502, Loss: 1.1707\n",
      "Epoch   1 Batch   95/269 - Train Accuracy: 0.5357, Validation Accuracy: 0.5496, Loss: 1.1493\n",
      "Epoch   1 Batch   96/269 - Train Accuracy: 0.5359, Validation Accuracy: 0.5532, Loss: 1.1330\n",
      "Epoch   1 Batch   97/269 - Train Accuracy: 0.5180, Validation Accuracy: 0.5520, Loss: 1.1437\n",
      "Epoch   1 Batch   98/269 - Train Accuracy: 0.5585, Validation Accuracy: 0.5541, Loss: 1.1283\n",
      "Epoch   1 Batch   99/269 - Train Accuracy: 0.5151, Validation Accuracy: 0.5546, Loss: 1.1894\n",
      "Epoch   1 Batch  100/269 - Train Accuracy: 0.5534, Validation Accuracy: 0.5554, Loss: 1.1051\n",
      "Epoch   1 Batch  101/269 - Train Accuracy: 0.4979, Validation Accuracy: 0.5493, Loss: 1.1851\n",
      "Epoch   1 Batch  102/269 - Train Accuracy: 0.5382, Validation Accuracy: 0.5566, Loss: 1.1154\n",
      "Epoch   1 Batch  103/269 - Train Accuracy: 0.5331, Validation Accuracy: 0.5609, Loss: 1.1193\n",
      "Epoch   1 Batch  104/269 - Train Accuracy: 0.5237, Validation Accuracy: 0.5553, Loss: 1.1304\n",
      "Epoch   1 Batch  105/269 - Train Accuracy: 0.5268, Validation Accuracy: 0.5492, Loss: 1.1407\n",
      "Epoch   1 Batch  106/269 - Train Accuracy: 0.5265, Validation Accuracy: 0.5520, Loss: 1.1198\n",
      "Epoch   1 Batch  107/269 - Train Accuracy: 0.4985, Validation Accuracy: 0.5479, Loss: 1.1700\n",
      "Epoch   1 Batch  108/269 - Train Accuracy: 0.5312, Validation Accuracy: 0.5506, Loss: 1.1048\n",
      "Epoch   1 Batch  109/269 - Train Accuracy: 0.5136, Validation Accuracy: 0.5526, Loss: 1.1310\n",
      "Epoch   1 Batch  110/269 - Train Accuracy: 0.5311, Validation Accuracy: 0.5560, Loss: 1.1061\n",
      "Epoch   1 Batch  111/269 - Train Accuracy: 0.5134, Validation Accuracy: 0.5530, Loss: 1.1933\n",
      "Epoch   1 Batch  112/269 - Train Accuracy: 0.5491, Validation Accuracy: 0.5520, Loss: 1.1007\n",
      "Epoch   1 Batch  113/269 - Train Accuracy: 0.5565, Validation Accuracy: 0.5545, Loss: 1.0594\n",
      "Epoch   1 Batch  114/269 - Train Accuracy: 0.5302, Validation Accuracy: 0.5514, Loss: 1.0967\n",
      "Epoch   1 Batch  115/269 - Train Accuracy: 0.5220, Validation Accuracy: 0.5552, Loss: 1.1311\n",
      "Epoch   1 Batch  116/269 - Train Accuracy: 0.5413, Validation Accuracy: 0.5538, Loss: 1.1070\n",
      "Epoch   1 Batch  117/269 - Train Accuracy: 0.5323, Validation Accuracy: 0.5538, Loss: 1.0816\n",
      "Epoch   1 Batch  118/269 - Train Accuracy: 0.5663, Validation Accuracy: 0.5550, Loss: 1.0529\n",
      "Epoch   1 Batch  119/269 - Train Accuracy: 0.5229, Validation Accuracy: 0.5546, Loss: 1.1539\n",
      "Epoch   1 Batch  120/269 - Train Accuracy: 0.5156, Validation Accuracy: 0.5462, Loss: 1.1228\n",
      "Epoch   1 Batch  121/269 - Train Accuracy: 0.5326, Validation Accuracy: 0.5471, Loss: 1.0740\n",
      "Epoch   1 Batch  122/269 - Train Accuracy: 0.5407, Validation Accuracy: 0.5551, Loss: 1.0704\n",
      "Epoch   1 Batch  123/269 - Train Accuracy: 0.5187, Validation Accuracy: 0.5534, Loss: 1.1343\n",
      "Epoch   1 Batch  124/269 - Train Accuracy: 0.5495, Validation Accuracy: 0.5557, Loss: 1.0470\n",
      "Epoch   1 Batch  125/269 - Train Accuracy: 0.5516, Validation Accuracy: 0.5581, Loss: 1.0508\n",
      "Epoch   1 Batch  126/269 - Train Accuracy: 0.5523, Validation Accuracy: 0.5606, Loss: 1.0498\n",
      "Epoch   1 Batch  127/269 - Train Accuracy: 0.5161, Validation Accuracy: 0.5566, Loss: 1.1166\n",
      "Epoch   1 Batch  128/269 - Train Accuracy: 0.5565, Validation Accuracy: 0.5587, Loss: 1.0690\n",
      "Epoch   1 Batch  129/269 - Train Accuracy: 0.5288, Validation Accuracy: 0.5539, Loss: 1.0827\n",
      "Epoch   1 Batch  130/269 - Train Accuracy: 0.5097, Validation Accuracy: 0.5530, Loss: 1.1288\n",
      "Epoch   1 Batch  131/269 - Train Accuracy: 0.5217, Validation Accuracy: 0.5534, Loss: 1.0960\n",
      "Epoch   1 Batch  132/269 - Train Accuracy: 0.5406, Validation Accuracy: 0.5547, Loss: 1.0691\n",
      "Epoch   1 Batch  133/269 - Train Accuracy: 0.5434, Validation Accuracy: 0.5548, Loss: 1.0330\n",
      "Epoch   1 Batch  134/269 - Train Accuracy: 0.5141, Validation Accuracy: 0.5573, Loss: 1.1024\n",
      "Epoch   1 Batch  135/269 - Train Accuracy: 0.5143, Validation Accuracy: 0.5629, Loss: 1.1250\n",
      "Epoch   1 Batch  136/269 - Train Accuracy: 0.5158, Validation Accuracy: 0.5634, Loss: 1.1198\n",
      "Epoch   1 Batch  137/269 - Train Accuracy: 0.5340, Validation Accuracy: 0.5636, Loss: 1.1020\n",
      "Epoch   1 Batch  138/269 - Train Accuracy: 0.5326, Validation Accuracy: 0.5561, Loss: 1.0661\n",
      "Epoch   1 Batch  139/269 - Train Accuracy: 0.5616, Validation Accuracy: 0.5517, Loss: 1.0224\n",
      "Epoch   1 Batch  140/269 - Train Accuracy: 0.5597, Validation Accuracy: 0.5590, Loss: 1.0521\n",
      "Epoch   1 Batch  141/269 - Train Accuracy: 0.5462, Validation Accuracy: 0.5610, Loss: 1.0652\n",
      "Epoch   1 Batch  142/269 - Train Accuracy: 0.5449, Validation Accuracy: 0.5610, Loss: 1.0207\n",
      "Epoch   1 Batch  143/269 - Train Accuracy: 0.5509, Validation Accuracy: 0.5535, Loss: 1.0390\n",
      "Epoch   1 Batch  144/269 - Train Accuracy: 0.5414, Validation Accuracy: 0.5579, Loss: 1.0230\n",
      "Epoch   1 Batch  145/269 - Train Accuracy: 0.5293, Validation Accuracy: 0.5524, Loss: 1.0233\n",
      "Epoch   1 Batch  146/269 - Train Accuracy: 0.5266, Validation Accuracy: 0.5463, Loss: 1.0256\n",
      "Epoch   1 Batch  147/269 - Train Accuracy: 0.5639, Validation Accuracy: 0.5509, Loss: 0.9860\n",
      "Epoch   1 Batch  148/269 - Train Accuracy: 0.5224, Validation Accuracy: 0.5542, Loss: 1.0607\n",
      "Epoch   1 Batch  149/269 - Train Accuracy: 0.5561, Validation Accuracy: 0.5598, Loss: 1.0268\n",
      "Epoch   1 Batch  150/269 - Train Accuracy: 0.5437, Validation Accuracy: 0.5624, Loss: 1.0414\n",
      "Epoch   1 Batch  151/269 - Train Accuracy: 0.5776, Validation Accuracy: 0.5617, Loss: 0.9904\n",
      "Epoch   1 Batch  152/269 - Train Accuracy: 0.5328, Validation Accuracy: 0.5574, Loss: 1.0217\n",
      "Epoch   1 Batch  153/269 - Train Accuracy: 0.5432, Validation Accuracy: 0.5566, Loss: 1.0055\n",
      "Epoch   1 Batch  154/269 - Train Accuracy: 0.5096, Validation Accuracy: 0.5523, Loss: 1.0548\n",
      "Epoch   1 Batch  155/269 - Train Accuracy: 0.5675, Validation Accuracy: 0.5544, Loss: 0.9573\n",
      "Epoch   1 Batch  156/269 - Train Accuracy: 0.5239, Validation Accuracy: 0.5563, Loss: 1.0500\n",
      "Epoch   1 Batch  157/269 - Train Accuracy: 0.5475, Validation Accuracy: 0.5622, Loss: 1.0140\n",
      "Epoch   1 Batch  158/269 - Train Accuracy: 0.5518, Validation Accuracy: 0.5630, Loss: 1.0007\n",
      "Epoch   1 Batch  159/269 - Train Accuracy: 0.5497, Validation Accuracy: 0.5599, Loss: 1.0132\n",
      "Epoch   1 Batch  160/269 - Train Accuracy: 0.5395, Validation Accuracy: 0.5561, Loss: 1.0134\n",
      "Epoch   1 Batch  161/269 - Train Accuracy: 0.5314, Validation Accuracy: 0.5485, Loss: 1.0119\n",
      "Epoch   1 Batch  162/269 - Train Accuracy: 0.5264, Validation Accuracy: 0.5498, Loss: 0.9993\n",
      "Epoch   1 Batch  163/269 - Train Accuracy: 0.5460, Validation Accuracy: 0.5538, Loss: 0.9912\n",
      "Epoch   1 Batch  164/269 - Train Accuracy: 0.5460, Validation Accuracy: 0.5558, Loss: 0.9934\n",
      "Epoch   1 Batch  165/269 - Train Accuracy: 0.5143, Validation Accuracy: 0.5589, Loss: 1.0207\n",
      "Epoch   1 Batch  166/269 - Train Accuracy: 0.5637, Validation Accuracy: 0.5628, Loss: 0.9465\n",
      "Epoch   1 Batch  167/269 - Train Accuracy: 0.5467, Validation Accuracy: 0.5614, Loss: 0.9963\n",
      "Epoch   1 Batch  168/269 - Train Accuracy: 0.5379, Validation Accuracy: 0.5604, Loss: 1.0064\n",
      "Epoch   1 Batch  169/269 - Train Accuracy: 0.5331, Validation Accuracy: 0.5568, Loss: 0.9931\n",
      "Epoch   1 Batch  170/269 - Train Accuracy: 0.5403, Validation Accuracy: 0.5540, Loss: 0.9834\n",
      "Epoch   1 Batch  171/269 - Train Accuracy: 0.5271, Validation Accuracy: 0.5542, Loss: 1.0222\n",
      "Epoch   1 Batch  172/269 - Train Accuracy: 0.5391, Validation Accuracy: 0.5542, Loss: 0.9997\n",
      "Epoch   1 Batch  173/269 - Train Accuracy: 0.5379, Validation Accuracy: 0.5518, Loss: 0.9802\n",
      "Epoch   1 Batch  174/269 - Train Accuracy: 0.5275, Validation Accuracy: 0.5492, Loss: 0.9830\n",
      "Epoch   1 Batch  175/269 - Train Accuracy: 0.5416, Validation Accuracy: 0.5565, Loss: 0.9956\n",
      "Epoch   1 Batch  176/269 - Train Accuracy: 0.5294, Validation Accuracy: 0.5597, Loss: 1.0335\n",
      "Epoch   1 Batch  177/269 - Train Accuracy: 0.5480, Validation Accuracy: 0.5557, Loss: 0.9456\n",
      "Epoch   1 Batch  178/269 - Train Accuracy: 0.5146, Validation Accuracy: 0.5510, Loss: 1.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 Batch  179/269 - Train Accuracy: 0.5423, Validation Accuracy: 0.5517, Loss: 0.9813\n",
      "Epoch   1 Batch  180/269 - Train Accuracy: 0.5352, Validation Accuracy: 0.5509, Loss: 0.9512\n",
      "Epoch   1 Batch  181/269 - Train Accuracy: 0.5281, Validation Accuracy: 0.5556, Loss: 0.9777\n",
      "Epoch   1 Batch  182/269 - Train Accuracy: 0.5437, Validation Accuracy: 0.5563, Loss: 0.9820\n",
      "Epoch   1 Batch  183/269 - Train Accuracy: 0.6103, Validation Accuracy: 0.5558, Loss: 0.8380\n",
      "Epoch   1 Batch  184/269 - Train Accuracy: 0.5192, Validation Accuracy: 0.5579, Loss: 1.0053\n",
      "Epoch   1 Batch  185/269 - Train Accuracy: 0.5585, Validation Accuracy: 0.5599, Loss: 0.9616\n",
      "Epoch   1 Batch  186/269 - Train Accuracy: 0.5187, Validation Accuracy: 0.5566, Loss: 0.9923\n",
      "Epoch   1 Batch  187/269 - Train Accuracy: 0.5419, Validation Accuracy: 0.5524, Loss: 0.9505\n",
      "Epoch   1 Batch  188/269 - Train Accuracy: 0.5576, Validation Accuracy: 0.5581, Loss: 0.9304\n",
      "Epoch   1 Batch  189/269 - Train Accuracy: 0.5503, Validation Accuracy: 0.5616, Loss: 0.9452\n",
      "Epoch   1 Batch  190/269 - Train Accuracy: 0.5331, Validation Accuracy: 0.5592, Loss: 0.9403\n",
      "Epoch   1 Batch  191/269 - Train Accuracy: 0.5490, Validation Accuracy: 0.5627, Loss: 0.9530\n",
      "Epoch   1 Batch  192/269 - Train Accuracy: 0.5466, Validation Accuracy: 0.5631, Loss: 0.9618\n",
      "Epoch   1 Batch  193/269 - Train Accuracy: 0.5419, Validation Accuracy: 0.5623, Loss: 0.9549\n",
      "Epoch   1 Batch  194/269 - Train Accuracy: 0.5572, Validation Accuracy: 0.5639, Loss: 0.9630\n",
      "Epoch   1 Batch  195/269 - Train Accuracy: 0.5366, Validation Accuracy: 0.5656, Loss: 0.9654\n",
      "Epoch   1 Batch  196/269 - Train Accuracy: 0.5349, Validation Accuracy: 0.5613, Loss: 0.9446\n",
      "Epoch   1 Batch  197/269 - Train Accuracy: 0.5153, Validation Accuracy: 0.5594, Loss: 0.9862\n",
      "Epoch   1 Batch  198/269 - Train Accuracy: 0.5118, Validation Accuracy: 0.5581, Loss: 1.0067\n",
      "Epoch   1 Batch  199/269 - Train Accuracy: 0.5352, Validation Accuracy: 0.5608, Loss: 0.9650\n",
      "Epoch   1 Batch  200/269 - Train Accuracy: 0.5353, Validation Accuracy: 0.5629, Loss: 0.9693\n",
      "Epoch   1 Batch  201/269 - Train Accuracy: 0.5393, Validation Accuracy: 0.5642, Loss: 0.9432\n",
      "Epoch   1 Batch  202/269 - Train Accuracy: 0.5465, Validation Accuracy: 0.5646, Loss: 0.9450\n",
      "Epoch   1 Batch  203/269 - Train Accuracy: 0.5252, Validation Accuracy: 0.5659, Loss: 0.9935\n",
      "Epoch   1 Batch  204/269 - Train Accuracy: 0.5265, Validation Accuracy: 0.5640, Loss: 0.9801\n",
      "Epoch   1 Batch  205/269 - Train Accuracy: 0.5299, Validation Accuracy: 0.5634, Loss: 0.9355\n",
      "Epoch   1 Batch  206/269 - Train Accuracy: 0.5268, Validation Accuracy: 0.5698, Loss: 0.9849\n",
      "Epoch   1 Batch  207/269 - Train Accuracy: 0.5740, Validation Accuracy: 0.5634, Loss: 0.9069\n",
      "Epoch   1 Batch  208/269 - Train Accuracy: 0.5159, Validation Accuracy: 0.5606, Loss: 0.9978\n",
      "Epoch   1 Batch  209/269 - Train Accuracy: 0.5248, Validation Accuracy: 0.5673, Loss: 0.9575\n",
      "Epoch   1 Batch  210/269 - Train Accuracy: 0.5645, Validation Accuracy: 0.5713, Loss: 0.9144\n",
      "Epoch   1 Batch  211/269 - Train Accuracy: 0.5518, Validation Accuracy: 0.5666, Loss: 0.9359\n",
      "Epoch   1 Batch  212/269 - Train Accuracy: 0.5689, Validation Accuracy: 0.5641, Loss: 0.9129\n",
      "Epoch   1 Batch  213/269 - Train Accuracy: 0.5605, Validation Accuracy: 0.5637, Loss: 0.9135\n",
      "Epoch   1 Batch  214/269 - Train Accuracy: 0.5600, Validation Accuracy: 0.5662, Loss: 0.9163\n",
      "Epoch   1 Batch  215/269 - Train Accuracy: 0.5738, Validation Accuracy: 0.5663, Loss: 0.8713\n",
      "Epoch   1 Batch  216/269 - Train Accuracy: 0.5207, Validation Accuracy: 0.5669, Loss: 1.0062\n",
      "Epoch   1 Batch  217/269 - Train Accuracy: 0.5333, Validation Accuracy: 0.5698, Loss: 0.9618\n",
      "Epoch   1 Batch  218/269 - Train Accuracy: 0.5374, Validation Accuracy: 0.5688, Loss: 0.9706\n",
      "Epoch   1 Batch  219/269 - Train Accuracy: 0.5379, Validation Accuracy: 0.5656, Loss: 0.9555\n",
      "Epoch   1 Batch  220/269 - Train Accuracy: 0.5547, Validation Accuracy: 0.5663, Loss: 0.8757\n",
      "Epoch   1 Batch  221/269 - Train Accuracy: 0.5615, Validation Accuracy: 0.5677, Loss: 0.9139\n",
      "Epoch   1 Batch  222/269 - Train Accuracy: 0.5560, Validation Accuracy: 0.5669, Loss: 0.8899\n",
      "Epoch   1 Batch  223/269 - Train Accuracy: 0.5487, Validation Accuracy: 0.5650, Loss: 0.8907\n",
      "Epoch   1 Batch  224/269 - Train Accuracy: 0.5627, Validation Accuracy: 0.5643, Loss: 0.9420\n",
      "Epoch   1 Batch  225/269 - Train Accuracy: 0.5424, Validation Accuracy: 0.5706, Loss: 0.9388\n",
      "Epoch   1 Batch  226/269 - Train Accuracy: 0.5468, Validation Accuracy: 0.5685, Loss: 0.9162\n",
      "Epoch   1 Batch  227/269 - Train Accuracy: 0.6073, Validation Accuracy: 0.5664, Loss: 0.8005\n",
      "Epoch   1 Batch  228/269 - Train Accuracy: 0.5375, Validation Accuracy: 0.5669, Loss: 0.9141\n",
      "Epoch   1 Batch  229/269 - Train Accuracy: 0.5469, Validation Accuracy: 0.5695, Loss: 0.9015\n",
      "Epoch   1 Batch  230/269 - Train Accuracy: 0.5446, Validation Accuracy: 0.5710, Loss: 0.9091\n",
      "Epoch   1 Batch  231/269 - Train Accuracy: 0.5211, Validation Accuracy: 0.5692, Loss: 0.9576\n",
      "Epoch   1 Batch  232/269 - Train Accuracy: 0.5271, Validation Accuracy: 0.5699, Loss: 0.9472\n",
      "Epoch   1 Batch  233/269 - Train Accuracy: 0.5597, Validation Accuracy: 0.5697, Loss: 0.9085\n",
      "Epoch   1 Batch  234/269 - Train Accuracy: 0.5569, Validation Accuracy: 0.5748, Loss: 0.9091\n",
      "Epoch   1 Batch  235/269 - Train Accuracy: 0.5630, Validation Accuracy: 0.5757, Loss: 0.9034\n",
      "Epoch   1 Batch  236/269 - Train Accuracy: 0.5492, Validation Accuracy: 0.5764, Loss: 0.8961\n",
      "Epoch   1 Batch  237/269 - Train Accuracy: 0.5539, Validation Accuracy: 0.5757, Loss: 0.8879\n",
      "Epoch   1 Batch  238/269 - Train Accuracy: 0.5694, Validation Accuracy: 0.5753, Loss: 0.8968\n",
      "Epoch   1 Batch  239/269 - Train Accuracy: 0.5687, Validation Accuracy: 0.5738, Loss: 0.8803\n",
      "Epoch   1 Batch  240/269 - Train Accuracy: 0.5832, Validation Accuracy: 0.5729, Loss: 0.8270\n",
      "Epoch   1 Batch  241/269 - Train Accuracy: 0.5518, Validation Accuracy: 0.5741, Loss: 0.9030\n",
      "Epoch   1 Batch  242/269 - Train Accuracy: 0.5415, Validation Accuracy: 0.5754, Loss: 0.8892\n",
      "Epoch   1 Batch  243/269 - Train Accuracy: 0.5887, Validation Accuracy: 0.5748, Loss: 0.8617\n",
      "Epoch   1 Batch  244/269 - Train Accuracy: 0.5554, Validation Accuracy: 0.5708, Loss: 0.8855\n",
      "Epoch   1 Batch  245/269 - Train Accuracy: 0.5458, Validation Accuracy: 0.5740, Loss: 0.9394\n",
      "Epoch   1 Batch  246/269 - Train Accuracy: 0.5508, Validation Accuracy: 0.5756, Loss: 0.9010\n",
      "Epoch   1 Batch  247/269 - Train Accuracy: 0.5475, Validation Accuracy: 0.5757, Loss: 0.9256\n",
      "Epoch   1 Batch  248/269 - Train Accuracy: 0.5574, Validation Accuracy: 0.5758, Loss: 0.8831\n",
      "Epoch   1 Batch  249/269 - Train Accuracy: 0.5918, Validation Accuracy: 0.5767, Loss: 0.8422\n",
      "Epoch   1 Batch  250/269 - Train Accuracy: 0.5401, Validation Accuracy: 0.5783, Loss: 0.9098\n",
      "Epoch   1 Batch  251/269 - Train Accuracy: 0.5736, Validation Accuracy: 0.5760, Loss: 0.8695\n",
      "Epoch   1 Batch  252/269 - Train Accuracy: 0.5592, Validation Accuracy: 0.5743, Loss: 0.8842\n",
      "Epoch   1 Batch  253/269 - Train Accuracy: 0.5500, Validation Accuracy: 0.5740, Loss: 0.8860\n",
      "Epoch   1 Batch  254/269 - Train Accuracy: 0.5717, Validation Accuracy: 0.5744, Loss: 0.8647\n",
      "Epoch   1 Batch  255/269 - Train Accuracy: 0.5863, Validation Accuracy: 0.5778, Loss: 0.8409\n",
      "Epoch   1 Batch  256/269 - Train Accuracy: 0.5499, Validation Accuracy: 0.5764, Loss: 0.8895\n",
      "Epoch   1 Batch  257/269 - Train Accuracy: 0.5554, Validation Accuracy: 0.5781, Loss: 0.8888\n",
      "Epoch   1 Batch  258/269 - Train Accuracy: 0.5531, Validation Accuracy: 0.5798, Loss: 0.8738\n",
      "Epoch   1 Batch  259/269 - Train Accuracy: 0.5863, Validation Accuracy: 0.5794, Loss: 0.8765\n",
      "Epoch   1 Batch  260/269 - Train Accuracy: 0.5554, Validation Accuracy: 0.5791, Loss: 0.9180\n",
      "Epoch   1 Batch  261/269 - Train Accuracy: 0.5183, Validation Accuracy: 0.5793, Loss: 0.9223\n",
      "Epoch   1 Batch  262/269 - Train Accuracy: 0.5672, Validation Accuracy: 0.5788, Loss: 0.8731\n",
      "Epoch   1 Batch  263/269 - Train Accuracy: 0.5536, Validation Accuracy: 0.5779, Loss: 0.9054\n",
      "Epoch   1 Batch  264/269 - Train Accuracy: 0.5455, Validation Accuracy: 0.5810, Loss: 0.9133\n",
      "Epoch   1 Batch  265/269 - Train Accuracy: 0.5479, Validation Accuracy: 0.5808, Loss: 0.8852\n",
      "Epoch   1 Batch  266/269 - Train Accuracy: 0.5715, Validation Accuracy: 0.5771, Loss: 0.8559\n",
      "Epoch   1 Batch  267/269 - Train Accuracy: 0.5650, Validation Accuracy: 0.5747, Loss: 0.8807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2 Batch    1/269 - Train Accuracy: 0.5399, Validation Accuracy: 0.5803, Loss: 0.8897\n",
      "Epoch   2 Batch    2/269 - Train Accuracy: 0.5455, Validation Accuracy: 0.5802, Loss: 0.8744\n",
      "Epoch   2 Batch    3/269 - Train Accuracy: 0.5464, Validation Accuracy: 0.5807, Loss: 0.8934\n",
      "Epoch   2 Batch    4/269 - Train Accuracy: 0.5515, Validation Accuracy: 0.5790, Loss: 0.8925\n",
      "Epoch   2 Batch    5/269 - Train Accuracy: 0.5346, Validation Accuracy: 0.5756, Loss: 0.9010\n",
      "Epoch   2 Batch    6/269 - Train Accuracy: 0.5694, Validation Accuracy: 0.5769, Loss: 0.8230\n",
      "Epoch   2 Batch    7/269 - Train Accuracy: 0.5636, Validation Accuracy: 0.5759, Loss: 0.8451\n",
      "Epoch   2 Batch    8/269 - Train Accuracy: 0.5398, Validation Accuracy: 0.5737, Loss: 0.8947\n",
      "Epoch   2 Batch    9/269 - Train Accuracy: 0.5495, Validation Accuracy: 0.5757, Loss: 0.8696\n",
      "Epoch   2 Batch   10/269 - Train Accuracy: 0.5457, Validation Accuracy: 0.5737, Loss: 0.8694\n",
      "Epoch   2 Batch   11/269 - Train Accuracy: 0.5480, Validation Accuracy: 0.5758, Loss: 0.8660\n",
      "Epoch   2 Batch   12/269 - Train Accuracy: 0.5438, Validation Accuracy: 0.5833, Loss: 0.8890\n",
      "Epoch   2 Batch   13/269 - Train Accuracy: 0.6001, Validation Accuracy: 0.5851, Loss: 0.7988\n",
      "Epoch   2 Batch   14/269 - Train Accuracy: 0.5676, Validation Accuracy: 0.5801, Loss: 0.8528\n",
      "Epoch   2 Batch   15/269 - Train Accuracy: 0.5550, Validation Accuracy: 0.5779, Loss: 0.8344\n",
      "Epoch   2 Batch   16/269 - Train Accuracy: 0.5773, Validation Accuracy: 0.5756, Loss: 0.8410\n",
      "Epoch   2 Batch   17/269 - Train Accuracy: 0.5563, Validation Accuracy: 0.5712, Loss: 0.8323\n",
      "Epoch   2 Batch   18/269 - Train Accuracy: 0.5443, Validation Accuracy: 0.5758, Loss: 0.8635\n",
      "Epoch   2 Batch   19/269 - Train Accuracy: 0.5970, Validation Accuracy: 0.5803, Loss: 0.7953\n",
      "Epoch   2 Batch   20/269 - Train Accuracy: 0.5508, Validation Accuracy: 0.5817, Loss: 0.8672\n",
      "Epoch   2 Batch   21/269 - Train Accuracy: 0.5623, Validation Accuracy: 0.5833, Loss: 0.8991\n",
      "Epoch   2 Batch   22/269 - Train Accuracy: 0.5805, Validation Accuracy: 0.5904, Loss: 0.8261\n",
      "Epoch   2 Batch   23/269 - Train Accuracy: 0.5916, Validation Accuracy: 0.5941, Loss: 0.8503\n",
      "Epoch   2 Batch   24/269 - Train Accuracy: 0.5751, Validation Accuracy: 0.5945, Loss: 0.8724\n",
      "Epoch   2 Batch   25/269 - Train Accuracy: 0.5637, Validation Accuracy: 0.5932, Loss: 0.8864\n",
      "Epoch   2 Batch   26/269 - Train Accuracy: 0.6270, Validation Accuracy: 0.6011, Loss: 0.7850\n",
      "Epoch   2 Batch   27/269 - Train Accuracy: 0.5786, Validation Accuracy: 0.6002, Loss: 0.8316\n",
      "Epoch   2 Batch   28/269 - Train Accuracy: 0.5484, Validation Accuracy: 0.5966, Loss: 0.8828\n",
      "Epoch   2 Batch   29/269 - Train Accuracy: 0.5702, Validation Accuracy: 0.5907, Loss: 0.8469\n",
      "Epoch   2 Batch   30/269 - Train Accuracy: 0.5841, Validation Accuracy: 0.5920, Loss: 0.8182\n",
      "Epoch   2 Batch   31/269 - Train Accuracy: 0.5826, Validation Accuracy: 0.5914, Loss: 0.8213\n",
      "Epoch   2 Batch   32/269 - Train Accuracy: 0.5728, Validation Accuracy: 0.5927, Loss: 0.8207\n",
      "Epoch   2 Batch   33/269 - Train Accuracy: 0.5857, Validation Accuracy: 0.5914, Loss: 0.8000\n",
      "Epoch   2 Batch   34/269 - Train Accuracy: 0.5830, Validation Accuracy: 0.5923, Loss: 0.8285\n",
      "Epoch   2 Batch   35/269 - Train Accuracy: 0.6028, Validation Accuracy: 0.5943, Loss: 0.8305\n",
      "Epoch   2 Batch   36/269 - Train Accuracy: 0.5854, Validation Accuracy: 0.5965, Loss: 0.8300\n",
      "Epoch   2 Batch   37/269 - Train Accuracy: 0.5915, Validation Accuracy: 0.5893, Loss: 0.8258\n",
      "Epoch   2 Batch   38/269 - Train Accuracy: 0.5737, Validation Accuracy: 0.5882, Loss: 0.8265\n",
      "Epoch   2 Batch   39/269 - Train Accuracy: 0.5868, Validation Accuracy: 0.5941, Loss: 0.8143\n",
      "Epoch   2 Batch   40/269 - Train Accuracy: 0.5901, Validation Accuracy: 0.6011, Loss: 0.8511\n",
      "Epoch   2 Batch   41/269 - Train Accuracy: 0.5832, Validation Accuracy: 0.5965, Loss: 0.8283\n",
      "Epoch   2 Batch   42/269 - Train Accuracy: 0.6181, Validation Accuracy: 0.5971, Loss: 0.7831\n",
      "Epoch   2 Batch   43/269 - Train Accuracy: 0.5813, Validation Accuracy: 0.6025, Loss: 0.8561\n",
      "Epoch   2 Batch   44/269 - Train Accuracy: 0.6062, Validation Accuracy: 0.6017, Loss: 0.8221\n",
      "Epoch   2 Batch   45/269 - Train Accuracy: 0.5760, Validation Accuracy: 0.5874, Loss: 0.8584\n",
      "Epoch   2 Batch   46/269 - Train Accuracy: 0.5868, Validation Accuracy: 0.6009, Loss: 0.8495\n",
      "Epoch   2 Batch   47/269 - Train Accuracy: 0.6270, Validation Accuracy: 0.6043, Loss: 0.7583\n",
      "Epoch   2 Batch   48/269 - Train Accuracy: 0.6007, Validation Accuracy: 0.6012, Loss: 0.7980\n",
      "Epoch   2 Batch   49/269 - Train Accuracy: 0.5744, Validation Accuracy: 0.5974, Loss: 0.8333\n",
      "Epoch   2 Batch   50/269 - Train Accuracy: 0.5822, Validation Accuracy: 0.5991, Loss: 0.8484\n",
      "Epoch   2 Batch   51/269 - Train Accuracy: 0.5836, Validation Accuracy: 0.5953, Loss: 0.8209\n",
      "Epoch   2 Batch   52/269 - Train Accuracy: 0.5815, Validation Accuracy: 0.5935, Loss: 0.7854\n",
      "Epoch   2 Batch   53/269 - Train Accuracy: 0.5587, Validation Accuracy: 0.5910, Loss: 0.8524\n",
      "Epoch   2 Batch   54/269 - Train Accuracy: 0.5655, Validation Accuracy: 0.5954, Loss: 0.8457\n",
      "Epoch   2 Batch   55/269 - Train Accuracy: 0.6044, Validation Accuracy: 0.6046, Loss: 0.7972\n",
      "Epoch   2 Batch   56/269 - Train Accuracy: 0.6087, Validation Accuracy: 0.6061, Loss: 0.8142\n",
      "Epoch   2 Batch   57/269 - Train Accuracy: 0.6022, Validation Accuracy: 0.6075, Loss: 0.8178\n",
      "Epoch   2 Batch   58/269 - Train Accuracy: 0.6123, Validation Accuracy: 0.6117, Loss: 0.8009\n",
      "Epoch   2 Batch   59/269 - Train Accuracy: 0.6112, Validation Accuracy: 0.6057, Loss: 0.7721\n",
      "Epoch   2 Batch   60/269 - Train Accuracy: 0.6172, Validation Accuracy: 0.6095, Loss: 0.7667\n",
      "Epoch   2 Batch   61/269 - Train Accuracy: 0.6253, Validation Accuracy: 0.6114, Loss: 0.7534\n",
      "Epoch   2 Batch   62/269 - Train Accuracy: 0.6148, Validation Accuracy: 0.6118, Loss: 0.7733\n",
      "Epoch   2 Batch   63/269 - Train Accuracy: 0.5954, Validation Accuracy: 0.6104, Loss: 0.8009\n",
      "Epoch   2 Batch   64/269 - Train Accuracy: 0.5902, Validation Accuracy: 0.6078, Loss: 0.7867\n",
      "Epoch   2 Batch   65/269 - Train Accuracy: 0.6046, Validation Accuracy: 0.6095, Loss: 0.7890\n",
      "Epoch   2 Batch   66/269 - Train Accuracy: 0.6115, Validation Accuracy: 0.6066, Loss: 0.7753\n",
      "Epoch   2 Batch   67/269 - Train Accuracy: 0.6055, Validation Accuracy: 0.6125, Loss: 0.8064\n",
      "Epoch   2 Batch   68/269 - Train Accuracy: 0.5938, Validation Accuracy: 0.6096, Loss: 0.8003\n",
      "Epoch   2 Batch   69/269 - Train Accuracy: 0.5775, Validation Accuracy: 0.6035, Loss: 0.8702\n",
      "Epoch   2 Batch   70/269 - Train Accuracy: 0.6244, Validation Accuracy: 0.6089, Loss: 0.7988\n",
      "Epoch   2 Batch   71/269 - Train Accuracy: 0.5947, Validation Accuracy: 0.6113, Loss: 0.8197\n",
      "Epoch   2 Batch   72/269 - Train Accuracy: 0.6162, Validation Accuracy: 0.6071, Loss: 0.7823\n",
      "Epoch   2 Batch   73/269 - Train Accuracy: 0.5994, Validation Accuracy: 0.6063, Loss: 0.8097\n",
      "Epoch   2 Batch   74/269 - Train Accuracy: 0.5997, Validation Accuracy: 0.6075, Loss: 0.8033\n",
      "Epoch   2 Batch   75/269 - Train Accuracy: 0.5999, Validation Accuracy: 0.6084, Loss: 0.7844\n",
      "Epoch   2 Batch   76/269 - Train Accuracy: 0.5944, Validation Accuracy: 0.6092, Loss: 0.8083\n",
      "Epoch   2 Batch   77/269 - Train Accuracy: 0.6294, Validation Accuracy: 0.6099, Loss: 0.7884\n",
      "Epoch   2 Batch   78/269 - Train Accuracy: 0.6096, Validation Accuracy: 0.6143, Loss: 0.7783\n",
      "Epoch   2 Batch   79/269 - Train Accuracy: 0.6105, Validation Accuracy: 0.6132, Loss: 0.7791\n",
      "Epoch   2 Batch   80/269 - Train Accuracy: 0.6174, Validation Accuracy: 0.6157, Loss: 0.7769\n",
      "Epoch   2 Batch   81/269 - Train Accuracy: 0.6192, Validation Accuracy: 0.6191, Loss: 0.8021\n",
      "Epoch   2 Batch   82/269 - Train Accuracy: 0.6202, Validation Accuracy: 0.6154, Loss: 0.7520\n",
      "Epoch   2 Batch   83/269 - Train Accuracy: 0.6110, Validation Accuracy: 0.6149, Loss: 0.7846\n",
      "Epoch   2 Batch   84/269 - Train Accuracy: 0.6231, Validation Accuracy: 0.6156, Loss: 0.7640\n",
      "Epoch   2 Batch   85/269 - Train Accuracy: 0.5963, Validation Accuracy: 0.6175, Loss: 0.7841\n",
      "Epoch   2 Batch   86/269 - Train Accuracy: 0.5831, Validation Accuracy: 0.6143, Loss: 0.7758\n",
      "Epoch   2 Batch   87/269 - Train Accuracy: 0.5889, Validation Accuracy: 0.6143, Loss: 0.8348\n",
      "Epoch   2 Batch   88/269 - Train Accuracy: 0.5975, Validation Accuracy: 0.6127, Loss: 0.7865\n",
      "Epoch   2 Batch   89/269 - Train Accuracy: 0.6228, Validation Accuracy: 0.6108, Loss: 0.7792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2 Batch   90/269 - Train Accuracy: 0.5729, Validation Accuracy: 0.6125, Loss: 0.8311\n",
      "Epoch   2 Batch   91/269 - Train Accuracy: 0.6099, Validation Accuracy: 0.6169, Loss: 0.7591\n",
      "Epoch   2 Batch   92/269 - Train Accuracy: 0.6092, Validation Accuracy: 0.6129, Loss: 0.7674\n",
      "Epoch   2 Batch   93/269 - Train Accuracy: 0.6209, Validation Accuracy: 0.6147, Loss: 0.7415\n",
      "Epoch   2 Batch   94/269 - Train Accuracy: 0.6087, Validation Accuracy: 0.6072, Loss: 0.7969\n",
      "Epoch   2 Batch   95/269 - Train Accuracy: 0.6025, Validation Accuracy: 0.6096, Loss: 0.7785\n",
      "Epoch   2 Batch   96/269 - Train Accuracy: 0.6071, Validation Accuracy: 0.6127, Loss: 0.7719\n",
      "Epoch   2 Batch   97/269 - Train Accuracy: 0.6064, Validation Accuracy: 0.6186, Loss: 0.7710\n",
      "Epoch   2 Batch   98/269 - Train Accuracy: 0.6175, Validation Accuracy: 0.6168, Loss: 0.7657\n",
      "Epoch   2 Batch   99/269 - Train Accuracy: 0.5978, Validation Accuracy: 0.6080, Loss: 0.8023\n",
      "Epoch   2 Batch  100/269 - Train Accuracy: 0.6268, Validation Accuracy: 0.6151, Loss: 0.7581\n",
      "Epoch   2 Batch  101/269 - Train Accuracy: 0.5835, Validation Accuracy: 0.6160, Loss: 0.8107\n",
      "Epoch   2 Batch  102/269 - Train Accuracy: 0.6092, Validation Accuracy: 0.6101, Loss: 0.7690\n",
      "Epoch   2 Batch  103/269 - Train Accuracy: 0.6174, Validation Accuracy: 0.6188, Loss: 0.7727\n",
      "Epoch   2 Batch  104/269 - Train Accuracy: 0.6030, Validation Accuracy: 0.6186, Loss: 0.7600\n",
      "Epoch   2 Batch  105/269 - Train Accuracy: 0.6006, Validation Accuracy: 0.6146, Loss: 0.7825\n",
      "Epoch   2 Batch  106/269 - Train Accuracy: 0.5991, Validation Accuracy: 0.6119, Loss: 0.7636\n",
      "Epoch   2 Batch  107/269 - Train Accuracy: 0.5879, Validation Accuracy: 0.6162, Loss: 0.8076\n",
      "Epoch   2 Batch  108/269 - Train Accuracy: 0.6144, Validation Accuracy: 0.6155, Loss: 0.7586\n",
      "Epoch   2 Batch  109/269 - Train Accuracy: 0.5913, Validation Accuracy: 0.6185, Loss: 0.7787\n",
      "Epoch   2 Batch  110/269 - Train Accuracy: 0.6042, Validation Accuracy: 0.6169, Loss: 0.7519\n",
      "Epoch   2 Batch  111/269 - Train Accuracy: 0.5875, Validation Accuracy: 0.6135, Loss: 0.8253\n",
      "Epoch   2 Batch  112/269 - Train Accuracy: 0.6164, Validation Accuracy: 0.6125, Loss: 0.7519\n",
      "Epoch   2 Batch  113/269 - Train Accuracy: 0.6195, Validation Accuracy: 0.6157, Loss: 0.7306\n",
      "Epoch   2 Batch  114/269 - Train Accuracy: 0.6050, Validation Accuracy: 0.6205, Loss: 0.7652\n",
      "Epoch   2 Batch  115/269 - Train Accuracy: 0.6002, Validation Accuracy: 0.6221, Loss: 0.7821\n",
      "Epoch   2 Batch  116/269 - Train Accuracy: 0.6128, Validation Accuracy: 0.6217, Loss: 0.7756\n",
      "Epoch   2 Batch  117/269 - Train Accuracy: 0.6150, Validation Accuracy: 0.6166, Loss: 0.7517\n",
      "Epoch   2 Batch  118/269 - Train Accuracy: 0.6348, Validation Accuracy: 0.6166, Loss: 0.7346\n",
      "Epoch   2 Batch  119/269 - Train Accuracy: 0.5911, Validation Accuracy: 0.6177, Loss: 0.7960\n",
      "Epoch   2 Batch  120/269 - Train Accuracy: 0.6066, Validation Accuracy: 0.6206, Loss: 0.7761\n",
      "Epoch   2 Batch  121/269 - Train Accuracy: 0.6143, Validation Accuracy: 0.6163, Loss: 0.7423\n",
      "Epoch   2 Batch  122/269 - Train Accuracy: 0.6156, Validation Accuracy: 0.6151, Loss: 0.7463\n",
      "Epoch   2 Batch  123/269 - Train Accuracy: 0.5893, Validation Accuracy: 0.6164, Loss: 0.7814\n",
      "Epoch   2 Batch  124/269 - Train Accuracy: 0.6104, Validation Accuracy: 0.6163, Loss: 0.7369\n",
      "Epoch   2 Batch  125/269 - Train Accuracy: 0.6216, Validation Accuracy: 0.6175, Loss: 0.7339\n",
      "Epoch   2 Batch  126/269 - Train Accuracy: 0.6192, Validation Accuracy: 0.6190, Loss: 0.7366\n",
      "Epoch   2 Batch  127/269 - Train Accuracy: 0.6109, Validation Accuracy: 0.6237, Loss: 0.7789\n",
      "Epoch   2 Batch  128/269 - Train Accuracy: 0.6283, Validation Accuracy: 0.6211, Loss: 0.7474\n",
      "Epoch   2 Batch  129/269 - Train Accuracy: 0.6053, Validation Accuracy: 0.6214, Loss: 0.7606\n",
      "Epoch   2 Batch  130/269 - Train Accuracy: 0.5889, Validation Accuracy: 0.6143, Loss: 0.7809\n",
      "Epoch   2 Batch  131/269 - Train Accuracy: 0.5943, Validation Accuracy: 0.6175, Loss: 0.7722\n",
      "Epoch   2 Batch  132/269 - Train Accuracy: 0.6121, Validation Accuracy: 0.6210, Loss: 0.7557\n",
      "Epoch   2 Batch  133/269 - Train Accuracy: 0.6192, Validation Accuracy: 0.6206, Loss: 0.7266\n",
      "Epoch   2 Batch  134/269 - Train Accuracy: 0.5975, Validation Accuracy: 0.6217, Loss: 0.7664\n",
      "Epoch   2 Batch  135/269 - Train Accuracy: 0.5938, Validation Accuracy: 0.6199, Loss: 0.7896\n",
      "Epoch   2 Batch  136/269 - Train Accuracy: 0.5860, Validation Accuracy: 0.6200, Loss: 0.7990\n",
      "Epoch   2 Batch  137/269 - Train Accuracy: 0.6037, Validation Accuracy: 0.6206, Loss: 0.7804\n",
      "Epoch   2 Batch  138/269 - Train Accuracy: 0.5988, Validation Accuracy: 0.6199, Loss: 0.7623\n",
      "Epoch   2 Batch  139/269 - Train Accuracy: 0.6230, Validation Accuracy: 0.6164, Loss: 0.7241\n",
      "Epoch   2 Batch  140/269 - Train Accuracy: 0.6234, Validation Accuracy: 0.6163, Loss: 0.7503\n",
      "Epoch   2 Batch  141/269 - Train Accuracy: 0.6195, Validation Accuracy: 0.6189, Loss: 0.7554\n",
      "Epoch   2 Batch  142/269 - Train Accuracy: 0.6136, Validation Accuracy: 0.6209, Loss: 0.7244\n",
      "Epoch   2 Batch  143/269 - Train Accuracy: 0.6188, Validation Accuracy: 0.6259, Loss: 0.7388\n",
      "Epoch   2 Batch  144/269 - Train Accuracy: 0.6257, Validation Accuracy: 0.6292, Loss: 0.7190\n",
      "Epoch   2 Batch  145/269 - Train Accuracy: 0.6210, Validation Accuracy: 0.6284, Loss: 0.7289\n",
      "Epoch   2 Batch  146/269 - Train Accuracy: 0.6158, Validation Accuracy: 0.6270, Loss: 0.7233\n",
      "Epoch   2 Batch  147/269 - Train Accuracy: 0.6412, Validation Accuracy: 0.6257, Loss: 0.7023\n",
      "Epoch   2 Batch  148/269 - Train Accuracy: 0.6128, Validation Accuracy: 0.6259, Loss: 0.7436\n",
      "Epoch   2 Batch  149/269 - Train Accuracy: 0.6147, Validation Accuracy: 0.6263, Loss: 0.7392\n",
      "Epoch   2 Batch  150/269 - Train Accuracy: 0.6196, Validation Accuracy: 0.6228, Loss: 0.7453\n",
      "Epoch   2 Batch  151/269 - Train Accuracy: 0.6447, Validation Accuracy: 0.6252, Loss: 0.7060\n",
      "Epoch   2 Batch  152/269 - Train Accuracy: 0.6215, Validation Accuracy: 0.6270, Loss: 0.7336\n",
      "Epoch   2 Batch  153/269 - Train Accuracy: 0.6292, Validation Accuracy: 0.6270, Loss: 0.7232\n",
      "Epoch   2 Batch  154/269 - Train Accuracy: 0.6089, Validation Accuracy: 0.6291, Loss: 0.7452\n",
      "Epoch   2 Batch  155/269 - Train Accuracy: 0.6539, Validation Accuracy: 0.6286, Loss: 0.6925\n",
      "Epoch   2 Batch  156/269 - Train Accuracy: 0.6055, Validation Accuracy: 0.6266, Loss: 0.7685\n",
      "Epoch   2 Batch  157/269 - Train Accuracy: 0.6156, Validation Accuracy: 0.6270, Loss: 0.7261\n",
      "Epoch   2 Batch  158/269 - Train Accuracy: 0.6230, Validation Accuracy: 0.6292, Loss: 0.7235\n",
      "Epoch   2 Batch  159/269 - Train Accuracy: 0.6217, Validation Accuracy: 0.6265, Loss: 0.7285\n",
      "Epoch   2 Batch  160/269 - Train Accuracy: 0.6194, Validation Accuracy: 0.6280, Loss: 0.7284\n",
      "Epoch   2 Batch  161/269 - Train Accuracy: 0.6157, Validation Accuracy: 0.6271, Loss: 0.7336\n",
      "Epoch   2 Batch  162/269 - Train Accuracy: 0.6179, Validation Accuracy: 0.6199, Loss: 0.7265\n",
      "Epoch   2 Batch  163/269 - Train Accuracy: 0.6290, Validation Accuracy: 0.6252, Loss: 0.7230\n",
      "Epoch   2 Batch  164/269 - Train Accuracy: 0.6263, Validation Accuracy: 0.6245, Loss: 0.7159\n",
      "Epoch   2 Batch  165/269 - Train Accuracy: 0.5911, Validation Accuracy: 0.6195, Loss: 0.7404\n",
      "Epoch   2 Batch  166/269 - Train Accuracy: 0.6415, Validation Accuracy: 0.6231, Loss: 0.6858\n",
      "Epoch   2 Batch  167/269 - Train Accuracy: 0.6127, Validation Accuracy: 0.6262, Loss: 0.7235\n",
      "Epoch   2 Batch  168/269 - Train Accuracy: 0.6096, Validation Accuracy: 0.6242, Loss: 0.7355\n",
      "Epoch   2 Batch  169/269 - Train Accuracy: 0.6124, Validation Accuracy: 0.6251, Loss: 0.7266\n",
      "Epoch   2 Batch  170/269 - Train Accuracy: 0.6229, Validation Accuracy: 0.6285, Loss: 0.7127\n",
      "Epoch   2 Batch  171/269 - Train Accuracy: 0.6177, Validation Accuracy: 0.6254, Loss: 0.7484\n",
      "Epoch   2 Batch  172/269 - Train Accuracy: 0.6185, Validation Accuracy: 0.6254, Loss: 0.7224\n",
      "Epoch   2 Batch  173/269 - Train Accuracy: 0.6239, Validation Accuracy: 0.6265, Loss: 0.7083\n",
      "Epoch   2 Batch  174/269 - Train Accuracy: 0.6068, Validation Accuracy: 0.6263, Loss: 0.7258\n",
      "Epoch   2 Batch  175/269 - Train Accuracy: 0.6236, Validation Accuracy: 0.6257, Loss: 0.7268\n",
      "Epoch   2 Batch  176/269 - Train Accuracy: 0.6045, Validation Accuracy: 0.6261, Loss: 0.7636\n",
      "Epoch   2 Batch  177/269 - Train Accuracy: 0.6312, Validation Accuracy: 0.6271, Loss: 0.6875\n",
      "Epoch   2 Batch  178/269 - Train Accuracy: 0.6095, Validation Accuracy: 0.6264, Loss: 0.7286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2 Batch  179/269 - Train Accuracy: 0.6291, Validation Accuracy: 0.6292, Loss: 0.7270\n",
      "Epoch   2 Batch  180/269 - Train Accuracy: 0.6193, Validation Accuracy: 0.6286, Loss: 0.7081\n",
      "Epoch   2 Batch  181/269 - Train Accuracy: 0.6031, Validation Accuracy: 0.6262, Loss: 0.7246\n",
      "Epoch   2 Batch  182/269 - Train Accuracy: 0.6256, Validation Accuracy: 0.6270, Loss: 0.7152\n",
      "Epoch   2 Batch  183/269 - Train Accuracy: 0.6807, Validation Accuracy: 0.6247, Loss: 0.6207\n",
      "Epoch   2 Batch  184/269 - Train Accuracy: 0.6051, Validation Accuracy: 0.6294, Loss: 0.7442\n",
      "Epoch   2 Batch  185/269 - Train Accuracy: 0.6270, Validation Accuracy: 0.6270, Loss: 0.7160\n",
      "Epoch   2 Batch  186/269 - Train Accuracy: 0.5998, Validation Accuracy: 0.6294, Loss: 0.7315\n",
      "Epoch   2 Batch  187/269 - Train Accuracy: 0.6187, Validation Accuracy: 0.6265, Loss: 0.6998\n",
      "Epoch   2 Batch  188/269 - Train Accuracy: 0.6293, Validation Accuracy: 0.6218, Loss: 0.6937\n",
      "Epoch   2 Batch  189/269 - Train Accuracy: 0.6084, Validation Accuracy: 0.6186, Loss: 0.6945\n",
      "Epoch   2 Batch  190/269 - Train Accuracy: 0.6036, Validation Accuracy: 0.6224, Loss: 0.6927\n",
      "Epoch   2 Batch  191/269 - Train Accuracy: 0.6338, Validation Accuracy: 0.6293, Loss: 0.7102\n",
      "Epoch   2 Batch  192/269 - Train Accuracy: 0.6353, Validation Accuracy: 0.6303, Loss: 0.7017\n",
      "Epoch   2 Batch  193/269 - Train Accuracy: 0.6291, Validation Accuracy: 0.6262, Loss: 0.7008\n",
      "Epoch   2 Batch  194/269 - Train Accuracy: 0.6288, Validation Accuracy: 0.6222, Loss: 0.7141\n",
      "Epoch   2 Batch  195/269 - Train Accuracy: 0.6119, Validation Accuracy: 0.6229, Loss: 0.7120\n",
      "Epoch   2 Batch  196/269 - Train Accuracy: 0.6044, Validation Accuracy: 0.6268, Loss: 0.6997\n",
      "Epoch   2 Batch  197/269 - Train Accuracy: 0.6006, Validation Accuracy: 0.6308, Loss: 0.7304\n",
      "Epoch   2 Batch  198/269 - Train Accuracy: 0.6001, Validation Accuracy: 0.6288, Loss: 0.7507\n",
      "Epoch   2 Batch  199/269 - Train Accuracy: 0.6100, Validation Accuracy: 0.6232, Loss: 0.7219\n",
      "Epoch   2 Batch  200/269 - Train Accuracy: 0.6146, Validation Accuracy: 0.6258, Loss: 0.7280\n",
      "Epoch   2 Batch  201/269 - Train Accuracy: 0.6187, Validation Accuracy: 0.6285, Loss: 0.7016\n",
      "Epoch   2 Batch  202/269 - Train Accuracy: 0.6209, Validation Accuracy: 0.6277, Loss: 0.6991\n",
      "Epoch   2 Batch  203/269 - Train Accuracy: 0.6079, Validation Accuracy: 0.6299, Loss: 0.7450\n",
      "Epoch   2 Batch  204/269 - Train Accuracy: 0.5956, Validation Accuracy: 0.6324, Loss: 0.7334\n",
      "Epoch   2 Batch  205/269 - Train Accuracy: 0.6188, Validation Accuracy: 0.6302, Loss: 0.6979\n",
      "Epoch   2 Batch  206/269 - Train Accuracy: 0.6130, Validation Accuracy: 0.6274, Loss: 0.7284\n",
      "Epoch   2 Batch  207/269 - Train Accuracy: 0.6469, Validation Accuracy: 0.6296, Loss: 0.6757\n",
      "Epoch   2 Batch  208/269 - Train Accuracy: 0.6033, Validation Accuracy: 0.6286, Loss: 0.7351\n",
      "Epoch   2 Batch  209/269 - Train Accuracy: 0.6121, Validation Accuracy: 0.6318, Loss: 0.7041\n",
      "Epoch   2 Batch  210/269 - Train Accuracy: 0.6267, Validation Accuracy: 0.6330, Loss: 0.6903\n",
      "Epoch   2 Batch  211/269 - Train Accuracy: 0.6261, Validation Accuracy: 0.6317, Loss: 0.7116\n",
      "Epoch   2 Batch  212/269 - Train Accuracy: 0.6423, Validation Accuracy: 0.6339, Loss: 0.6866\n",
      "Epoch   2 Batch  213/269 - Train Accuracy: 0.6236, Validation Accuracy: 0.6333, Loss: 0.6907\n",
      "Epoch   2 Batch  214/269 - Train Accuracy: 0.6384, Validation Accuracy: 0.6339, Loss: 0.6972\n",
      "Epoch   2 Batch  215/269 - Train Accuracy: 0.6536, Validation Accuracy: 0.6339, Loss: 0.6532\n",
      "Epoch   2 Batch  216/269 - Train Accuracy: 0.5952, Validation Accuracy: 0.6307, Loss: 0.7466\n",
      "Epoch   2 Batch  217/269 - Train Accuracy: 0.5978, Validation Accuracy: 0.6277, Loss: 0.7192\n",
      "Epoch   2 Batch  218/269 - Train Accuracy: 0.6127, Validation Accuracy: 0.6251, Loss: 0.7267\n",
      "Epoch   2 Batch  219/269 - Train Accuracy: 0.6253, Validation Accuracy: 0.6287, Loss: 0.7255\n",
      "Epoch   2 Batch  220/269 - Train Accuracy: 0.6330, Validation Accuracy: 0.6317, Loss: 0.6580\n",
      "Epoch   2 Batch  221/269 - Train Accuracy: 0.6552, Validation Accuracy: 0.6262, Loss: 0.6902\n",
      "Epoch   2 Batch  222/269 - Train Accuracy: 0.6339, Validation Accuracy: 0.6240, Loss: 0.6651\n",
      "Epoch   2 Batch  223/269 - Train Accuracy: 0.6145, Validation Accuracy: 0.6251, Loss: 0.6830\n",
      "Epoch   2 Batch  224/269 - Train Accuracy: 0.6239, Validation Accuracy: 0.6257, Loss: 0.7095\n",
      "Epoch   2 Batch  225/269 - Train Accuracy: 0.6098, Validation Accuracy: 0.6241, Loss: 0.7049\n",
      "Epoch   2 Batch  226/269 - Train Accuracy: 0.6135, Validation Accuracy: 0.6294, Loss: 0.6967\n",
      "Epoch   2 Batch  227/269 - Train Accuracy: 0.6753, Validation Accuracy: 0.6300, Loss: 0.6139\n",
      "Epoch   2 Batch  228/269 - Train Accuracy: 0.6205, Validation Accuracy: 0.6276, Loss: 0.6905\n",
      "Epoch   2 Batch  229/269 - Train Accuracy: 0.6140, Validation Accuracy: 0.6254, Loss: 0.6772\n",
      "Epoch   2 Batch  230/269 - Train Accuracy: 0.6187, Validation Accuracy: 0.6316, Loss: 0.6820\n",
      "Epoch   2 Batch  231/269 - Train Accuracy: 0.6034, Validation Accuracy: 0.6335, Loss: 0.7247\n",
      "Epoch   2 Batch  232/269 - Train Accuracy: 0.5953, Validation Accuracy: 0.6313, Loss: 0.7117\n",
      "Epoch   2 Batch  233/269 - Train Accuracy: 0.6339, Validation Accuracy: 0.6298, Loss: 0.6979\n",
      "Epoch   2 Batch  234/269 - Train Accuracy: 0.6226, Validation Accuracy: 0.6258, Loss: 0.6840\n",
      "Epoch   2 Batch  235/269 - Train Accuracy: 0.6147, Validation Accuracy: 0.6220, Loss: 0.6769\n",
      "Epoch   2 Batch  236/269 - Train Accuracy: 0.6071, Validation Accuracy: 0.6286, Loss: 0.6745\n",
      "Epoch   2 Batch  237/269 - Train Accuracy: 0.6081, Validation Accuracy: 0.6339, Loss: 0.6757\n",
      "Epoch   2 Batch  238/269 - Train Accuracy: 0.6416, Validation Accuracy: 0.6331, Loss: 0.6775\n",
      "Epoch   2 Batch  239/269 - Train Accuracy: 0.6290, Validation Accuracy: 0.6252, Loss: 0.6708\n",
      "Epoch   2 Batch  240/269 - Train Accuracy: 0.6499, Validation Accuracy: 0.6251, Loss: 0.6255\n",
      "Epoch   2 Batch  241/269 - Train Accuracy: 0.6189, Validation Accuracy: 0.6272, Loss: 0.6866\n",
      "Epoch   2 Batch  242/269 - Train Accuracy: 0.6184, Validation Accuracy: 0.6315, Loss: 0.6741\n",
      "Epoch   2 Batch  243/269 - Train Accuracy: 0.6500, Validation Accuracy: 0.6330, Loss: 0.6543\n",
      "Epoch   2 Batch  244/269 - Train Accuracy: 0.6193, Validation Accuracy: 0.6309, Loss: 0.6750\n",
      "Epoch   2 Batch  245/269 - Train Accuracy: 0.6122, Validation Accuracy: 0.6259, Loss: 0.7140\n",
      "Epoch   2 Batch  246/269 - Train Accuracy: 0.5954, Validation Accuracy: 0.6243, Loss: 0.6884\n",
      "Epoch   2 Batch  247/269 - Train Accuracy: 0.6176, Validation Accuracy: 0.6341, Loss: 0.7082\n",
      "Epoch   2 Batch  248/269 - Train Accuracy: 0.6279, Validation Accuracy: 0.6340, Loss: 0.6719\n",
      "Epoch   2 Batch  249/269 - Train Accuracy: 0.6517, Validation Accuracy: 0.6320, Loss: 0.6462\n",
      "Epoch   2 Batch  250/269 - Train Accuracy: 0.6106, Validation Accuracy: 0.6320, Loss: 0.6919\n",
      "Epoch   2 Batch  251/269 - Train Accuracy: 0.6409, Validation Accuracy: 0.6312, Loss: 0.6597\n",
      "Epoch   2 Batch  252/269 - Train Accuracy: 0.6244, Validation Accuracy: 0.6298, Loss: 0.6783\n",
      "Epoch   2 Batch  253/269 - Train Accuracy: 0.6137, Validation Accuracy: 0.6321, Loss: 0.6862\n",
      "Epoch   2 Batch  254/269 - Train Accuracy: 0.6290, Validation Accuracy: 0.6357, Loss: 0.6702\n",
      "Epoch   2 Batch  255/269 - Train Accuracy: 0.6491, Validation Accuracy: 0.6334, Loss: 0.6487\n",
      "Epoch   2 Batch  256/269 - Train Accuracy: 0.6117, Validation Accuracy: 0.6314, Loss: 0.6796\n",
      "Epoch   2 Batch  257/269 - Train Accuracy: 0.6100, Validation Accuracy: 0.6306, Loss: 0.6787\n",
      "Epoch   2 Batch  258/269 - Train Accuracy: 0.6196, Validation Accuracy: 0.6319, Loss: 0.6721\n",
      "Epoch   2 Batch  259/269 - Train Accuracy: 0.6415, Validation Accuracy: 0.6342, Loss: 0.6700\n",
      "Epoch   2 Batch  260/269 - Train Accuracy: 0.6099, Validation Accuracy: 0.6341, Loss: 0.7067\n",
      "Epoch   2 Batch  261/269 - Train Accuracy: 0.5996, Validation Accuracy: 0.6346, Loss: 0.7048\n",
      "Epoch   2 Batch  262/269 - Train Accuracy: 0.6347, Validation Accuracy: 0.6365, Loss: 0.6639\n",
      "Epoch   2 Batch  263/269 - Train Accuracy: 0.6194, Validation Accuracy: 0.6342, Loss: 0.6948\n",
      "Epoch   2 Batch  264/269 - Train Accuracy: 0.6062, Validation Accuracy: 0.6362, Loss: 0.7032\n",
      "Epoch   2 Batch  265/269 - Train Accuracy: 0.6061, Validation Accuracy: 0.6360, Loss: 0.6911\n",
      "Epoch   2 Batch  266/269 - Train Accuracy: 0.6379, Validation Accuracy: 0.6341, Loss: 0.6621\n",
      "Epoch   2 Batch  267/269 - Train Accuracy: 0.6292, Validation Accuracy: 0.6352, Loss: 0.6761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   3 Batch    1/269 - Train Accuracy: 0.6049, Validation Accuracy: 0.6333, Loss: 0.6858\n",
      "Epoch   3 Batch    2/269 - Train Accuracy: 0.6125, Validation Accuracy: 0.6365, Loss: 0.6721\n",
      "Epoch   3 Batch    3/269 - Train Accuracy: 0.6293, Validation Accuracy: 0.6374, Loss: 0.6838\n",
      "Epoch   3 Batch    4/269 - Train Accuracy: 0.6055, Validation Accuracy: 0.6369, Loss: 0.6978\n",
      "Epoch   3 Batch    5/269 - Train Accuracy: 0.6004, Validation Accuracy: 0.6368, Loss: 0.6959\n",
      "Epoch   3 Batch    6/269 - Train Accuracy: 0.6253, Validation Accuracy: 0.6369, Loss: 0.6457\n",
      "Epoch   3 Batch    7/269 - Train Accuracy: 0.6287, Validation Accuracy: 0.6390, Loss: 0.6535\n",
      "Epoch   3 Batch    8/269 - Train Accuracy: 0.6120, Validation Accuracy: 0.6374, Loss: 0.7023\n",
      "Epoch   3 Batch    9/269 - Train Accuracy: 0.6204, Validation Accuracy: 0.6400, Loss: 0.6794\n",
      "Epoch   3 Batch   10/269 - Train Accuracy: 0.6140, Validation Accuracy: 0.6388, Loss: 0.6804\n",
      "Epoch   3 Batch   11/269 - Train Accuracy: 0.6181, Validation Accuracy: 0.6373, Loss: 0.6798\n",
      "Epoch   3 Batch   12/269 - Train Accuracy: 0.6107, Validation Accuracy: 0.6365, Loss: 0.6936\n",
      "Epoch   3 Batch   13/269 - Train Accuracy: 0.6476, Validation Accuracy: 0.6345, Loss: 0.6247\n",
      "Epoch   3 Batch   14/269 - Train Accuracy: 0.6230, Validation Accuracy: 0.6373, Loss: 0.6612\n",
      "Epoch   3 Batch   15/269 - Train Accuracy: 0.6137, Validation Accuracy: 0.6361, Loss: 0.6500\n",
      "Epoch   3 Batch   16/269 - Train Accuracy: 0.6346, Validation Accuracy: 0.6346, Loss: 0.6537\n",
      "Epoch   3 Batch   17/269 - Train Accuracy: 0.6198, Validation Accuracy: 0.6304, Loss: 0.6395\n",
      "Epoch   3 Batch   18/269 - Train Accuracy: 0.6009, Validation Accuracy: 0.6316, Loss: 0.6759\n",
      "Epoch   3 Batch   19/269 - Train Accuracy: 0.6529, Validation Accuracy: 0.6336, Loss: 0.6156\n",
      "Epoch   3 Batch   20/269 - Train Accuracy: 0.6147, Validation Accuracy: 0.6322, Loss: 0.6783\n",
      "Epoch   3 Batch   21/269 - Train Accuracy: 0.6173, Validation Accuracy: 0.6356, Loss: 0.7005\n",
      "Epoch   3 Batch   22/269 - Train Accuracy: 0.6374, Validation Accuracy: 0.6370, Loss: 0.6379\n",
      "Epoch   3 Batch   23/269 - Train Accuracy: 0.6278, Validation Accuracy: 0.6353, Loss: 0.6618\n",
      "Epoch   3 Batch   24/269 - Train Accuracy: 0.6152, Validation Accuracy: 0.6319, Loss: 0.6841\n",
      "Epoch   3 Batch   25/269 - Train Accuracy: 0.6051, Validation Accuracy: 0.6358, Loss: 0.6949\n",
      "Epoch   3 Batch   26/269 - Train Accuracy: 0.6460, Validation Accuracy: 0.6407, Loss: 0.6160\n",
      "Epoch   3 Batch   27/269 - Train Accuracy: 0.6146, Validation Accuracy: 0.6357, Loss: 0.6443\n",
      "Epoch   3 Batch   28/269 - Train Accuracy: 0.5895, Validation Accuracy: 0.6375, Loss: 0.7020\n",
      "Epoch   3 Batch   29/269 - Train Accuracy: 0.6200, Validation Accuracy: 0.6369, Loss: 0.6769\n",
      "Epoch   3 Batch   30/269 - Train Accuracy: 0.6323, Validation Accuracy: 0.6317, Loss: 0.6429\n",
      "Epoch   3 Batch   31/269 - Train Accuracy: 0.6300, Validation Accuracy: 0.6386, Loss: 0.6395\n",
      "Epoch   3 Batch   32/269 - Train Accuracy: 0.6254, Validation Accuracy: 0.6389, Loss: 0.6441\n",
      "Epoch   3 Batch   33/269 - Train Accuracy: 0.6409, Validation Accuracy: 0.6397, Loss: 0.6273\n",
      "Epoch   3 Batch   34/269 - Train Accuracy: 0.6286, Validation Accuracy: 0.6395, Loss: 0.6487\n",
      "Epoch   3 Batch   35/269 - Train Accuracy: 0.6364, Validation Accuracy: 0.6400, Loss: 0.6586\n",
      "Epoch   3 Batch   36/269 - Train Accuracy: 0.6274, Validation Accuracy: 0.6393, Loss: 0.6516\n",
      "Epoch   3 Batch   37/269 - Train Accuracy: 0.6301, Validation Accuracy: 0.6409, Loss: 0.6486\n",
      "Epoch   3 Batch   38/269 - Train Accuracy: 0.6360, Validation Accuracy: 0.6392, Loss: 0.6500\n",
      "Epoch   3 Batch   39/269 - Train Accuracy: 0.6305, Validation Accuracy: 0.6405, Loss: 0.6461\n",
      "Epoch   3 Batch   40/269 - Train Accuracy: 0.6212, Validation Accuracy: 0.6417, Loss: 0.6710\n",
      "Epoch   3 Batch   41/269 - Train Accuracy: 0.6283, Validation Accuracy: 0.6384, Loss: 0.6528\n",
      "Epoch   3 Batch   42/269 - Train Accuracy: 0.6525, Validation Accuracy: 0.6373, Loss: 0.6140\n",
      "Epoch   3 Batch   43/269 - Train Accuracy: 0.6208, Validation Accuracy: 0.6391, Loss: 0.6742\n",
      "Epoch   3 Batch   44/269 - Train Accuracy: 0.6418, Validation Accuracy: 0.6387, Loss: 0.6476\n",
      "Epoch   3 Batch   45/269 - Train Accuracy: 0.6146, Validation Accuracy: 0.6310, Loss: 0.6809\n",
      "Epoch   3 Batch   46/269 - Train Accuracy: 0.6149, Validation Accuracy: 0.6351, Loss: 0.6765\n",
      "Epoch   3 Batch   47/269 - Train Accuracy: 0.6584, Validation Accuracy: 0.6400, Loss: 0.6032\n",
      "Epoch   3 Batch   48/269 - Train Accuracy: 0.6364, Validation Accuracy: 0.6405, Loss: 0.6195\n",
      "Epoch   3 Batch   49/269 - Train Accuracy: 0.6099, Validation Accuracy: 0.6393, Loss: 0.6651\n",
      "Epoch   3 Batch   50/269 - Train Accuracy: 0.6154, Validation Accuracy: 0.6377, Loss: 0.6677\n",
      "Epoch   3 Batch   51/269 - Train Accuracy: 0.6211, Validation Accuracy: 0.6390, Loss: 0.6462\n",
      "Epoch   3 Batch   52/269 - Train Accuracy: 0.6283, Validation Accuracy: 0.6377, Loss: 0.6201\n",
      "Epoch   3 Batch   53/269 - Train Accuracy: 0.6120, Validation Accuracy: 0.6365, Loss: 0.6695\n",
      "Epoch   3 Batch   54/269 - Train Accuracy: 0.6287, Validation Accuracy: 0.6380, Loss: 0.6603\n",
      "Epoch   3 Batch   55/269 - Train Accuracy: 0.6455, Validation Accuracy: 0.6385, Loss: 0.6376\n",
      "Epoch   3 Batch   56/269 - Train Accuracy: 0.6411, Validation Accuracy: 0.6388, Loss: 0.6407\n",
      "Epoch   3 Batch   57/269 - Train Accuracy: 0.6323, Validation Accuracy: 0.6419, Loss: 0.6531\n",
      "Epoch   3 Batch   58/269 - Train Accuracy: 0.6376, Validation Accuracy: 0.6452, Loss: 0.6394\n",
      "Epoch   3 Batch   59/269 - Train Accuracy: 0.6401, Validation Accuracy: 0.6449, Loss: 0.6132\n",
      "Epoch   3 Batch   60/269 - Train Accuracy: 0.6396, Validation Accuracy: 0.6429, Loss: 0.6049\n",
      "Epoch   3 Batch   61/269 - Train Accuracy: 0.6433, Validation Accuracy: 0.6424, Loss: 0.5964\n",
      "Epoch   3 Batch   62/269 - Train Accuracy: 0.6475, Validation Accuracy: 0.6429, Loss: 0.6084\n",
      "Epoch   3 Batch   63/269 - Train Accuracy: 0.6286, Validation Accuracy: 0.6444, Loss: 0.6403\n",
      "Epoch   3 Batch   64/269 - Train Accuracy: 0.6193, Validation Accuracy: 0.6433, Loss: 0.6244\n",
      "Epoch   3 Batch   65/269 - Train Accuracy: 0.6299, Validation Accuracy: 0.6396, Loss: 0.6341\n",
      "Epoch   3 Batch   66/269 - Train Accuracy: 0.6384, Validation Accuracy: 0.6414, Loss: 0.6122\n",
      "Epoch   3 Batch   67/269 - Train Accuracy: 0.6328, Validation Accuracy: 0.6418, Loss: 0.6446\n",
      "Epoch   3 Batch   68/269 - Train Accuracy: 0.6187, Validation Accuracy: 0.6412, Loss: 0.6438\n",
      "Epoch   3 Batch   69/269 - Train Accuracy: 0.6024, Validation Accuracy: 0.6424, Loss: 0.6966\n",
      "Epoch   3 Batch   70/269 - Train Accuracy: 0.6484, Validation Accuracy: 0.6417, Loss: 0.6358\n",
      "Epoch   3 Batch   71/269 - Train Accuracy: 0.6228, Validation Accuracy: 0.6422, Loss: 0.6646\n",
      "Epoch   3 Batch   72/269 - Train Accuracy: 0.6372, Validation Accuracy: 0.6422, Loss: 0.6240\n",
      "Epoch   3 Batch   73/269 - Train Accuracy: 0.6223, Validation Accuracy: 0.6374, Loss: 0.6535\n",
      "Epoch   3 Batch   74/269 - Train Accuracy: 0.6223, Validation Accuracy: 0.6375, Loss: 0.6404\n",
      "Epoch   3 Batch   75/269 - Train Accuracy: 0.6335, Validation Accuracy: 0.6408, Loss: 0.6304\n",
      "Epoch   3 Batch   76/269 - Train Accuracy: 0.6297, Validation Accuracy: 0.6419, Loss: 0.6417\n",
      "Epoch   3 Batch   77/269 - Train Accuracy: 0.6497, Validation Accuracy: 0.6420, Loss: 0.6273\n",
      "Epoch   3 Batch   78/269 - Train Accuracy: 0.6312, Validation Accuracy: 0.6392, Loss: 0.6167\n",
      "Epoch   3 Batch   79/269 - Train Accuracy: 0.6239, Validation Accuracy: 0.6377, Loss: 0.6224\n",
      "Epoch   3 Batch   80/269 - Train Accuracy: 0.6400, Validation Accuracy: 0.6381, Loss: 0.6249\n",
      "Epoch   3 Batch   81/269 - Train Accuracy: 0.6416, Validation Accuracy: 0.6431, Loss: 0.6465\n",
      "Epoch   3 Batch   82/269 - Train Accuracy: 0.6415, Validation Accuracy: 0.6438, Loss: 0.6069\n",
      "Epoch   3 Batch   83/269 - Train Accuracy: 0.6389, Validation Accuracy: 0.6426, Loss: 0.6398\n",
      "Epoch   3 Batch   84/269 - Train Accuracy: 0.6448, Validation Accuracy: 0.6450, Loss: 0.6134\n",
      "Epoch   3 Batch   85/269 - Train Accuracy: 0.6336, Validation Accuracy: 0.6471, Loss: 0.6274\n",
      "Epoch   3 Batch   86/269 - Train Accuracy: 0.6024, Validation Accuracy: 0.6409, Loss: 0.6276\n",
      "Epoch   3 Batch   87/269 - Train Accuracy: 0.6120, Validation Accuracy: 0.6404, Loss: 0.6661\n",
      "Epoch   3 Batch   88/269 - Train Accuracy: 0.6190, Validation Accuracy: 0.6396, Loss: 0.6336\n",
      "Epoch   3 Batch   89/269 - Train Accuracy: 0.6397, Validation Accuracy: 0.6400, Loss: 0.6308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   3 Batch   90/269 - Train Accuracy: 0.6066, Validation Accuracy: 0.6468, Loss: 0.6680\n",
      "Epoch   3 Batch   91/269 - Train Accuracy: 0.6356, Validation Accuracy: 0.6428, Loss: 0.6058\n",
      "Epoch   3 Batch   92/269 - Train Accuracy: 0.6298, Validation Accuracy: 0.6434, Loss: 0.6182\n",
      "Epoch   3 Batch   93/269 - Train Accuracy: 0.6360, Validation Accuracy: 0.6442, Loss: 0.5997\n",
      "Epoch   3 Batch   94/269 - Train Accuracy: 0.6416, Validation Accuracy: 0.6468, Loss: 0.6395\n",
      "Epoch   3 Batch   95/269 - Train Accuracy: 0.6306, Validation Accuracy: 0.6458, Loss: 0.6298\n",
      "Epoch   3 Batch   96/269 - Train Accuracy: 0.6359, Validation Accuracy: 0.6469, Loss: 0.6241\n",
      "Epoch   3 Batch   97/269 - Train Accuracy: 0.6305, Validation Accuracy: 0.6468, Loss: 0.6214\n",
      "Epoch   3 Batch   98/269 - Train Accuracy: 0.6440, Validation Accuracy: 0.6442, Loss: 0.6193\n",
      "Epoch   3 Batch   99/269 - Train Accuracy: 0.6223, Validation Accuracy: 0.6457, Loss: 0.6467\n",
      "Epoch   3 Batch  100/269 - Train Accuracy: 0.6596, Validation Accuracy: 0.6449, Loss: 0.6158\n",
      "Epoch   3 Batch  101/269 - Train Accuracy: 0.6067, Validation Accuracy: 0.6446, Loss: 0.6580\n",
      "Epoch   3 Batch  102/269 - Train Accuracy: 0.6361, Validation Accuracy: 0.6471, Loss: 0.6225\n",
      "Epoch   3 Batch  103/269 - Train Accuracy: 0.6333, Validation Accuracy: 0.6451, Loss: 0.6141\n",
      "Epoch   3 Batch  104/269 - Train Accuracy: 0.6259, Validation Accuracy: 0.6455, Loss: 0.6061\n",
      "Epoch   3 Batch  105/269 - Train Accuracy: 0.6310, Validation Accuracy: 0.6484, Loss: 0.6322\n",
      "Epoch   3 Batch  106/269 - Train Accuracy: 0.6347, Validation Accuracy: 0.6475, Loss: 0.6140\n",
      "Epoch   3 Batch  107/269 - Train Accuracy: 0.6003, Validation Accuracy: 0.6440, Loss: 0.6563\n",
      "Epoch   3 Batch  108/269 - Train Accuracy: 0.6409, Validation Accuracy: 0.6435, Loss: 0.6216\n",
      "Epoch   3 Batch  109/269 - Train Accuracy: 0.6067, Validation Accuracy: 0.6445, Loss: 0.6256\n",
      "Epoch   3 Batch  110/269 - Train Accuracy: 0.6223, Validation Accuracy: 0.6418, Loss: 0.6142\n",
      "Epoch   3 Batch  111/269 - Train Accuracy: 0.6082, Validation Accuracy: 0.6437, Loss: 0.6570\n",
      "Epoch   3 Batch  112/269 - Train Accuracy: 0.6329, Validation Accuracy: 0.6443, Loss: 0.6185\n",
      "Epoch   3 Batch  113/269 - Train Accuracy: 0.6414, Validation Accuracy: 0.6460, Loss: 0.5967\n",
      "Epoch   3 Batch  114/269 - Train Accuracy: 0.6320, Validation Accuracy: 0.6475, Loss: 0.6157\n",
      "Epoch   3 Batch  115/269 - Train Accuracy: 0.6232, Validation Accuracy: 0.6454, Loss: 0.6465\n",
      "Epoch   3 Batch  116/269 - Train Accuracy: 0.6320, Validation Accuracy: 0.6437, Loss: 0.6279\n",
      "Epoch   3 Batch  117/269 - Train Accuracy: 0.6337, Validation Accuracy: 0.6444, Loss: 0.6206\n",
      "Epoch   3 Batch  118/269 - Train Accuracy: 0.6532, Validation Accuracy: 0.6449, Loss: 0.6009\n",
      "Epoch   3 Batch  119/269 - Train Accuracy: 0.6257, Validation Accuracy: 0.6460, Loss: 0.6582\n",
      "Epoch   3 Batch  120/269 - Train Accuracy: 0.6286, Validation Accuracy: 0.6481, Loss: 0.6318\n",
      "Epoch   3 Batch  121/269 - Train Accuracy: 0.6342, Validation Accuracy: 0.6468, Loss: 0.6088\n",
      "Epoch   3 Batch  122/269 - Train Accuracy: 0.6409, Validation Accuracy: 0.6463, Loss: 0.6051\n",
      "Epoch   3 Batch  123/269 - Train Accuracy: 0.6186, Validation Accuracy: 0.6465, Loss: 0.6519\n",
      "Epoch   3 Batch  124/269 - Train Accuracy: 0.6316, Validation Accuracy: 0.6460, Loss: 0.6044\n",
      "Epoch   3 Batch  125/269 - Train Accuracy: 0.6441, Validation Accuracy: 0.6491, Loss: 0.6111\n",
      "Epoch   3 Batch  126/269 - Train Accuracy: 0.6418, Validation Accuracy: 0.6468, Loss: 0.6025\n",
      "Epoch   3 Batch  127/269 - Train Accuracy: 0.6196, Validation Accuracy: 0.6483, Loss: 0.6482\n",
      "Epoch   3 Batch  128/269 - Train Accuracy: 0.6537, Validation Accuracy: 0.6504, Loss: 0.6130\n",
      "Epoch   3 Batch  129/269 - Train Accuracy: 0.6356, Validation Accuracy: 0.6513, Loss: 0.6121\n",
      "Epoch   3 Batch  130/269 - Train Accuracy: 0.6158, Validation Accuracy: 0.6528, Loss: 0.6393\n",
      "Epoch   3 Batch  131/269 - Train Accuracy: 0.6265, Validation Accuracy: 0.6535, Loss: 0.6332\n",
      "Epoch   3 Batch  132/269 - Train Accuracy: 0.6339, Validation Accuracy: 0.6510, Loss: 0.6212\n",
      "Epoch   3 Batch  133/269 - Train Accuracy: 0.6482, Validation Accuracy: 0.6525, Loss: 0.5978\n",
      "Epoch   3 Batch  134/269 - Train Accuracy: 0.6197, Validation Accuracy: 0.6486, Loss: 0.6328\n",
      "Epoch   3 Batch  135/269 - Train Accuracy: 0.6141, Validation Accuracy: 0.6424, Loss: 0.6544\n",
      "Epoch   3 Batch  136/269 - Train Accuracy: 0.6104, Validation Accuracy: 0.6464, Loss: 0.6610\n",
      "Epoch   3 Batch  137/269 - Train Accuracy: 0.6337, Validation Accuracy: 0.6511, Loss: 0.6416\n",
      "Epoch   3 Batch  138/269 - Train Accuracy: 0.6336, Validation Accuracy: 0.6450, Loss: 0.6315\n",
      "Epoch   3 Batch  139/269 - Train Accuracy: 0.6501, Validation Accuracy: 0.6505, Loss: 0.5938\n",
      "Epoch   3 Batch  140/269 - Train Accuracy: 0.6434, Validation Accuracy: 0.6467, Loss: 0.6219\n",
      "Epoch   3 Batch  141/269 - Train Accuracy: 0.6284, Validation Accuracy: 0.6468, Loss: 0.6229\n",
      "Epoch   3 Batch  142/269 - Train Accuracy: 0.6392, Validation Accuracy: 0.6455, Loss: 0.6008\n",
      "Epoch   3 Batch  143/269 - Train Accuracy: 0.6381, Validation Accuracy: 0.6464, Loss: 0.6039\n",
      "Epoch   3 Batch  144/269 - Train Accuracy: 0.6464, Validation Accuracy: 0.6469, Loss: 0.5919\n",
      "Epoch   3 Batch  145/269 - Train Accuracy: 0.6443, Validation Accuracy: 0.6454, Loss: 0.6028\n",
      "Epoch   3 Batch  146/269 - Train Accuracy: 0.6370, Validation Accuracy: 0.6468, Loss: 0.5950\n",
      "Epoch   3 Batch  147/269 - Train Accuracy: 0.6483, Validation Accuracy: 0.6467, Loss: 0.5829\n",
      "Epoch   3 Batch  148/269 - Train Accuracy: 0.6449, Validation Accuracy: 0.6503, Loss: 0.6100\n",
      "Epoch   3 Batch  149/269 - Train Accuracy: 0.6391, Validation Accuracy: 0.6501, Loss: 0.6167\n",
      "Epoch   3 Batch  150/269 - Train Accuracy: 0.6484, Validation Accuracy: 0.6525, Loss: 0.6131\n",
      "Epoch   3 Batch  151/269 - Train Accuracy: 0.6712, Validation Accuracy: 0.6547, Loss: 0.5908\n",
      "Epoch   3 Batch  152/269 - Train Accuracy: 0.6470, Validation Accuracy: 0.6528, Loss: 0.6012\n",
      "Epoch   3 Batch  153/269 - Train Accuracy: 0.6505, Validation Accuracy: 0.6552, Loss: 0.5939\n",
      "Epoch   3 Batch  154/269 - Train Accuracy: 0.6299, Validation Accuracy: 0.6562, Loss: 0.6201\n",
      "Epoch   3 Batch  155/269 - Train Accuracy: 0.6744, Validation Accuracy: 0.6547, Loss: 0.5702\n",
      "Epoch   3 Batch  156/269 - Train Accuracy: 0.6317, Validation Accuracy: 0.6531, Loss: 0.6291\n",
      "Epoch   3 Batch  157/269 - Train Accuracy: 0.6384, Validation Accuracy: 0.6530, Loss: 0.6036\n",
      "Epoch   3 Batch  158/269 - Train Accuracy: 0.6442, Validation Accuracy: 0.6545, Loss: 0.6025\n",
      "Epoch   3 Batch  159/269 - Train Accuracy: 0.6395, Validation Accuracy: 0.6501, Loss: 0.6052\n",
      "Epoch   3 Batch  160/269 - Train Accuracy: 0.6473, Validation Accuracy: 0.6553, Loss: 0.5947\n",
      "Epoch   3 Batch  161/269 - Train Accuracy: 0.6409, Validation Accuracy: 0.6534, Loss: 0.6045\n",
      "Epoch   3 Batch  162/269 - Train Accuracy: 0.6437, Validation Accuracy: 0.6493, Loss: 0.5982\n",
      "Epoch   3 Batch  163/269 - Train Accuracy: 0.6544, Validation Accuracy: 0.6558, Loss: 0.5953\n",
      "Epoch   3 Batch  164/269 - Train Accuracy: 0.6546, Validation Accuracy: 0.6555, Loss: 0.5906\n",
      "Epoch   3 Batch  165/269 - Train Accuracy: 0.6187, Validation Accuracy: 0.6455, Loss: 0.6146\n",
      "Epoch   3 Batch  166/269 - Train Accuracy: 0.6590, Validation Accuracy: 0.6491, Loss: 0.5711\n",
      "Epoch   3 Batch  167/269 - Train Accuracy: 0.6422, Validation Accuracy: 0.6571, Loss: 0.6040\n",
      "Epoch   3 Batch  168/269 - Train Accuracy: 0.6325, Validation Accuracy: 0.6515, Loss: 0.6016\n",
      "Epoch   3 Batch  169/269 - Train Accuracy: 0.6404, Validation Accuracy: 0.6541, Loss: 0.6061\n",
      "Epoch   3 Batch  170/269 - Train Accuracy: 0.6422, Validation Accuracy: 0.6551, Loss: 0.5931\n",
      "Epoch   3 Batch  171/269 - Train Accuracy: 0.6403, Validation Accuracy: 0.6539, Loss: 0.6231\n",
      "Epoch   3 Batch  172/269 - Train Accuracy: 0.6435, Validation Accuracy: 0.6584, Loss: 0.6085\n",
      "Epoch   3 Batch  173/269 - Train Accuracy: 0.6466, Validation Accuracy: 0.6552, Loss: 0.5843\n",
      "Epoch   3 Batch  174/269 - Train Accuracy: 0.6194, Validation Accuracy: 0.6472, Loss: 0.6014\n",
      "Epoch   3 Batch  175/269 - Train Accuracy: 0.6439, Validation Accuracy: 0.6518, Loss: 0.6090\n",
      "Epoch   3 Batch  176/269 - Train Accuracy: 0.6300, Validation Accuracy: 0.6536, Loss: 0.6287\n",
      "Epoch   3 Batch  177/269 - Train Accuracy: 0.6521, Validation Accuracy: 0.6497, Loss: 0.5644\n",
      "Epoch   3 Batch  178/269 - Train Accuracy: 0.6301, Validation Accuracy: 0.6501, Loss: 0.6104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   3 Batch  179/269 - Train Accuracy: 0.6373, Validation Accuracy: 0.6532, Loss: 0.5997\n",
      "Epoch   3 Batch  180/269 - Train Accuracy: 0.6413, Validation Accuracy: 0.6517, Loss: 0.5855\n",
      "Epoch   3 Batch  181/269 - Train Accuracy: 0.6339, Validation Accuracy: 0.6537, Loss: 0.5987\n",
      "Epoch   3 Batch  182/269 - Train Accuracy: 0.6512, Validation Accuracy: 0.6524, Loss: 0.5932\n",
      "Epoch   3 Batch  183/269 - Train Accuracy: 0.6872, Validation Accuracy: 0.6498, Loss: 0.5132\n",
      "Epoch   3 Batch  184/269 - Train Accuracy: 0.6231, Validation Accuracy: 0.6531, Loss: 0.6183\n",
      "Epoch   3 Batch  185/269 - Train Accuracy: 0.6587, Validation Accuracy: 0.6557, Loss: 0.5863\n",
      "Epoch   3 Batch  186/269 - Train Accuracy: 0.6227, Validation Accuracy: 0.6508, Loss: 0.6042\n",
      "Epoch   3 Batch  187/269 - Train Accuracy: 0.6420, Validation Accuracy: 0.6525, Loss: 0.5814\n",
      "Epoch   3 Batch  188/269 - Train Accuracy: 0.6525, Validation Accuracy: 0.6557, Loss: 0.5726\n",
      "Epoch   3 Batch  189/269 - Train Accuracy: 0.6509, Validation Accuracy: 0.6571, Loss: 0.5763\n",
      "Epoch   3 Batch  190/269 - Train Accuracy: 0.6451, Validation Accuracy: 0.6560, Loss: 0.5779\n",
      "Epoch   3 Batch  191/269 - Train Accuracy: 0.6539, Validation Accuracy: 0.6536, Loss: 0.5827\n",
      "Epoch   3 Batch  192/269 - Train Accuracy: 0.6446, Validation Accuracy: 0.6564, Loss: 0.5876\n",
      "Epoch   3 Batch  193/269 - Train Accuracy: 0.6503, Validation Accuracy: 0.6560, Loss: 0.5814\n",
      "Epoch   3 Batch  194/269 - Train Accuracy: 0.6598, Validation Accuracy: 0.6531, Loss: 0.5906\n",
      "Epoch   3 Batch  195/269 - Train Accuracy: 0.6311, Validation Accuracy: 0.6554, Loss: 0.5896\n",
      "Epoch   3 Batch  196/269 - Train Accuracy: 0.6330, Validation Accuracy: 0.6531, Loss: 0.5806\n",
      "Epoch   3 Batch  197/269 - Train Accuracy: 0.6257, Validation Accuracy: 0.6578, Loss: 0.6120\n",
      "Epoch   3 Batch  198/269 - Train Accuracy: 0.6337, Validation Accuracy: 0.6698, Loss: 0.6157\n",
      "Epoch   3 Batch  199/269 - Train Accuracy: 0.6408, Validation Accuracy: 0.6624, Loss: 0.6007\n",
      "Epoch   3 Batch  200/269 - Train Accuracy: 0.6312, Validation Accuracy: 0.6582, Loss: 0.6041\n",
      "Epoch   3 Batch  201/269 - Train Accuracy: 0.6475, Validation Accuracy: 0.6601, Loss: 0.5846\n",
      "Epoch   3 Batch  202/269 - Train Accuracy: 0.6513, Validation Accuracy: 0.6633, Loss: 0.5767\n",
      "Epoch   3 Batch  203/269 - Train Accuracy: 0.6315, Validation Accuracy: 0.6642, Loss: 0.6285\n",
      "Epoch   3 Batch  204/269 - Train Accuracy: 0.6288, Validation Accuracy: 0.6662, Loss: 0.6136\n",
      "Epoch   3 Batch  205/269 - Train Accuracy: 0.6561, Validation Accuracy: 0.6704, Loss: 0.5737\n",
      "Epoch   3 Batch  206/269 - Train Accuracy: 0.6484, Validation Accuracy: 0.6675, Loss: 0.6104\n",
      "Epoch   3 Batch  207/269 - Train Accuracy: 0.6716, Validation Accuracy: 0.6645, Loss: 0.5650\n",
      "Epoch   3 Batch  208/269 - Train Accuracy: 0.6387, Validation Accuracy: 0.6697, Loss: 0.6075\n",
      "Epoch   3 Batch  209/269 - Train Accuracy: 0.6529, Validation Accuracy: 0.6677, Loss: 0.5928\n",
      "Epoch   3 Batch  210/269 - Train Accuracy: 0.6557, Validation Accuracy: 0.6578, Loss: 0.5693\n",
      "Epoch   3 Batch  211/269 - Train Accuracy: 0.6418, Validation Accuracy: 0.6604, Loss: 0.5910\n",
      "Epoch   3 Batch  212/269 - Train Accuracy: 0.6669, Validation Accuracy: 0.6657, Loss: 0.5697\n",
      "Epoch   3 Batch  213/269 - Train Accuracy: 0.6432, Validation Accuracy: 0.6578, Loss: 0.5747\n",
      "Epoch   3 Batch  214/269 - Train Accuracy: 0.6627, Validation Accuracy: 0.6601, Loss: 0.5800\n",
      "Epoch   3 Batch  215/269 - Train Accuracy: 0.6874, Validation Accuracy: 0.6633, Loss: 0.5469\n",
      "Epoch   3 Batch  216/269 - Train Accuracy: 0.6193, Validation Accuracy: 0.6586, Loss: 0.6199\n",
      "Epoch   3 Batch  217/269 - Train Accuracy: 0.6273, Validation Accuracy: 0.6563, Loss: 0.6005\n",
      "Epoch   3 Batch  218/269 - Train Accuracy: 0.6405, Validation Accuracy: 0.6578, Loss: 0.5979\n",
      "Epoch   3 Batch  219/269 - Train Accuracy: 0.6612, Validation Accuracy: 0.6575, Loss: 0.6042\n",
      "Epoch   3 Batch  220/269 - Train Accuracy: 0.6503, Validation Accuracy: 0.6608, Loss: 0.5499\n",
      "Epoch   3 Batch  221/269 - Train Accuracy: 0.6783, Validation Accuracy: 0.6701, Loss: 0.5775\n",
      "Epoch   3 Batch  222/269 - Train Accuracy: 0.6745, Validation Accuracy: 0.6683, Loss: 0.5619\n",
      "Epoch   3 Batch  223/269 - Train Accuracy: 0.6474, Validation Accuracy: 0.6584, Loss: 0.5652\n",
      "Epoch   3 Batch  224/269 - Train Accuracy: 0.6602, Validation Accuracy: 0.6565, Loss: 0.5913\n",
      "Epoch   3 Batch  225/269 - Train Accuracy: 0.6477, Validation Accuracy: 0.6545, Loss: 0.5801\n",
      "Epoch   3 Batch  226/269 - Train Accuracy: 0.6483, Validation Accuracy: 0.6705, Loss: 0.5693\n",
      "Epoch   3 Batch  227/269 - Train Accuracy: 0.7083, Validation Accuracy: 0.6759, Loss: 0.5097\n",
      "Epoch   3 Batch  228/269 - Train Accuracy: 0.6562, Validation Accuracy: 0.6578, Loss: 0.5682\n",
      "Epoch   3 Batch  229/269 - Train Accuracy: 0.6475, Validation Accuracy: 0.6563, Loss: 0.5688\n",
      "Epoch   3 Batch  230/269 - Train Accuracy: 0.6604, Validation Accuracy: 0.6688, Loss: 0.5670\n",
      "Epoch   3 Batch  231/269 - Train Accuracy: 0.6457, Validation Accuracy: 0.6730, Loss: 0.6043\n",
      "Epoch   3 Batch  232/269 - Train Accuracy: 0.6354, Validation Accuracy: 0.6611, Loss: 0.5916\n",
      "Epoch   3 Batch  233/269 - Train Accuracy: 0.6549, Validation Accuracy: 0.6523, Loss: 0.5753\n",
      "Epoch   3 Batch  234/269 - Train Accuracy: 0.6473, Validation Accuracy: 0.6716, Loss: 0.5672\n",
      "Epoch   3 Batch  235/269 - Train Accuracy: 0.6797, Validation Accuracy: 0.6833, Loss: 0.5500\n",
      "Epoch   3 Batch  236/269 - Train Accuracy: 0.6504, Validation Accuracy: 0.6742, Loss: 0.5659\n",
      "Epoch   3 Batch  237/269 - Train Accuracy: 0.6416, Validation Accuracy: 0.6700, Loss: 0.5682\n",
      "Epoch   3 Batch  238/269 - Train Accuracy: 0.6791, Validation Accuracy: 0.6756, Loss: 0.5545\n",
      "Epoch   3 Batch  239/269 - Train Accuracy: 0.6554, Validation Accuracy: 0.6680, Loss: 0.5640\n",
      "Epoch   3 Batch  240/269 - Train Accuracy: 0.6787, Validation Accuracy: 0.6595, Loss: 0.5146\n",
      "Epoch   3 Batch  241/269 - Train Accuracy: 0.6531, Validation Accuracy: 0.6642, Loss: 0.5782\n",
      "Epoch   3 Batch  242/269 - Train Accuracy: 0.6474, Validation Accuracy: 0.6723, Loss: 0.5640\n",
      "Epoch   3 Batch  243/269 - Train Accuracy: 0.6799, Validation Accuracy: 0.6790, Loss: 0.5456\n",
      "Epoch   3 Batch  244/269 - Train Accuracy: 0.6618, Validation Accuracy: 0.6849, Loss: 0.5655\n",
      "Epoch   3 Batch  245/269 - Train Accuracy: 0.6499, Validation Accuracy: 0.6863, Loss: 0.5931\n",
      "Epoch   3 Batch  246/269 - Train Accuracy: 0.6536, Validation Accuracy: 0.6902, Loss: 0.5767\n",
      "Epoch   3 Batch  247/269 - Train Accuracy: 0.6473, Validation Accuracy: 0.6803, Loss: 0.5893\n",
      "Epoch   3 Batch  248/269 - Train Accuracy: 0.6687, Validation Accuracy: 0.6765, Loss: 0.5567\n",
      "Epoch   3 Batch  249/269 - Train Accuracy: 0.6784, Validation Accuracy: 0.6749, Loss: 0.5380\n",
      "Epoch   3 Batch  250/269 - Train Accuracy: 0.6604, Validation Accuracy: 0.6784, Loss: 0.5788\n",
      "Epoch   3 Batch  251/269 - Train Accuracy: 0.6856, Validation Accuracy: 0.6731, Loss: 0.5555\n",
      "Epoch   3 Batch  252/269 - Train Accuracy: 0.6662, Validation Accuracy: 0.6774, Loss: 0.5675\n",
      "Epoch   3 Batch  253/269 - Train Accuracy: 0.6616, Validation Accuracy: 0.6782, Loss: 0.5670\n",
      "Epoch   3 Batch  254/269 - Train Accuracy: 0.6598, Validation Accuracy: 0.6781, Loss: 0.5608\n",
      "Epoch   3 Batch  255/269 - Train Accuracy: 0.6758, Validation Accuracy: 0.6716, Loss: 0.5402\n",
      "Epoch   3 Batch  256/269 - Train Accuracy: 0.6605, Validation Accuracy: 0.6819, Loss: 0.5721\n",
      "Epoch   3 Batch  257/269 - Train Accuracy: 0.6480, Validation Accuracy: 0.6826, Loss: 0.5713\n",
      "Epoch   3 Batch  258/269 - Train Accuracy: 0.6643, Validation Accuracy: 0.6761, Loss: 0.5620\n",
      "Epoch   3 Batch  259/269 - Train Accuracy: 0.6728, Validation Accuracy: 0.6772, Loss: 0.5637\n",
      "Epoch   3 Batch  260/269 - Train Accuracy: 0.6404, Validation Accuracy: 0.6747, Loss: 0.5908\n",
      "Epoch   3 Batch  261/269 - Train Accuracy: 0.6337, Validation Accuracy: 0.6773, Loss: 0.5900\n",
      "Epoch   3 Batch  262/269 - Train Accuracy: 0.6784, Validation Accuracy: 0.6826, Loss: 0.5603\n",
      "Epoch   3 Batch  263/269 - Train Accuracy: 0.6573, Validation Accuracy: 0.6814, Loss: 0.5771\n",
      "Epoch   3 Batch  264/269 - Train Accuracy: 0.6478, Validation Accuracy: 0.6689, Loss: 0.5822\n",
      "Epoch   3 Batch  265/269 - Train Accuracy: 0.6470, Validation Accuracy: 0.6639, Loss: 0.5726\n",
      "Epoch   3 Batch  266/269 - Train Accuracy: 0.6847, Validation Accuracy: 0.6770, Loss: 0.5533\n",
      "Epoch   3 Batch  267/269 - Train Accuracy: 0.6616, Validation Accuracy: 0.6818, Loss: 0.5665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4 Batch    1/269 - Train Accuracy: 0.6461, Validation Accuracy: 0.6708, Loss: 0.5761\n",
      "Epoch   4 Batch    2/269 - Train Accuracy: 0.6519, Validation Accuracy: 0.6752, Loss: 0.5590\n",
      "Epoch   4 Batch    3/269 - Train Accuracy: 0.6707, Validation Accuracy: 0.6713, Loss: 0.5672\n",
      "Epoch   4 Batch    4/269 - Train Accuracy: 0.6322, Validation Accuracy: 0.6800, Loss: 0.5825\n",
      "Epoch   4 Batch    5/269 - Train Accuracy: 0.6465, Validation Accuracy: 0.6864, Loss: 0.5753\n",
      "Epoch   4 Batch    6/269 - Train Accuracy: 0.6603, Validation Accuracy: 0.6792, Loss: 0.5438\n",
      "Epoch   4 Batch    7/269 - Train Accuracy: 0.6583, Validation Accuracy: 0.6700, Loss: 0.5467\n",
      "Epoch   4 Batch    8/269 - Train Accuracy: 0.6429, Validation Accuracy: 0.6695, Loss: 0.5806\n",
      "Epoch   4 Batch    9/269 - Train Accuracy: 0.6553, Validation Accuracy: 0.6809, Loss: 0.5714\n",
      "Epoch   4 Batch   10/269 - Train Accuracy: 0.6428, Validation Accuracy: 0.6808, Loss: 0.5679\n",
      "Epoch   4 Batch   11/269 - Train Accuracy: 0.6578, Validation Accuracy: 0.6771, Loss: 0.5640\n",
      "Epoch   4 Batch   12/269 - Train Accuracy: 0.6724, Validation Accuracy: 0.6938, Loss: 0.5891\n",
      "Epoch   4 Batch   13/269 - Train Accuracy: 0.6862, Validation Accuracy: 0.6910, Loss: 0.5203\n",
      "Epoch   4 Batch   14/269 - Train Accuracy: 0.6637, Validation Accuracy: 0.6816, Loss: 0.5560\n",
      "Epoch   4 Batch   15/269 - Train Accuracy: 0.6596, Validation Accuracy: 0.6796, Loss: 0.5445\n",
      "Epoch   4 Batch   16/269 - Train Accuracy: 0.6740, Validation Accuracy: 0.6903, Loss: 0.5547\n",
      "Epoch   4 Batch   17/269 - Train Accuracy: 0.6749, Validation Accuracy: 0.6871, Loss: 0.5382\n",
      "Epoch   4 Batch   18/269 - Train Accuracy: 0.6604, Validation Accuracy: 0.6862, Loss: 0.5619\n",
      "Epoch   4 Batch   19/269 - Train Accuracy: 0.6854, Validation Accuracy: 0.6890, Loss: 0.5153\n",
      "Epoch   4 Batch   20/269 - Train Accuracy: 0.6741, Validation Accuracy: 0.6891, Loss: 0.5695\n",
      "Epoch   4 Batch   21/269 - Train Accuracy: 0.6641, Validation Accuracy: 0.6894, Loss: 0.5770\n",
      "Epoch   4 Batch   22/269 - Train Accuracy: 0.6828, Validation Accuracy: 0.6887, Loss: 0.5366\n",
      "Epoch   4 Batch   23/269 - Train Accuracy: 0.6702, Validation Accuracy: 0.6873, Loss: 0.5439\n",
      "Epoch   4 Batch   24/269 - Train Accuracy: 0.6646, Validation Accuracy: 0.6901, Loss: 0.5769\n",
      "Epoch   4 Batch   25/269 - Train Accuracy: 0.6637, Validation Accuracy: 0.6849, Loss: 0.5827\n",
      "Epoch   4 Batch   26/269 - Train Accuracy: 0.6916, Validation Accuracy: 0.6883, Loss: 0.5146\n",
      "Epoch   4 Batch   27/269 - Train Accuracy: 0.6595, Validation Accuracy: 0.6837, Loss: 0.5404\n",
      "Epoch   4 Batch   28/269 - Train Accuracy: 0.6243, Validation Accuracy: 0.6825, Loss: 0.6009\n",
      "Epoch   4 Batch   29/269 - Train Accuracy: 0.6637, Validation Accuracy: 0.6909, Loss: 0.5809\n",
      "Epoch   4 Batch   30/269 - Train Accuracy: 0.6827, Validation Accuracy: 0.7015, Loss: 0.5420\n",
      "Epoch   4 Batch   31/269 - Train Accuracy: 0.6775, Validation Accuracy: 0.6874, Loss: 0.5341\n",
      "Epoch   4 Batch   32/269 - Train Accuracy: 0.6692, Validation Accuracy: 0.6809, Loss: 0.5399\n",
      "Epoch   4 Batch   33/269 - Train Accuracy: 0.6856, Validation Accuracy: 0.6878, Loss: 0.5290\n",
      "Epoch   4 Batch   34/269 - Train Accuracy: 0.6652, Validation Accuracy: 0.6903, Loss: 0.5426\n",
      "Epoch   4 Batch   35/269 - Train Accuracy: 0.6713, Validation Accuracy: 0.6906, Loss: 0.5565\n",
      "Epoch   4 Batch   36/269 - Train Accuracy: 0.6694, Validation Accuracy: 0.6899, Loss: 0.5484\n",
      "Epoch   4 Batch   37/269 - Train Accuracy: 0.6717, Validation Accuracy: 0.6873, Loss: 0.5452\n",
      "Epoch   4 Batch   38/269 - Train Accuracy: 0.6806, Validation Accuracy: 0.6873, Loss: 0.5403\n",
      "Epoch   4 Batch   39/269 - Train Accuracy: 0.6767, Validation Accuracy: 0.6955, Loss: 0.5411\n",
      "Epoch   4 Batch   40/269 - Train Accuracy: 0.6594, Validation Accuracy: 0.6964, Loss: 0.5645\n",
      "Epoch   4 Batch   41/269 - Train Accuracy: 0.6707, Validation Accuracy: 0.6873, Loss: 0.5440\n",
      "Epoch   4 Batch   42/269 - Train Accuracy: 0.6851, Validation Accuracy: 0.6831, Loss: 0.5134\n",
      "Epoch   4 Batch   43/269 - Train Accuracy: 0.6742, Validation Accuracy: 0.6844, Loss: 0.5562\n",
      "Epoch   4 Batch   44/269 - Train Accuracy: 0.6730, Validation Accuracy: 0.6906, Loss: 0.5338\n",
      "Epoch   4 Batch   45/269 - Train Accuracy: 0.6625, Validation Accuracy: 0.6837, Loss: 0.5628\n",
      "Epoch   4 Batch   46/269 - Train Accuracy: 0.6572, Validation Accuracy: 0.6857, Loss: 0.5605\n",
      "Epoch   4 Batch   47/269 - Train Accuracy: 0.6781, Validation Accuracy: 0.6778, Loss: 0.5005\n",
      "Epoch   4 Batch   48/269 - Train Accuracy: 0.6828, Validation Accuracy: 0.6762, Loss: 0.5247\n",
      "Epoch   4 Batch   49/269 - Train Accuracy: 0.6615, Validation Accuracy: 0.6788, Loss: 0.5515\n",
      "Epoch   4 Batch   50/269 - Train Accuracy: 0.6614, Validation Accuracy: 0.6859, Loss: 0.5622\n",
      "Epoch   4 Batch   51/269 - Train Accuracy: 0.6650, Validation Accuracy: 0.6875, Loss: 0.5391\n",
      "Epoch   4 Batch   52/269 - Train Accuracy: 0.6495, Validation Accuracy: 0.6815, Loss: 0.5185\n",
      "Epoch   4 Batch   53/269 - Train Accuracy: 0.6573, Validation Accuracy: 0.6764, Loss: 0.5557\n",
      "Epoch   4 Batch   54/269 - Train Accuracy: 0.6646, Validation Accuracy: 0.6818, Loss: 0.5452\n",
      "Epoch   4 Batch   55/269 - Train Accuracy: 0.6731, Validation Accuracy: 0.6837, Loss: 0.5270\n",
      "Epoch   4 Batch   56/269 - Train Accuracy: 0.6846, Validation Accuracy: 0.6932, Loss: 0.5336\n",
      "Epoch   4 Batch   57/269 - Train Accuracy: 0.6699, Validation Accuracy: 0.6921, Loss: 0.5495\n",
      "Epoch   4 Batch   58/269 - Train Accuracy: 0.6831, Validation Accuracy: 0.6911, Loss: 0.5284\n",
      "Epoch   4 Batch   59/269 - Train Accuracy: 0.6897, Validation Accuracy: 0.6848, Loss: 0.5104\n",
      "Epoch   4 Batch   60/269 - Train Accuracy: 0.6924, Validation Accuracy: 0.6949, Loss: 0.5014\n",
      "Epoch   4 Batch   61/269 - Train Accuracy: 0.7099, Validation Accuracy: 0.7072, Loss: 0.4951\n",
      "Epoch   4 Batch   62/269 - Train Accuracy: 0.7025, Validation Accuracy: 0.7000, Loss: 0.5077\n",
      "Epoch   4 Batch   63/269 - Train Accuracy: 0.6856, Validation Accuracy: 0.6894, Loss: 0.5362\n",
      "Epoch   4 Batch   64/269 - Train Accuracy: 0.6843, Validation Accuracy: 0.6938, Loss: 0.5203\n",
      "Epoch   4 Batch   65/269 - Train Accuracy: 0.6695, Validation Accuracy: 0.6909, Loss: 0.5255\n",
      "Epoch   4 Batch   66/269 - Train Accuracy: 0.6845, Validation Accuracy: 0.6948, Loss: 0.5142\n",
      "Epoch   4 Batch   67/269 - Train Accuracy: 0.6735, Validation Accuracy: 0.6866, Loss: 0.5287\n",
      "Epoch   4 Batch   68/269 - Train Accuracy: 0.6601, Validation Accuracy: 0.6966, Loss: 0.5393\n",
      "Epoch   4 Batch   69/269 - Train Accuracy: 0.6377, Validation Accuracy: 0.6985, Loss: 0.5781\n",
      "Epoch   4 Batch   70/269 - Train Accuracy: 0.6879, Validation Accuracy: 0.6897, Loss: 0.5337\n",
      "Epoch   4 Batch   71/269 - Train Accuracy: 0.6559, Validation Accuracy: 0.6856, Loss: 0.5537\n",
      "Epoch   4 Batch   72/269 - Train Accuracy: 0.6763, Validation Accuracy: 0.6912, Loss: 0.5179\n",
      "Epoch   4 Batch   73/269 - Train Accuracy: 0.6749, Validation Accuracy: 0.6954, Loss: 0.5368\n",
      "Epoch   4 Batch   74/269 - Train Accuracy: 0.6848, Validation Accuracy: 0.6891, Loss: 0.5291\n",
      "Epoch   4 Batch   75/269 - Train Accuracy: 0.6854, Validation Accuracy: 0.6798, Loss: 0.5181\n",
      "Epoch   4 Batch   76/269 - Train Accuracy: 0.6743, Validation Accuracy: 0.6919, Loss: 0.5277\n",
      "Epoch   4 Batch   77/269 - Train Accuracy: 0.6947, Validation Accuracy: 0.6936, Loss: 0.5186\n",
      "Epoch   4 Batch   78/269 - Train Accuracy: 0.6991, Validation Accuracy: 0.6893, Loss: 0.5138\n",
      "Epoch   4 Batch   79/269 - Train Accuracy: 0.6817, Validation Accuracy: 0.6952, Loss: 0.5143\n",
      "Epoch   4 Batch   80/269 - Train Accuracy: 0.6950, Validation Accuracy: 0.7012, Loss: 0.5126\n",
      "Epoch   4 Batch   81/269 - Train Accuracy: 0.6798, Validation Accuracy: 0.6943, Loss: 0.5398\n",
      "Epoch   4 Batch   82/269 - Train Accuracy: 0.6868, Validation Accuracy: 0.6878, Loss: 0.5053\n",
      "Epoch   4 Batch   83/269 - Train Accuracy: 0.6753, Validation Accuracy: 0.6984, Loss: 0.5348\n",
      "Epoch   4 Batch   84/269 - Train Accuracy: 0.6928, Validation Accuracy: 0.7016, Loss: 0.5128\n",
      "Epoch   4 Batch   85/269 - Train Accuracy: 0.6747, Validation Accuracy: 0.6969, Loss: 0.5169\n",
      "Epoch   4 Batch   86/269 - Train Accuracy: 0.6720, Validation Accuracy: 0.6952, Loss: 0.5114\n",
      "Epoch   4 Batch   87/269 - Train Accuracy: 0.6661, Validation Accuracy: 0.7031, Loss: 0.5501\n",
      "Epoch   4 Batch   88/269 - Train Accuracy: 0.6823, Validation Accuracy: 0.7014, Loss: 0.5171\n",
      "Epoch   4 Batch   89/269 - Train Accuracy: 0.6963, Validation Accuracy: 0.7058, Loss: 0.5202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4 Batch   90/269 - Train Accuracy: 0.6551, Validation Accuracy: 0.6969, Loss: 0.5507\n",
      "Epoch   4 Batch   91/269 - Train Accuracy: 0.6891, Validation Accuracy: 0.7042, Loss: 0.5001\n",
      "Epoch   4 Batch   92/269 - Train Accuracy: 0.6914, Validation Accuracy: 0.7002, Loss: 0.5094\n",
      "Epoch   4 Batch   93/269 - Train Accuracy: 0.6916, Validation Accuracy: 0.6938, Loss: 0.4967\n",
      "Epoch   4 Batch   94/269 - Train Accuracy: 0.6752, Validation Accuracy: 0.6922, Loss: 0.5255\n",
      "Epoch   4 Batch   95/269 - Train Accuracy: 0.6727, Validation Accuracy: 0.7014, Loss: 0.5100\n",
      "Epoch   4 Batch   96/269 - Train Accuracy: 0.6909, Validation Accuracy: 0.7035, Loss: 0.5178\n",
      "Epoch   4 Batch   97/269 - Train Accuracy: 0.6873, Validation Accuracy: 0.6931, Loss: 0.5140\n",
      "Epoch   4 Batch   98/269 - Train Accuracy: 0.6749, Validation Accuracy: 0.6958, Loss: 0.5111\n",
      "Epoch   4 Batch   99/269 - Train Accuracy: 0.6783, Validation Accuracy: 0.6985, Loss: 0.5277\n",
      "Epoch   4 Batch  100/269 - Train Accuracy: 0.7003, Validation Accuracy: 0.7035, Loss: 0.5037\n",
      "Epoch   4 Batch  101/269 - Train Accuracy: 0.6538, Validation Accuracy: 0.6934, Loss: 0.5437\n",
      "Epoch   4 Batch  102/269 - Train Accuracy: 0.6709, Validation Accuracy: 0.6949, Loss: 0.5176\n",
      "Epoch   4 Batch  103/269 - Train Accuracy: 0.7053, Validation Accuracy: 0.7097, Loss: 0.5072\n",
      "Epoch   4 Batch  104/269 - Train Accuracy: 0.6870, Validation Accuracy: 0.7082, Loss: 0.5086\n",
      "Epoch   4 Batch  105/269 - Train Accuracy: 0.6663, Validation Accuracy: 0.6909, Loss: 0.5107\n",
      "Epoch   4 Batch  106/269 - Train Accuracy: 0.6731, Validation Accuracy: 0.6996, Loss: 0.5029\n",
      "Epoch   4 Batch  107/269 - Train Accuracy: 0.6821, Validation Accuracy: 0.7087, Loss: 0.5377\n",
      "Epoch   4 Batch  108/269 - Train Accuracy: 0.6920, Validation Accuracy: 0.7064, Loss: 0.5154\n",
      "Epoch   4 Batch  109/269 - Train Accuracy: 0.6682, Validation Accuracy: 0.6949, Loss: 0.5139\n",
      "Epoch   4 Batch  110/269 - Train Accuracy: 0.6820, Validation Accuracy: 0.7005, Loss: 0.5104\n",
      "Epoch   4 Batch  111/269 - Train Accuracy: 0.6663, Validation Accuracy: 0.7013, Loss: 0.5443\n",
      "Epoch   4 Batch  112/269 - Train Accuracy: 0.6843, Validation Accuracy: 0.6905, Loss: 0.5098\n",
      "Epoch   4 Batch  113/269 - Train Accuracy: 0.6866, Validation Accuracy: 0.6901, Loss: 0.4888\n",
      "Epoch   4 Batch  114/269 - Train Accuracy: 0.6940, Validation Accuracy: 0.7005, Loss: 0.5069\n",
      "Epoch   4 Batch  115/269 - Train Accuracy: 0.6861, Validation Accuracy: 0.7072, Loss: 0.5293\n",
      "Epoch   4 Batch  116/269 - Train Accuracy: 0.6917, Validation Accuracy: 0.7048, Loss: 0.5167\n",
      "Epoch   4 Batch  117/269 - Train Accuracy: 0.6975, Validation Accuracy: 0.6989, Loss: 0.5051\n",
      "Epoch   4 Batch  118/269 - Train Accuracy: 0.6990, Validation Accuracy: 0.7108, Loss: 0.4883\n",
      "Epoch   4 Batch  119/269 - Train Accuracy: 0.6880, Validation Accuracy: 0.7091, Loss: 0.5372\n",
      "Epoch   4 Batch  120/269 - Train Accuracy: 0.6744, Validation Accuracy: 0.6966, Loss: 0.5239\n",
      "Epoch   4 Batch  121/269 - Train Accuracy: 0.6868, Validation Accuracy: 0.7033, Loss: 0.4959\n",
      "Epoch   4 Batch  122/269 - Train Accuracy: 0.6922, Validation Accuracy: 0.7139, Loss: 0.4993\n",
      "Epoch   4 Batch  123/269 - Train Accuracy: 0.6912, Validation Accuracy: 0.7085, Loss: 0.5196\n",
      "Epoch   4 Batch  124/269 - Train Accuracy: 0.6824, Validation Accuracy: 0.7012, Loss: 0.4943\n",
      "Epoch   4 Batch  125/269 - Train Accuracy: 0.7049, Validation Accuracy: 0.7103, Loss: 0.4944\n",
      "Epoch   4 Batch  126/269 - Train Accuracy: 0.7051, Validation Accuracy: 0.7106, Loss: 0.4968\n",
      "Epoch   4 Batch  127/269 - Train Accuracy: 0.6821, Validation Accuracy: 0.7167, Loss: 0.5246\n",
      "Epoch   4 Batch  128/269 - Train Accuracy: 0.6934, Validation Accuracy: 0.6986, Loss: 0.5024\n",
      "Epoch   4 Batch  129/269 - Train Accuracy: 0.6862, Validation Accuracy: 0.7115, Loss: 0.5020\n",
      "Epoch   4 Batch  130/269 - Train Accuracy: 0.6794, Validation Accuracy: 0.7114, Loss: 0.5160\n",
      "Epoch   4 Batch  131/269 - Train Accuracy: 0.6946, Validation Accuracy: 0.7181, Loss: 0.5223\n",
      "Epoch   4 Batch  132/269 - Train Accuracy: 0.6896, Validation Accuracy: 0.7022, Loss: 0.5047\n",
      "Epoch   4 Batch  133/269 - Train Accuracy: 0.7035, Validation Accuracy: 0.7062, Loss: 0.4822\n",
      "Epoch   4 Batch  134/269 - Train Accuracy: 0.6767, Validation Accuracy: 0.7071, Loss: 0.5074\n",
      "Epoch   4 Batch  135/269 - Train Accuracy: 0.6683, Validation Accuracy: 0.7148, Loss: 0.5397\n",
      "Epoch   4 Batch  136/269 - Train Accuracy: 0.6604, Validation Accuracy: 0.6923, Loss: 0.5348\n",
      "Epoch   4 Batch  137/269 - Train Accuracy: 0.6857, Validation Accuracy: 0.6991, Loss: 0.5280\n",
      "Epoch   4 Batch  138/269 - Train Accuracy: 0.7040, Validation Accuracy: 0.7183, Loss: 0.5174\n",
      "Epoch   4 Batch  139/269 - Train Accuracy: 0.7153, Validation Accuracy: 0.7112, Loss: 0.4843\n",
      "Epoch   4 Batch  140/269 - Train Accuracy: 0.6975, Validation Accuracy: 0.7177, Loss: 0.5163\n",
      "Epoch   4 Batch  141/269 - Train Accuracy: 0.6985, Validation Accuracy: 0.7132, Loss: 0.5107\n",
      "Epoch   4 Batch  142/269 - Train Accuracy: 0.7014, Validation Accuracy: 0.7125, Loss: 0.4935\n",
      "Epoch   4 Batch  143/269 - Train Accuracy: 0.7027, Validation Accuracy: 0.7159, Loss: 0.4926\n",
      "Epoch   4 Batch  144/269 - Train Accuracy: 0.7000, Validation Accuracy: 0.7131, Loss: 0.4813\n",
      "Epoch   4 Batch  145/269 - Train Accuracy: 0.7113, Validation Accuracy: 0.7053, Loss: 0.4912\n",
      "Epoch   4 Batch  146/269 - Train Accuracy: 0.7058, Validation Accuracy: 0.7080, Loss: 0.4856\n",
      "Epoch   4 Batch  147/269 - Train Accuracy: 0.7054, Validation Accuracy: 0.7035, Loss: 0.4721\n",
      "Epoch   4 Batch  148/269 - Train Accuracy: 0.6897, Validation Accuracy: 0.7082, Loss: 0.4996\n",
      "Epoch   4 Batch  149/269 - Train Accuracy: 0.6820, Validation Accuracy: 0.7114, Loss: 0.5002\n",
      "Epoch   4 Batch  150/269 - Train Accuracy: 0.7074, Validation Accuracy: 0.7215, Loss: 0.4952\n",
      "Epoch   4 Batch  151/269 - Train Accuracy: 0.7225, Validation Accuracy: 0.7223, Loss: 0.4722\n",
      "Epoch   4 Batch  152/269 - Train Accuracy: 0.7078, Validation Accuracy: 0.7179, Loss: 0.4892\n",
      "Epoch   4 Batch  153/269 - Train Accuracy: 0.6966, Validation Accuracy: 0.7176, Loss: 0.4897\n",
      "Epoch   4 Batch  154/269 - Train Accuracy: 0.6863, Validation Accuracy: 0.7058, Loss: 0.5027\n",
      "Epoch   4 Batch  155/269 - Train Accuracy: 0.7175, Validation Accuracy: 0.7122, Loss: 0.4674\n",
      "Epoch   4 Batch  156/269 - Train Accuracy: 0.6871, Validation Accuracy: 0.7159, Loss: 0.5123\n",
      "Epoch   4 Batch  157/269 - Train Accuracy: 0.6934, Validation Accuracy: 0.7269, Loss: 0.4947\n",
      "Epoch   4 Batch  158/269 - Train Accuracy: 0.6910, Validation Accuracy: 0.7148, Loss: 0.4861\n",
      "Epoch   4 Batch  159/269 - Train Accuracy: 0.6922, Validation Accuracy: 0.7137, Loss: 0.4917\n",
      "Epoch   4 Batch  160/269 - Train Accuracy: 0.7145, Validation Accuracy: 0.7212, Loss: 0.4877\n",
      "Epoch   4 Batch  161/269 - Train Accuracy: 0.7000, Validation Accuracy: 0.7289, Loss: 0.4908\n",
      "Epoch   4 Batch  162/269 - Train Accuracy: 0.7043, Validation Accuracy: 0.7122, Loss: 0.4838\n",
      "Epoch   4 Batch  163/269 - Train Accuracy: 0.7077, Validation Accuracy: 0.7211, Loss: 0.4880\n",
      "Epoch   4 Batch  164/269 - Train Accuracy: 0.7241, Validation Accuracy: 0.7318, Loss: 0.4859\n",
      "Epoch   4 Batch  165/269 - Train Accuracy: 0.6928, Validation Accuracy: 0.7168, Loss: 0.5044\n",
      "Epoch   4 Batch  166/269 - Train Accuracy: 0.7112, Validation Accuracy: 0.7215, Loss: 0.4592\n",
      "Epoch   4 Batch  167/269 - Train Accuracy: 0.7111, Validation Accuracy: 0.7187, Loss: 0.4880\n",
      "Epoch   4 Batch  168/269 - Train Accuracy: 0.7013, Validation Accuracy: 0.7265, Loss: 0.4887\n",
      "Epoch   4 Batch  169/269 - Train Accuracy: 0.7005, Validation Accuracy: 0.7254, Loss: 0.4887\n",
      "Epoch   4 Batch  170/269 - Train Accuracy: 0.6984, Validation Accuracy: 0.7216, Loss: 0.4790\n",
      "Epoch   4 Batch  171/269 - Train Accuracy: 0.7094, Validation Accuracy: 0.7216, Loss: 0.5029\n",
      "Epoch   4 Batch  172/269 - Train Accuracy: 0.7130, Validation Accuracy: 0.7216, Loss: 0.4921\n",
      "Epoch   4 Batch  173/269 - Train Accuracy: 0.7024, Validation Accuracy: 0.7185, Loss: 0.4713\n",
      "Epoch   4 Batch  174/269 - Train Accuracy: 0.6957, Validation Accuracy: 0.7160, Loss: 0.4870\n",
      "Epoch   4 Batch  175/269 - Train Accuracy: 0.7125, Validation Accuracy: 0.7226, Loss: 0.5017\n",
      "Epoch   4 Batch  176/269 - Train Accuracy: 0.6946, Validation Accuracy: 0.7149, Loss: 0.5137\n",
      "Epoch   4 Batch  177/269 - Train Accuracy: 0.7153, Validation Accuracy: 0.7204, Loss: 0.4598\n",
      "Epoch   4 Batch  178/269 - Train Accuracy: 0.6858, Validation Accuracy: 0.7114, Loss: 0.4916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   4 Batch  179/269 - Train Accuracy: 0.7049, Validation Accuracy: 0.7196, Loss: 0.4806\n",
      "Epoch   4 Batch  180/269 - Train Accuracy: 0.7111, Validation Accuracy: 0.7211, Loss: 0.4742\n",
      "Epoch   4 Batch  181/269 - Train Accuracy: 0.7053, Validation Accuracy: 0.7185, Loss: 0.4840\n",
      "Epoch   4 Batch  182/269 - Train Accuracy: 0.7107, Validation Accuracy: 0.7114, Loss: 0.4825\n",
      "Epoch   4 Batch  183/269 - Train Accuracy: 0.7471, Validation Accuracy: 0.7109, Loss: 0.4182\n",
      "Epoch   4 Batch  184/269 - Train Accuracy: 0.6881, Validation Accuracy: 0.7123, Loss: 0.4958\n",
      "Epoch   4 Batch  185/269 - Train Accuracy: 0.7215, Validation Accuracy: 0.7222, Loss: 0.4699\n",
      "Epoch   4 Batch  186/269 - Train Accuracy: 0.6890, Validation Accuracy: 0.7204, Loss: 0.4929\n",
      "Epoch   4 Batch  187/269 - Train Accuracy: 0.7179, Validation Accuracy: 0.7212, Loss: 0.4673\n",
      "Epoch   4 Batch  188/269 - Train Accuracy: 0.7191, Validation Accuracy: 0.7203, Loss: 0.4691\n",
      "Epoch   4 Batch  189/269 - Train Accuracy: 0.7254, Validation Accuracy: 0.7171, Loss: 0.4623\n",
      "Epoch   4 Batch  190/269 - Train Accuracy: 0.6988, Validation Accuracy: 0.7088, Loss: 0.4624\n",
      "Epoch   4 Batch  191/269 - Train Accuracy: 0.7051, Validation Accuracy: 0.7169, Loss: 0.4719\n",
      "Epoch   4 Batch  192/269 - Train Accuracy: 0.7297, Validation Accuracy: 0.7225, Loss: 0.4762\n",
      "Epoch   4 Batch  193/269 - Train Accuracy: 0.7274, Validation Accuracy: 0.7124, Loss: 0.4674\n",
      "Epoch   4 Batch  194/269 - Train Accuracy: 0.7195, Validation Accuracy: 0.7220, Loss: 0.4796\n",
      "Epoch   4 Batch  195/269 - Train Accuracy: 0.7120, Validation Accuracy: 0.7163, Loss: 0.4706\n",
      "Epoch   4 Batch  196/269 - Train Accuracy: 0.7097, Validation Accuracy: 0.7170, Loss: 0.4707\n",
      "Epoch   4 Batch  197/269 - Train Accuracy: 0.6937, Validation Accuracy: 0.7136, Loss: 0.4924\n",
      "Epoch   4 Batch  198/269 - Train Accuracy: 0.7099, Validation Accuracy: 0.7233, Loss: 0.4988\n",
      "Epoch   4 Batch  199/269 - Train Accuracy: 0.7080, Validation Accuracy: 0.7208, Loss: 0.4816\n",
      "Epoch   4 Batch  200/269 - Train Accuracy: 0.6899, Validation Accuracy: 0.7123, Loss: 0.4846\n",
      "Epoch   4 Batch  201/269 - Train Accuracy: 0.7127, Validation Accuracy: 0.7161, Loss: 0.4762\n",
      "Epoch   4 Batch  202/269 - Train Accuracy: 0.7188, Validation Accuracy: 0.7176, Loss: 0.4683\n",
      "Epoch   4 Batch  203/269 - Train Accuracy: 0.6962, Validation Accuracy: 0.7179, Loss: 0.5066\n",
      "Epoch   4 Batch  204/269 - Train Accuracy: 0.6983, Validation Accuracy: 0.7181, Loss: 0.4916\n",
      "Epoch   4 Batch  205/269 - Train Accuracy: 0.7153, Validation Accuracy: 0.7185, Loss: 0.4676\n",
      "Epoch   4 Batch  206/269 - Train Accuracy: 0.6941, Validation Accuracy: 0.7219, Loss: 0.4938\n",
      "Epoch   4 Batch  207/269 - Train Accuracy: 0.7209, Validation Accuracy: 0.7157, Loss: 0.4534\n",
      "Epoch   4 Batch  208/269 - Train Accuracy: 0.6956, Validation Accuracy: 0.7222, Loss: 0.4883\n",
      "Epoch   4 Batch  209/269 - Train Accuracy: 0.7164, Validation Accuracy: 0.7231, Loss: 0.4780\n",
      "Epoch   4 Batch  210/269 - Train Accuracy: 0.7306, Validation Accuracy: 0.7143, Loss: 0.4631\n",
      "Epoch   4 Batch  211/269 - Train Accuracy: 0.7018, Validation Accuracy: 0.7260, Loss: 0.4733\n",
      "Epoch   4 Batch  212/269 - Train Accuracy: 0.7247, Validation Accuracy: 0.7221, Loss: 0.4684\n",
      "Epoch   4 Batch  213/269 - Train Accuracy: 0.7127, Validation Accuracy: 0.7175, Loss: 0.4668\n",
      "Epoch   4 Batch  214/269 - Train Accuracy: 0.7085, Validation Accuracy: 0.7170, Loss: 0.4712\n",
      "Epoch   4 Batch  215/269 - Train Accuracy: 0.7335, Validation Accuracy: 0.7223, Loss: 0.4393\n",
      "Epoch   4 Batch  216/269 - Train Accuracy: 0.6902, Validation Accuracy: 0.7245, Loss: 0.5016\n",
      "Epoch   4 Batch  217/269 - Train Accuracy: 0.6928, Validation Accuracy: 0.7260, Loss: 0.4811\n",
      "Epoch   4 Batch  218/269 - Train Accuracy: 0.7044, Validation Accuracy: 0.7245, Loss: 0.4810\n",
      "Epoch   4 Batch  219/269 - Train Accuracy: 0.7312, Validation Accuracy: 0.7250, Loss: 0.4817\n",
      "Epoch   4 Batch  220/269 - Train Accuracy: 0.7100, Validation Accuracy: 0.7286, Loss: 0.4384\n",
      "Epoch   4 Batch  221/269 - Train Accuracy: 0.7398, Validation Accuracy: 0.7282, Loss: 0.4664\n",
      "Epoch   4 Batch  222/269 - Train Accuracy: 0.7378, Validation Accuracy: 0.7235, Loss: 0.4524\n",
      "Epoch   4 Batch  223/269 - Train Accuracy: 0.7246, Validation Accuracy: 0.7274, Loss: 0.4510\n",
      "Epoch   4 Batch  224/269 - Train Accuracy: 0.7291, Validation Accuracy: 0.7253, Loss: 0.4779\n",
      "Epoch   4 Batch  225/269 - Train Accuracy: 0.7154, Validation Accuracy: 0.7270, Loss: 0.4642\n",
      "Epoch   4 Batch  226/269 - Train Accuracy: 0.7270, Validation Accuracy: 0.7188, Loss: 0.4631\n",
      "Epoch   4 Batch  227/269 - Train Accuracy: 0.7541, Validation Accuracy: 0.7180, Loss: 0.4175\n",
      "Epoch   4 Batch  228/269 - Train Accuracy: 0.7052, Validation Accuracy: 0.7219, Loss: 0.4557\n",
      "Epoch   4 Batch  229/269 - Train Accuracy: 0.7057, Validation Accuracy: 0.7182, Loss: 0.4622\n",
      "Epoch   4 Batch  230/269 - Train Accuracy: 0.7254, Validation Accuracy: 0.7144, Loss: 0.4549\n",
      "Epoch   4 Batch  231/269 - Train Accuracy: 0.7095, Validation Accuracy: 0.7119, Loss: 0.4864\n",
      "Epoch   4 Batch  232/269 - Train Accuracy: 0.6933, Validation Accuracy: 0.7184, Loss: 0.4774\n",
      "Epoch   4 Batch  233/269 - Train Accuracy: 0.7203, Validation Accuracy: 0.7224, Loss: 0.4722\n",
      "Epoch   4 Batch  234/269 - Train Accuracy: 0.7195, Validation Accuracy: 0.7253, Loss: 0.4553\n",
      "Epoch   4 Batch  235/269 - Train Accuracy: 0.7307, Validation Accuracy: 0.7304, Loss: 0.4492\n",
      "Epoch   4 Batch  236/269 - Train Accuracy: 0.7110, Validation Accuracy: 0.7171, Loss: 0.4502\n",
      "Epoch   4 Batch  237/269 - Train Accuracy: 0.7020, Validation Accuracy: 0.7248, Loss: 0.4509\n",
      "Epoch   4 Batch  238/269 - Train Accuracy: 0.7339, Validation Accuracy: 0.7255, Loss: 0.4473\n",
      "Epoch   4 Batch  239/269 - Train Accuracy: 0.7112, Validation Accuracy: 0.7301, Loss: 0.4451\n",
      "Epoch   4 Batch  240/269 - Train Accuracy: 0.7334, Validation Accuracy: 0.7213, Loss: 0.4230\n",
      "Epoch   4 Batch  241/269 - Train Accuracy: 0.7150, Validation Accuracy: 0.7285, Loss: 0.4646\n",
      "Epoch   4 Batch  242/269 - Train Accuracy: 0.7218, Validation Accuracy: 0.7112, Loss: 0.4460\n",
      "Epoch   4 Batch  243/269 - Train Accuracy: 0.7201, Validation Accuracy: 0.7079, Loss: 0.4423\n",
      "Epoch   4 Batch  244/269 - Train Accuracy: 0.7185, Validation Accuracy: 0.7296, Loss: 0.4548\n",
      "Epoch   4 Batch  245/269 - Train Accuracy: 0.7007, Validation Accuracy: 0.7243, Loss: 0.4773\n",
      "Epoch   4 Batch  246/269 - Train Accuracy: 0.7090, Validation Accuracy: 0.7222, Loss: 0.4527\n",
      "Epoch   4 Batch  247/269 - Train Accuracy: 0.7069, Validation Accuracy: 0.7237, Loss: 0.4714\n",
      "Epoch   4 Batch  248/269 - Train Accuracy: 0.7307, Validation Accuracy: 0.7261, Loss: 0.4434\n",
      "Epoch   4 Batch  249/269 - Train Accuracy: 0.7354, Validation Accuracy: 0.7177, Loss: 0.4309\n",
      "Epoch   4 Batch  250/269 - Train Accuracy: 0.7148, Validation Accuracy: 0.7186, Loss: 0.4636\n",
      "Epoch   4 Batch  251/269 - Train Accuracy: 0.7414, Validation Accuracy: 0.7251, Loss: 0.4389\n",
      "Epoch   4 Batch  252/269 - Train Accuracy: 0.7142, Validation Accuracy: 0.7273, Loss: 0.4513\n",
      "Epoch   4 Batch  253/269 - Train Accuracy: 0.7052, Validation Accuracy: 0.7256, Loss: 0.4538\n",
      "Epoch   4 Batch  254/269 - Train Accuracy: 0.7225, Validation Accuracy: 0.7296, Loss: 0.4406\n",
      "Epoch   4 Batch  255/269 - Train Accuracy: 0.7272, Validation Accuracy: 0.7255, Loss: 0.4419\n",
      "Epoch   4 Batch  256/269 - Train Accuracy: 0.7176, Validation Accuracy: 0.7267, Loss: 0.4531\n",
      "Epoch   4 Batch  257/269 - Train Accuracy: 0.7076, Validation Accuracy: 0.7290, Loss: 0.4569\n",
      "Epoch   4 Batch  258/269 - Train Accuracy: 0.7386, Validation Accuracy: 0.7264, Loss: 0.4513\n",
      "Epoch   4 Batch  259/269 - Train Accuracy: 0.7401, Validation Accuracy: 0.7310, Loss: 0.4467\n",
      "Epoch   4 Batch  260/269 - Train Accuracy: 0.7151, Validation Accuracy: 0.7315, Loss: 0.4682\n",
      "Epoch   4 Batch  261/269 - Train Accuracy: 0.6989, Validation Accuracy: 0.7332, Loss: 0.4703\n",
      "Epoch   4 Batch  262/269 - Train Accuracy: 0.7357, Validation Accuracy: 0.7301, Loss: 0.4447\n",
      "Epoch   4 Batch  263/269 - Train Accuracy: 0.7187, Validation Accuracy: 0.7301, Loss: 0.4585\n",
      "Epoch   4 Batch  264/269 - Train Accuracy: 0.7192, Validation Accuracy: 0.7299, Loss: 0.4650\n",
      "Epoch   4 Batch  265/269 - Train Accuracy: 0.7218, Validation Accuracy: 0.7356, Loss: 0.4526\n",
      "Epoch   4 Batch  266/269 - Train Accuracy: 0.7334, Validation Accuracy: 0.7362, Loss: 0.4398\n",
      "Epoch   4 Batch  267/269 - Train Accuracy: 0.7227, Validation Accuracy: 0.7310, Loss: 0.4501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5 Batch    1/269 - Train Accuracy: 0.7132, Validation Accuracy: 0.7338, Loss: 0.4598\n",
      "Epoch   5 Batch    2/269 - Train Accuracy: 0.7334, Validation Accuracy: 0.7338, Loss: 0.4490\n",
      "Epoch   5 Batch    3/269 - Train Accuracy: 0.7178, Validation Accuracy: 0.7214, Loss: 0.4538\n",
      "Epoch   5 Batch    4/269 - Train Accuracy: 0.7045, Validation Accuracy: 0.7282, Loss: 0.4682\n",
      "Epoch   5 Batch    5/269 - Train Accuracy: 0.6955, Validation Accuracy: 0.7245, Loss: 0.4613\n",
      "Epoch   5 Batch    6/269 - Train Accuracy: 0.7317, Validation Accuracy: 0.7229, Loss: 0.4290\n",
      "Epoch   5 Batch    7/269 - Train Accuracy: 0.7269, Validation Accuracy: 0.7289, Loss: 0.4363\n",
      "Epoch   5 Batch    8/269 - Train Accuracy: 0.7091, Validation Accuracy: 0.7257, Loss: 0.4680\n",
      "Epoch   5 Batch    9/269 - Train Accuracy: 0.7266, Validation Accuracy: 0.7306, Loss: 0.4518\n",
      "Epoch   5 Batch   10/269 - Train Accuracy: 0.7229, Validation Accuracy: 0.7314, Loss: 0.4448\n",
      "Epoch   5 Batch   11/269 - Train Accuracy: 0.7250, Validation Accuracy: 0.7286, Loss: 0.4482\n",
      "Epoch   5 Batch   12/269 - Train Accuracy: 0.7096, Validation Accuracy: 0.7260, Loss: 0.4691\n",
      "Epoch   5 Batch   13/269 - Train Accuracy: 0.7383, Validation Accuracy: 0.7310, Loss: 0.4076\n",
      "Epoch   5 Batch   14/269 - Train Accuracy: 0.7295, Validation Accuracy: 0.7322, Loss: 0.4388\n",
      "Epoch   5 Batch   15/269 - Train Accuracy: 0.7253, Validation Accuracy: 0.7284, Loss: 0.4218\n",
      "Epoch   5 Batch   16/269 - Train Accuracy: 0.7307, Validation Accuracy: 0.7253, Loss: 0.4384\n",
      "Epoch   5 Batch   17/269 - Train Accuracy: 0.7407, Validation Accuracy: 0.7232, Loss: 0.4232\n",
      "Epoch   5 Batch   18/269 - Train Accuracy: 0.7147, Validation Accuracy: 0.7295, Loss: 0.4466\n",
      "Epoch   5 Batch   19/269 - Train Accuracy: 0.7513, Validation Accuracy: 0.7306, Loss: 0.4068\n",
      "Epoch   5 Batch   20/269 - Train Accuracy: 0.7295, Validation Accuracy: 0.7327, Loss: 0.4468\n",
      "Epoch   5 Batch   21/269 - Train Accuracy: 0.7120, Validation Accuracy: 0.7300, Loss: 0.4680\n",
      "Epoch   5 Batch   22/269 - Train Accuracy: 0.7383, Validation Accuracy: 0.7289, Loss: 0.4237\n",
      "Epoch   5 Batch   23/269 - Train Accuracy: 0.7227, Validation Accuracy: 0.7267, Loss: 0.4284\n",
      "Epoch   5 Batch   24/269 - Train Accuracy: 0.7253, Validation Accuracy: 0.7259, Loss: 0.4479\n",
      "Epoch   5 Batch   25/269 - Train Accuracy: 0.7183, Validation Accuracy: 0.7309, Loss: 0.4578\n",
      "Epoch   5 Batch   26/269 - Train Accuracy: 0.7428, Validation Accuracy: 0.7287, Loss: 0.4047\n",
      "Epoch   5 Batch   27/269 - Train Accuracy: 0.7241, Validation Accuracy: 0.7332, Loss: 0.4209\n",
      "Epoch   5 Batch   28/269 - Train Accuracy: 0.7017, Validation Accuracy: 0.7369, Loss: 0.4596\n",
      "Epoch   5 Batch   29/269 - Train Accuracy: 0.7273, Validation Accuracy: 0.7369, Loss: 0.4476\n",
      "Epoch   5 Batch   30/269 - Train Accuracy: 0.7348, Validation Accuracy: 0.7367, Loss: 0.4276\n",
      "Epoch   5 Batch   31/269 - Train Accuracy: 0.7433, Validation Accuracy: 0.7370, Loss: 0.4232\n",
      "Epoch   5 Batch   32/269 - Train Accuracy: 0.7340, Validation Accuracy: 0.7346, Loss: 0.4288\n",
      "Epoch   5 Batch   33/269 - Train Accuracy: 0.7560, Validation Accuracy: 0.7330, Loss: 0.4157\n",
      "Epoch   5 Batch   34/269 - Train Accuracy: 0.7311, Validation Accuracy: 0.7329, Loss: 0.4219\n",
      "Epoch   5 Batch   35/269 - Train Accuracy: 0.7202, Validation Accuracy: 0.7311, Loss: 0.4457\n",
      "Epoch   5 Batch   36/269 - Train Accuracy: 0.7050, Validation Accuracy: 0.7374, Loss: 0.4327\n",
      "Epoch   5 Batch   37/269 - Train Accuracy: 0.7442, Validation Accuracy: 0.7336, Loss: 0.4268\n",
      "Epoch   5 Batch   38/269 - Train Accuracy: 0.7281, Validation Accuracy: 0.7315, Loss: 0.4316\n",
      "Epoch   5 Batch   39/269 - Train Accuracy: 0.7297, Validation Accuracy: 0.7362, Loss: 0.4233\n",
      "Epoch   5 Batch   40/269 - Train Accuracy: 0.7341, Validation Accuracy: 0.7375, Loss: 0.4392\n",
      "Epoch   5 Batch   41/269 - Train Accuracy: 0.7287, Validation Accuracy: 0.7377, Loss: 0.4341\n",
      "Epoch   5 Batch   42/269 - Train Accuracy: 0.7385, Validation Accuracy: 0.7354, Loss: 0.4066\n",
      "Epoch   5 Batch   43/269 - Train Accuracy: 0.7510, Validation Accuracy: 0.7354, Loss: 0.4465\n",
      "Epoch   5 Batch   44/269 - Train Accuracy: 0.7199, Validation Accuracy: 0.7314, Loss: 0.4255\n",
      "Epoch   5 Batch   45/269 - Train Accuracy: 0.7214, Validation Accuracy: 0.7276, Loss: 0.4423\n",
      "Epoch   5 Batch   46/269 - Train Accuracy: 0.7241, Validation Accuracy: 0.7290, Loss: 0.4418\n",
      "Epoch   5 Batch   47/269 - Train Accuracy: 0.7459, Validation Accuracy: 0.7277, Loss: 0.3959\n",
      "Epoch   5 Batch   48/269 - Train Accuracy: 0.7385, Validation Accuracy: 0.7202, Loss: 0.4095\n",
      "Epoch   5 Batch   49/269 - Train Accuracy: 0.7324, Validation Accuracy: 0.7298, Loss: 0.4384\n",
      "Epoch   5 Batch   50/269 - Train Accuracy: 0.6941, Validation Accuracy: 0.7243, Loss: 0.4443\n",
      "Epoch   5 Batch   51/269 - Train Accuracy: 0.7348, Validation Accuracy: 0.7257, Loss: 0.4344\n",
      "Epoch   5 Batch   52/269 - Train Accuracy: 0.7116, Validation Accuracy: 0.7220, Loss: 0.4076\n",
      "Epoch   5 Batch   53/269 - Train Accuracy: 0.7132, Validation Accuracy: 0.7334, Loss: 0.4492\n",
      "Epoch   5 Batch   54/269 - Train Accuracy: 0.7435, Validation Accuracy: 0.7369, Loss: 0.4382\n",
      "Epoch   5 Batch   55/269 - Train Accuracy: 0.7533, Validation Accuracy: 0.7322, Loss: 0.4100\n",
      "Epoch   5 Batch   56/269 - Train Accuracy: 0.7271, Validation Accuracy: 0.7404, Loss: 0.4280\n",
      "Epoch   5 Batch   57/269 - Train Accuracy: 0.7277, Validation Accuracy: 0.7320, Loss: 0.4317\n",
      "Epoch   5 Batch   58/269 - Train Accuracy: 0.7326, Validation Accuracy: 0.7416, Loss: 0.4207\n",
      "Epoch   5 Batch   59/269 - Train Accuracy: 0.7498, Validation Accuracy: 0.7345, Loss: 0.4029\n",
      "Epoch   5 Batch   60/269 - Train Accuracy: 0.7441, Validation Accuracy: 0.7417, Loss: 0.4032\n",
      "Epoch   5 Batch   61/269 - Train Accuracy: 0.7411, Validation Accuracy: 0.7454, Loss: 0.3867\n",
      "Epoch   5 Batch   62/269 - Train Accuracy: 0.7525, Validation Accuracy: 0.7384, Loss: 0.4128\n",
      "Epoch   5 Batch   63/269 - Train Accuracy: 0.7320, Validation Accuracy: 0.7331, Loss: 0.4220\n",
      "Epoch   5 Batch   64/269 - Train Accuracy: 0.7440, Validation Accuracy: 0.7338, Loss: 0.4100\n",
      "Epoch   5 Batch   65/269 - Train Accuracy: 0.7369, Validation Accuracy: 0.7399, Loss: 0.4132\n",
      "Epoch   5 Batch   66/269 - Train Accuracy: 0.7327, Validation Accuracy: 0.7390, Loss: 0.4063\n",
      "Epoch   5 Batch   67/269 - Train Accuracy: 0.7436, Validation Accuracy: 0.7341, Loss: 0.4260\n",
      "Epoch   5 Batch   68/269 - Train Accuracy: 0.7140, Validation Accuracy: 0.7377, Loss: 0.4270\n",
      "Epoch   5 Batch   69/269 - Train Accuracy: 0.6949, Validation Accuracy: 0.7347, Loss: 0.4637\n",
      "Epoch   5 Batch   70/269 - Train Accuracy: 0.7463, Validation Accuracy: 0.7404, Loss: 0.4280\n",
      "Epoch   5 Batch   71/269 - Train Accuracy: 0.7199, Validation Accuracy: 0.7298, Loss: 0.4429\n",
      "Epoch   5 Batch   72/269 - Train Accuracy: 0.7402, Validation Accuracy: 0.7401, Loss: 0.4142\n",
      "Epoch   5 Batch   73/269 - Train Accuracy: 0.7297, Validation Accuracy: 0.7441, Loss: 0.4340\n",
      "Epoch   5 Batch   74/269 - Train Accuracy: 0.7355, Validation Accuracy: 0.7393, Loss: 0.4249\n",
      "Epoch   5 Batch   75/269 - Train Accuracy: 0.7372, Validation Accuracy: 0.7273, Loss: 0.4132\n",
      "Epoch   5 Batch   76/269 - Train Accuracy: 0.7326, Validation Accuracy: 0.7328, Loss: 0.4188\n",
      "Epoch   5 Batch   77/269 - Train Accuracy: 0.7189, Validation Accuracy: 0.7308, Loss: 0.4147\n",
      "Epoch   5 Batch   78/269 - Train Accuracy: 0.7516, Validation Accuracy: 0.7304, Loss: 0.4118\n",
      "Epoch   5 Batch   79/269 - Train Accuracy: 0.7365, Validation Accuracy: 0.7361, Loss: 0.4076\n",
      "Epoch   5 Batch   80/269 - Train Accuracy: 0.7453, Validation Accuracy: 0.7438, Loss: 0.4124\n",
      "Epoch   5 Batch   81/269 - Train Accuracy: 0.7316, Validation Accuracy: 0.7377, Loss: 0.4298\n",
      "Epoch   5 Batch   82/269 - Train Accuracy: 0.7473, Validation Accuracy: 0.7402, Loss: 0.4005\n",
      "Epoch   5 Batch   83/269 - Train Accuracy: 0.7285, Validation Accuracy: 0.7376, Loss: 0.4219\n",
      "Epoch   5 Batch   84/269 - Train Accuracy: 0.7474, Validation Accuracy: 0.7323, Loss: 0.4052\n",
      "Epoch   5 Batch   85/269 - Train Accuracy: 0.7485, Validation Accuracy: 0.7346, Loss: 0.4111\n",
      "Epoch   5 Batch   86/269 - Train Accuracy: 0.7374, Validation Accuracy: 0.7404, Loss: 0.4086\n",
      "Epoch   5 Batch   87/269 - Train Accuracy: 0.7403, Validation Accuracy: 0.7371, Loss: 0.4426\n",
      "Epoch   5 Batch   88/269 - Train Accuracy: 0.7265, Validation Accuracy: 0.7389, Loss: 0.4159\n",
      "Epoch   5 Batch   89/269 - Train Accuracy: 0.7590, Validation Accuracy: 0.7425, Loss: 0.4119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5 Batch   90/269 - Train Accuracy: 0.7166, Validation Accuracy: 0.7385, Loss: 0.4300\n",
      "Epoch   5 Batch   91/269 - Train Accuracy: 0.7625, Validation Accuracy: 0.7365, Loss: 0.3970\n",
      "Epoch   5 Batch   92/269 - Train Accuracy: 0.7440, Validation Accuracy: 0.7352, Loss: 0.4014\n",
      "Epoch   5 Batch   93/269 - Train Accuracy: 0.7466, Validation Accuracy: 0.7377, Loss: 0.3896\n",
      "Epoch   5 Batch   94/269 - Train Accuracy: 0.7344, Validation Accuracy: 0.7329, Loss: 0.4213\n",
      "Epoch   5 Batch   95/269 - Train Accuracy: 0.7409, Validation Accuracy: 0.7389, Loss: 0.4093\n",
      "Epoch   5 Batch   96/269 - Train Accuracy: 0.7375, Validation Accuracy: 0.7328, Loss: 0.4031\n",
      "Epoch   5 Batch   97/269 - Train Accuracy: 0.7419, Validation Accuracy: 0.7381, Loss: 0.4037\n",
      "Epoch   5 Batch   98/269 - Train Accuracy: 0.7513, Validation Accuracy: 0.7357, Loss: 0.4113\n",
      "Epoch   5 Batch   99/269 - Train Accuracy: 0.7370, Validation Accuracy: 0.7319, Loss: 0.4158\n",
      "Epoch   5 Batch  100/269 - Train Accuracy: 0.7576, Validation Accuracy: 0.7374, Loss: 0.3993\n",
      "Epoch   5 Batch  101/269 - Train Accuracy: 0.7113, Validation Accuracy: 0.7387, Loss: 0.4363\n",
      "Epoch   5 Batch  102/269 - Train Accuracy: 0.7258, Validation Accuracy: 0.7386, Loss: 0.4096\n",
      "Epoch   5 Batch  103/269 - Train Accuracy: 0.7495, Validation Accuracy: 0.7373, Loss: 0.4017\n",
      "Epoch   5 Batch  104/269 - Train Accuracy: 0.7365, Validation Accuracy: 0.7368, Loss: 0.4015\n",
      "Epoch   5 Batch  105/269 - Train Accuracy: 0.7451, Validation Accuracy: 0.7417, Loss: 0.4076\n",
      "Epoch   5 Batch  106/269 - Train Accuracy: 0.7352, Validation Accuracy: 0.7390, Loss: 0.3968\n",
      "Epoch   5 Batch  107/269 - Train Accuracy: 0.7382, Validation Accuracy: 0.7321, Loss: 0.4335\n",
      "Epoch   5 Batch  108/269 - Train Accuracy: 0.7462, Validation Accuracy: 0.7496, Loss: 0.4170\n",
      "Epoch   5 Batch  109/269 - Train Accuracy: 0.7229, Validation Accuracy: 0.7468, Loss: 0.4066\n",
      "Epoch   5 Batch  110/269 - Train Accuracy: 0.7518, Validation Accuracy: 0.7309, Loss: 0.4010\n",
      "Epoch   5 Batch  111/269 - Train Accuracy: 0.7326, Validation Accuracy: 0.7373, Loss: 0.4300\n",
      "Epoch   5 Batch  112/269 - Train Accuracy: 0.7459, Validation Accuracy: 0.7425, Loss: 0.4020\n",
      "Epoch   5 Batch  113/269 - Train Accuracy: 0.7384, Validation Accuracy: 0.7470, Loss: 0.3911\n",
      "Epoch   5 Batch  114/269 - Train Accuracy: 0.7553, Validation Accuracy: 0.7351, Loss: 0.4028\n",
      "Epoch   5 Batch  115/269 - Train Accuracy: 0.7293, Validation Accuracy: 0.7408, Loss: 0.4236\n",
      "Epoch   5 Batch  116/269 - Train Accuracy: 0.7485, Validation Accuracy: 0.7479, Loss: 0.4051\n",
      "Epoch   5 Batch  117/269 - Train Accuracy: 0.7459, Validation Accuracy: 0.7480, Loss: 0.3964\n",
      "Epoch   5 Batch  118/269 - Train Accuracy: 0.7635, Validation Accuracy: 0.7383, Loss: 0.3931\n",
      "Epoch   5 Batch  119/269 - Train Accuracy: 0.7252, Validation Accuracy: 0.7377, Loss: 0.4250\n",
      "Epoch   5 Batch  120/269 - Train Accuracy: 0.7357, Validation Accuracy: 0.7501, Loss: 0.4133\n",
      "Epoch   5 Batch  121/269 - Train Accuracy: 0.7516, Validation Accuracy: 0.7504, Loss: 0.3964\n",
      "Epoch   5 Batch  122/269 - Train Accuracy: 0.7458, Validation Accuracy: 0.7402, Loss: 0.3980\n",
      "Epoch   5 Batch  123/269 - Train Accuracy: 0.7508, Validation Accuracy: 0.7418, Loss: 0.4073\n",
      "Epoch   5 Batch  124/269 - Train Accuracy: 0.7510, Validation Accuracy: 0.7442, Loss: 0.3922\n",
      "Epoch   5 Batch  125/269 - Train Accuracy: 0.7530, Validation Accuracy: 0.7421, Loss: 0.3913\n",
      "Epoch   5 Batch  126/269 - Train Accuracy: 0.7504, Validation Accuracy: 0.7382, Loss: 0.3935\n",
      "Epoch   5 Batch  127/269 - Train Accuracy: 0.7324, Validation Accuracy: 0.7361, Loss: 0.4148\n",
      "Epoch   5 Batch  128/269 - Train Accuracy: 0.7406, Validation Accuracy: 0.7436, Loss: 0.4008\n",
      "Epoch   5 Batch  129/269 - Train Accuracy: 0.7470, Validation Accuracy: 0.7471, Loss: 0.4025\n",
      "Epoch   5 Batch  130/269 - Train Accuracy: 0.7462, Validation Accuracy: 0.7421, Loss: 0.4128\n",
      "Epoch   5 Batch  131/269 - Train Accuracy: 0.7312, Validation Accuracy: 0.7388, Loss: 0.4126\n",
      "Epoch   5 Batch  132/269 - Train Accuracy: 0.7410, Validation Accuracy: 0.7426, Loss: 0.4002\n",
      "Epoch   5 Batch  133/269 - Train Accuracy: 0.7573, Validation Accuracy: 0.7455, Loss: 0.3852\n",
      "Epoch   5 Batch  134/269 - Train Accuracy: 0.7187, Validation Accuracy: 0.7350, Loss: 0.4161\n",
      "Epoch   5 Batch  135/269 - Train Accuracy: 0.7351, Validation Accuracy: 0.7367, Loss: 0.4319\n",
      "Epoch   5 Batch  136/269 - Train Accuracy: 0.7199, Validation Accuracy: 0.7428, Loss: 0.4312\n",
      "Epoch   5 Batch  137/269 - Train Accuracy: 0.7376, Validation Accuracy: 0.7414, Loss: 0.4234\n",
      "Epoch   5 Batch  138/269 - Train Accuracy: 0.7397, Validation Accuracy: 0.7395, Loss: 0.4119\n",
      "Epoch   5 Batch  139/269 - Train Accuracy: 0.7619, Validation Accuracy: 0.7386, Loss: 0.3888\n",
      "Epoch   5 Batch  140/269 - Train Accuracy: 0.7427, Validation Accuracy: 0.7470, Loss: 0.4178\n",
      "Epoch   5 Batch  141/269 - Train Accuracy: 0.7543, Validation Accuracy: 0.7467, Loss: 0.4079\n",
      "Epoch   5 Batch  142/269 - Train Accuracy: 0.7403, Validation Accuracy: 0.7425, Loss: 0.3942\n",
      "Epoch   5 Batch  143/269 - Train Accuracy: 0.7607, Validation Accuracy: 0.7493, Loss: 0.3892\n",
      "Epoch   5 Batch  144/269 - Train Accuracy: 0.7671, Validation Accuracy: 0.7432, Loss: 0.3827\n",
      "Epoch   5 Batch  145/269 - Train Accuracy: 0.7480, Validation Accuracy: 0.7433, Loss: 0.3863\n",
      "Epoch   5 Batch  146/269 - Train Accuracy: 0.7619, Validation Accuracy: 0.7433, Loss: 0.3908\n",
      "Epoch   5 Batch  147/269 - Train Accuracy: 0.7628, Validation Accuracy: 0.7499, Loss: 0.3789\n",
      "Epoch   5 Batch  148/269 - Train Accuracy: 0.7307, Validation Accuracy: 0.7410, Loss: 0.3980\n",
      "Epoch   5 Batch  149/269 - Train Accuracy: 0.7252, Validation Accuracy: 0.7369, Loss: 0.4036\n",
      "Epoch   5 Batch  150/269 - Train Accuracy: 0.7473, Validation Accuracy: 0.7506, Loss: 0.3959\n",
      "Epoch   5 Batch  151/269 - Train Accuracy: 0.7664, Validation Accuracy: 0.7511, Loss: 0.3800\n",
      "Epoch   5 Batch  152/269 - Train Accuracy: 0.7481, Validation Accuracy: 0.7406, Loss: 0.3939\n",
      "Epoch   5 Batch  153/269 - Train Accuracy: 0.7476, Validation Accuracy: 0.7423, Loss: 0.3949\n",
      "Epoch   5 Batch  154/269 - Train Accuracy: 0.7607, Validation Accuracy: 0.7497, Loss: 0.3996\n",
      "Epoch   5 Batch  155/269 - Train Accuracy: 0.7652, Validation Accuracy: 0.7568, Loss: 0.3722\n",
      "Epoch   5 Batch  156/269 - Train Accuracy: 0.7256, Validation Accuracy: 0.7518, Loss: 0.4013\n",
      "Epoch   5 Batch  157/269 - Train Accuracy: 0.7499, Validation Accuracy: 0.7529, Loss: 0.3824\n",
      "Epoch   5 Batch  158/269 - Train Accuracy: 0.7569, Validation Accuracy: 0.7595, Loss: 0.3864\n",
      "Epoch   5 Batch  159/269 - Train Accuracy: 0.7433, Validation Accuracy: 0.7527, Loss: 0.3931\n",
      "Epoch   5 Batch  160/269 - Train Accuracy: 0.7646, Validation Accuracy: 0.7518, Loss: 0.3884\n",
      "Epoch   5 Batch  161/269 - Train Accuracy: 0.7514, Validation Accuracy: 0.7488, Loss: 0.3920\n",
      "Epoch   5 Batch  162/269 - Train Accuracy: 0.7552, Validation Accuracy: 0.7572, Loss: 0.3847\n",
      "Epoch   5 Batch  163/269 - Train Accuracy: 0.7578, Validation Accuracy: 0.7553, Loss: 0.3866\n",
      "Epoch   5 Batch  164/269 - Train Accuracy: 0.7667, Validation Accuracy: 0.7532, Loss: 0.3836\n",
      "Epoch   5 Batch  165/269 - Train Accuracy: 0.7378, Validation Accuracy: 0.7495, Loss: 0.3951\n",
      "Epoch   5 Batch  166/269 - Train Accuracy: 0.7663, Validation Accuracy: 0.7558, Loss: 0.3650\n",
      "Epoch   5 Batch  167/269 - Train Accuracy: 0.7536, Validation Accuracy: 0.7599, Loss: 0.3832\n",
      "Epoch   5 Batch  168/269 - Train Accuracy: 0.7509, Validation Accuracy: 0.7638, Loss: 0.3923\n",
      "Epoch   5 Batch  169/269 - Train Accuracy: 0.7654, Validation Accuracy: 0.7551, Loss: 0.3905\n",
      "Epoch   5 Batch  170/269 - Train Accuracy: 0.7661, Validation Accuracy: 0.7517, Loss: 0.3820\n",
      "Epoch   5 Batch  171/269 - Train Accuracy: 0.7622, Validation Accuracy: 0.7496, Loss: 0.3905\n",
      "Epoch   5 Batch  172/269 - Train Accuracy: 0.7762, Validation Accuracy: 0.7549, Loss: 0.3944\n",
      "Epoch   5 Batch  173/269 - Train Accuracy: 0.7573, Validation Accuracy: 0.7540, Loss: 0.3733\n",
      "Epoch   5 Batch  174/269 - Train Accuracy: 0.7548, Validation Accuracy: 0.7501, Loss: 0.3879\n",
      "Epoch   5 Batch  175/269 - Train Accuracy: 0.7600, Validation Accuracy: 0.7480, Loss: 0.3985\n",
      "Epoch   5 Batch  176/269 - Train Accuracy: 0.7454, Validation Accuracy: 0.7511, Loss: 0.4153\n",
      "Epoch   5 Batch  177/269 - Train Accuracy: 0.7698, Validation Accuracy: 0.7503, Loss: 0.3683\n",
      "Epoch   5 Batch  178/269 - Train Accuracy: 0.7570, Validation Accuracy: 0.7474, Loss: 0.3957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5 Batch  179/269 - Train Accuracy: 0.7411, Validation Accuracy: 0.7507, Loss: 0.3912\n",
      "Epoch   5 Batch  180/269 - Train Accuracy: 0.7705, Validation Accuracy: 0.7541, Loss: 0.3793\n",
      "Epoch   5 Batch  181/269 - Train Accuracy: 0.7595, Validation Accuracy: 0.7489, Loss: 0.3879\n",
      "Epoch   5 Batch  182/269 - Train Accuracy: 0.7547, Validation Accuracy: 0.7500, Loss: 0.3901\n",
      "Epoch   5 Batch  183/269 - Train Accuracy: 0.7872, Validation Accuracy: 0.7472, Loss: 0.3354\n",
      "Epoch   5 Batch  184/269 - Train Accuracy: 0.7427, Validation Accuracy: 0.7507, Loss: 0.3940\n",
      "Epoch   5 Batch  185/269 - Train Accuracy: 0.7753, Validation Accuracy: 0.7579, Loss: 0.3887\n",
      "Epoch   5 Batch  186/269 - Train Accuracy: 0.7404, Validation Accuracy: 0.7484, Loss: 0.3933\n",
      "Epoch   5 Batch  187/269 - Train Accuracy: 0.7631, Validation Accuracy: 0.7534, Loss: 0.3810\n",
      "Epoch   5 Batch  188/269 - Train Accuracy: 0.7667, Validation Accuracy: 0.7637, Loss: 0.3681\n",
      "Epoch   5 Batch  189/269 - Train Accuracy: 0.7617, Validation Accuracy: 0.7525, Loss: 0.3775\n",
      "Epoch   5 Batch  190/269 - Train Accuracy: 0.7527, Validation Accuracy: 0.7544, Loss: 0.3727\n",
      "Epoch   5 Batch  191/269 - Train Accuracy: 0.7518, Validation Accuracy: 0.7474, Loss: 0.3797\n",
      "Epoch   5 Batch  192/269 - Train Accuracy: 0.7437, Validation Accuracy: 0.7534, Loss: 0.3898\n",
      "Epoch   5 Batch  193/269 - Train Accuracy: 0.7704, Validation Accuracy: 0.7641, Loss: 0.3820\n",
      "Epoch   5 Batch  194/269 - Train Accuracy: 0.7561, Validation Accuracy: 0.7437, Loss: 0.3780\n",
      "Epoch   5 Batch  195/269 - Train Accuracy: 0.7558, Validation Accuracy: 0.7494, Loss: 0.3832\n",
      "Epoch   5 Batch  196/269 - Train Accuracy: 0.7581, Validation Accuracy: 0.7634, Loss: 0.3755\n",
      "Epoch   5 Batch  197/269 - Train Accuracy: 0.7449, Validation Accuracy: 0.7593, Loss: 0.3990\n",
      "Epoch   5 Batch  198/269 - Train Accuracy: 0.7633, Validation Accuracy: 0.7547, Loss: 0.4003\n",
      "Epoch   5 Batch  199/269 - Train Accuracy: 0.7453, Validation Accuracy: 0.7605, Loss: 0.3908\n",
      "Epoch   5 Batch  200/269 - Train Accuracy: 0.7487, Validation Accuracy: 0.7540, Loss: 0.3936\n",
      "Epoch   5 Batch  201/269 - Train Accuracy: 0.7691, Validation Accuracy: 0.7462, Loss: 0.3808\n",
      "Epoch   5 Batch  202/269 - Train Accuracy: 0.7482, Validation Accuracy: 0.7514, Loss: 0.3755\n",
      "Epoch   5 Batch  203/269 - Train Accuracy: 0.7610, Validation Accuracy: 0.7565, Loss: 0.4072\n",
      "Epoch   5 Batch  204/269 - Train Accuracy: 0.7590, Validation Accuracy: 0.7569, Loss: 0.3921\n",
      "Epoch   5 Batch  205/269 - Train Accuracy: 0.7625, Validation Accuracy: 0.7479, Loss: 0.3777\n",
      "Epoch   5 Batch  206/269 - Train Accuracy: 0.7437, Validation Accuracy: 0.7595, Loss: 0.3999\n",
      "Epoch   5 Batch  207/269 - Train Accuracy: 0.7707, Validation Accuracy: 0.7520, Loss: 0.3650\n",
      "Epoch   5 Batch  208/269 - Train Accuracy: 0.7736, Validation Accuracy: 0.7566, Loss: 0.3926\n",
      "Epoch   5 Batch  209/269 - Train Accuracy: 0.7795, Validation Accuracy: 0.7567, Loss: 0.3783\n",
      "Epoch   5 Batch  210/269 - Train Accuracy: 0.7863, Validation Accuracy: 0.7601, Loss: 0.3638\n",
      "Epoch   5 Batch  211/269 - Train Accuracy: 0.7630, Validation Accuracy: 0.7589, Loss: 0.3836\n",
      "Epoch   5 Batch  212/269 - Train Accuracy: 0.7670, Validation Accuracy: 0.7616, Loss: 0.3674\n",
      "Epoch   5 Batch  213/269 - Train Accuracy: 0.7653, Validation Accuracy: 0.7669, Loss: 0.3669\n",
      "Epoch   5 Batch  214/269 - Train Accuracy: 0.7743, Validation Accuracy: 0.7623, Loss: 0.3750\n",
      "Epoch   5 Batch  215/269 - Train Accuracy: 0.7896, Validation Accuracy: 0.7629, Loss: 0.3490\n",
      "Epoch   5 Batch  216/269 - Train Accuracy: 0.7490, Validation Accuracy: 0.7664, Loss: 0.4063\n",
      "Epoch   5 Batch  217/269 - Train Accuracy: 0.7604, Validation Accuracy: 0.7621, Loss: 0.3870\n",
      "Epoch   5 Batch  218/269 - Train Accuracy: 0.7717, Validation Accuracy: 0.7610, Loss: 0.3881\n",
      "Epoch   5 Batch  219/269 - Train Accuracy: 0.7620, Validation Accuracy: 0.7568, Loss: 0.3883\n",
      "Epoch   5 Batch  220/269 - Train Accuracy: 0.7605, Validation Accuracy: 0.7590, Loss: 0.3593\n",
      "Epoch   5 Batch  221/269 - Train Accuracy: 0.7958, Validation Accuracy: 0.7587, Loss: 0.3712\n",
      "Epoch   5 Batch  222/269 - Train Accuracy: 0.7790, Validation Accuracy: 0.7569, Loss: 0.3576\n",
      "Epoch   5 Batch  223/269 - Train Accuracy: 0.7610, Validation Accuracy: 0.7614, Loss: 0.3714\n",
      "Epoch   5 Batch  224/269 - Train Accuracy: 0.7707, Validation Accuracy: 0.7565, Loss: 0.3835\n",
      "Epoch   5 Batch  225/269 - Train Accuracy: 0.7654, Validation Accuracy: 0.7565, Loss: 0.3755\n",
      "Epoch   5 Batch  226/269 - Train Accuracy: 0.7746, Validation Accuracy: 0.7544, Loss: 0.3712\n",
      "Epoch   5 Batch  227/269 - Train Accuracy: 0.7953, Validation Accuracy: 0.7574, Loss: 0.3374\n",
      "Epoch   5 Batch  228/269 - Train Accuracy: 0.7554, Validation Accuracy: 0.7605, Loss: 0.3682\n",
      "Epoch   5 Batch  229/269 - Train Accuracy: 0.7597, Validation Accuracy: 0.7607, Loss: 0.3662\n",
      "Epoch   5 Batch  230/269 - Train Accuracy: 0.7716, Validation Accuracy: 0.7561, Loss: 0.3568\n",
      "Epoch   5 Batch  231/269 - Train Accuracy: 0.7779, Validation Accuracy: 0.7563, Loss: 0.3855\n",
      "Epoch   5 Batch  232/269 - Train Accuracy: 0.7638, Validation Accuracy: 0.7541, Loss: 0.3821\n",
      "Epoch   5 Batch  233/269 - Train Accuracy: 0.7917, Validation Accuracy: 0.7496, Loss: 0.3699\n",
      "Epoch   5 Batch  234/269 - Train Accuracy: 0.7719, Validation Accuracy: 0.7596, Loss: 0.3638\n",
      "Epoch   5 Batch  235/269 - Train Accuracy: 0.7733, Validation Accuracy: 0.7575, Loss: 0.3583\n",
      "Epoch   5 Batch  236/269 - Train Accuracy: 0.7660, Validation Accuracy: 0.7623, Loss: 0.3638\n",
      "Epoch   5 Batch  237/269 - Train Accuracy: 0.7816, Validation Accuracy: 0.7649, Loss: 0.3682\n",
      "Epoch   5 Batch  238/269 - Train Accuracy: 0.7863, Validation Accuracy: 0.7614, Loss: 0.3647\n",
      "Epoch   5 Batch  239/269 - Train Accuracy: 0.7536, Validation Accuracy: 0.7591, Loss: 0.3671\n",
      "Epoch   5 Batch  240/269 - Train Accuracy: 0.7932, Validation Accuracy: 0.7570, Loss: 0.3380\n",
      "Epoch   5 Batch  241/269 - Train Accuracy: 0.7678, Validation Accuracy: 0.7645, Loss: 0.3816\n",
      "Epoch   5 Batch  242/269 - Train Accuracy: 0.7717, Validation Accuracy: 0.7630, Loss: 0.3590\n",
      "Epoch   5 Batch  243/269 - Train Accuracy: 0.7868, Validation Accuracy: 0.7659, Loss: 0.3502\n",
      "Epoch   5 Batch  244/269 - Train Accuracy: 0.7788, Validation Accuracy: 0.7663, Loss: 0.3589\n",
      "Epoch   5 Batch  245/269 - Train Accuracy: 0.7420, Validation Accuracy: 0.7624, Loss: 0.3820\n",
      "Epoch   5 Batch  246/269 - Train Accuracy: 0.7642, Validation Accuracy: 0.7581, Loss: 0.3673\n",
      "Epoch   5 Batch  247/269 - Train Accuracy: 0.7615, Validation Accuracy: 0.7602, Loss: 0.3741\n",
      "Epoch   5 Batch  248/269 - Train Accuracy: 0.7666, Validation Accuracy: 0.7613, Loss: 0.3523\n",
      "Epoch   5 Batch  249/269 - Train Accuracy: 0.7947, Validation Accuracy: 0.7646, Loss: 0.3469\n",
      "Epoch   5 Batch  250/269 - Train Accuracy: 0.7804, Validation Accuracy: 0.7597, Loss: 0.3667\n",
      "Epoch   5 Batch  251/269 - Train Accuracy: 0.7905, Validation Accuracy: 0.7605, Loss: 0.3543\n",
      "Epoch   5 Batch  252/269 - Train Accuracy: 0.7660, Validation Accuracy: 0.7583, Loss: 0.3628\n",
      "Epoch   5 Batch  253/269 - Train Accuracy: 0.7503, Validation Accuracy: 0.7663, Loss: 0.3745\n",
      "Epoch   5 Batch  254/269 - Train Accuracy: 0.7750, Validation Accuracy: 0.7629, Loss: 0.3513\n",
      "Epoch   5 Batch  255/269 - Train Accuracy: 0.7768, Validation Accuracy: 0.7629, Loss: 0.3550\n",
      "Epoch   5 Batch  256/269 - Train Accuracy: 0.7622, Validation Accuracy: 0.7571, Loss: 0.3622\n",
      "Epoch   5 Batch  257/269 - Train Accuracy: 0.7703, Validation Accuracy: 0.7595, Loss: 0.3690\n",
      "Epoch   5 Batch  258/269 - Train Accuracy: 0.7915, Validation Accuracy: 0.7620, Loss: 0.3629\n",
      "Epoch   5 Batch  259/269 - Train Accuracy: 0.7876, Validation Accuracy: 0.7666, Loss: 0.3622\n",
      "Epoch   5 Batch  260/269 - Train Accuracy: 0.7618, Validation Accuracy: 0.7752, Loss: 0.3751\n",
      "Epoch   5 Batch  261/269 - Train Accuracy: 0.7618, Validation Accuracy: 0.7714, Loss: 0.3797\n",
      "Epoch   5 Batch  262/269 - Train Accuracy: 0.7950, Validation Accuracy: 0.7620, Loss: 0.3609\n",
      "Epoch   5 Batch  263/269 - Train Accuracy: 0.7770, Validation Accuracy: 0.7690, Loss: 0.3808\n",
      "Epoch   5 Batch  264/269 - Train Accuracy: 0.7680, Validation Accuracy: 0.7721, Loss: 0.3793\n",
      "Epoch   5 Batch  265/269 - Train Accuracy: 0.7715, Validation Accuracy: 0.7691, Loss: 0.3659\n",
      "Epoch   5 Batch  266/269 - Train Accuracy: 0.7812, Validation Accuracy: 0.7724, Loss: 0.3586\n",
      "Epoch   5 Batch  267/269 - Train Accuracy: 0.7786, Validation Accuracy: 0.7694, Loss: 0.3676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   6 Batch    1/269 - Train Accuracy: 0.7708, Validation Accuracy: 0.7580, Loss: 0.3672\n",
      "Epoch   6 Batch    2/269 - Train Accuracy: 0.7791, Validation Accuracy: 0.7645, Loss: 0.3635\n",
      "Epoch   6 Batch    3/269 - Train Accuracy: 0.7804, Validation Accuracy: 0.7751, Loss: 0.3706\n",
      "Epoch   6 Batch    4/269 - Train Accuracy: 0.7473, Validation Accuracy: 0.7752, Loss: 0.3717\n",
      "Epoch   6 Batch    5/269 - Train Accuracy: 0.7691, Validation Accuracy: 0.7757, Loss: 0.3667\n",
      "Epoch   6 Batch    6/269 - Train Accuracy: 0.7986, Validation Accuracy: 0.7715, Loss: 0.3456\n",
      "Epoch   6 Batch    7/269 - Train Accuracy: 0.7797, Validation Accuracy: 0.7731, Loss: 0.3525\n",
      "Epoch   6 Batch    8/269 - Train Accuracy: 0.7633, Validation Accuracy: 0.7750, Loss: 0.3730\n",
      "Epoch   6 Batch    9/269 - Train Accuracy: 0.7879, Validation Accuracy: 0.7739, Loss: 0.3706\n",
      "Epoch   6 Batch   10/269 - Train Accuracy: 0.7839, Validation Accuracy: 0.7666, Loss: 0.3573\n",
      "Epoch   6 Batch   11/269 - Train Accuracy: 0.7855, Validation Accuracy: 0.7693, Loss: 0.3612\n",
      "Epoch   6 Batch   12/269 - Train Accuracy: 0.7555, Validation Accuracy: 0.7719, Loss: 0.3781\n",
      "Epoch   6 Batch   13/269 - Train Accuracy: 0.7871, Validation Accuracy: 0.7691, Loss: 0.3319\n",
      "Epoch   6 Batch   14/269 - Train Accuracy: 0.7726, Validation Accuracy: 0.7662, Loss: 0.3515\n",
      "Epoch   6 Batch   15/269 - Train Accuracy: 0.7727, Validation Accuracy: 0.7714, Loss: 0.3438\n",
      "Epoch   6 Batch   16/269 - Train Accuracy: 0.7732, Validation Accuracy: 0.7754, Loss: 0.3535\n",
      "Epoch   6 Batch   17/269 - Train Accuracy: 0.7866, Validation Accuracy: 0.7719, Loss: 0.3373\n",
      "Epoch   6 Batch   18/269 - Train Accuracy: 0.7638, Validation Accuracy: 0.7700, Loss: 0.3598\n",
      "Epoch   6 Batch   19/269 - Train Accuracy: 0.7977, Validation Accuracy: 0.7756, Loss: 0.3306\n",
      "Epoch   6 Batch   20/269 - Train Accuracy: 0.7718, Validation Accuracy: 0.7812, Loss: 0.3574\n",
      "Epoch   6 Batch   21/269 - Train Accuracy: 0.7561, Validation Accuracy: 0.7723, Loss: 0.3800\n",
      "Epoch   6 Batch   22/269 - Train Accuracy: 0.7812, Validation Accuracy: 0.7757, Loss: 0.3402\n",
      "Epoch   6 Batch   23/269 - Train Accuracy: 0.7828, Validation Accuracy: 0.7786, Loss: 0.3516\n",
      "Epoch   6 Batch   24/269 - Train Accuracy: 0.7837, Validation Accuracy: 0.7755, Loss: 0.3608\n",
      "Epoch   6 Batch   25/269 - Train Accuracy: 0.7611, Validation Accuracy: 0.7771, Loss: 0.3739\n",
      "Epoch   6 Batch   26/269 - Train Accuracy: 0.7919, Validation Accuracy: 0.7745, Loss: 0.3258\n",
      "Epoch   6 Batch   27/269 - Train Accuracy: 0.7782, Validation Accuracy: 0.7718, Loss: 0.3407\n",
      "Epoch   6 Batch   28/269 - Train Accuracy: 0.7454, Validation Accuracy: 0.7717, Loss: 0.3743\n",
      "Epoch   6 Batch   29/269 - Train Accuracy: 0.7734, Validation Accuracy: 0.7793, Loss: 0.3662\n",
      "Epoch   6 Batch   30/269 - Train Accuracy: 0.7906, Validation Accuracy: 0.7773, Loss: 0.3410\n",
      "Epoch   6 Batch   31/269 - Train Accuracy: 0.7932, Validation Accuracy: 0.7741, Loss: 0.3441\n",
      "Epoch   6 Batch   32/269 - Train Accuracy: 0.7796, Validation Accuracy: 0.7726, Loss: 0.3511\n",
      "Epoch   6 Batch   33/269 - Train Accuracy: 0.7895, Validation Accuracy: 0.7791, Loss: 0.3394\n",
      "Epoch   6 Batch   34/269 - Train Accuracy: 0.7821, Validation Accuracy: 0.7781, Loss: 0.3479\n",
      "Epoch   6 Batch   35/269 - Train Accuracy: 0.7728, Validation Accuracy: 0.7701, Loss: 0.3631\n",
      "Epoch   6 Batch   36/269 - Train Accuracy: 0.7810, Validation Accuracy: 0.7770, Loss: 0.3545\n",
      "Epoch   6 Batch   37/269 - Train Accuracy: 0.7774, Validation Accuracy: 0.7794, Loss: 0.3517\n",
      "Epoch   6 Batch   38/269 - Train Accuracy: 0.7674, Validation Accuracy: 0.7827, Loss: 0.3489\n",
      "Epoch   6 Batch   39/269 - Train Accuracy: 0.7885, Validation Accuracy: 0.7744, Loss: 0.3450\n",
      "Epoch   6 Batch   40/269 - Train Accuracy: 0.7630, Validation Accuracy: 0.7765, Loss: 0.3605\n",
      "Epoch   6 Batch   41/269 - Train Accuracy: 0.7785, Validation Accuracy: 0.7847, Loss: 0.3528\n",
      "Epoch   6 Batch   42/269 - Train Accuracy: 0.7934, Validation Accuracy: 0.7813, Loss: 0.3234\n",
      "Epoch   6 Batch   43/269 - Train Accuracy: 0.7946, Validation Accuracy: 0.7776, Loss: 0.3615\n",
      "Epoch   6 Batch   44/269 - Train Accuracy: 0.7681, Validation Accuracy: 0.7747, Loss: 0.3557\n",
      "Epoch   6 Batch   45/269 - Train Accuracy: 0.7735, Validation Accuracy: 0.7725, Loss: 0.3554\n",
      "Epoch   6 Batch   46/269 - Train Accuracy: 0.7731, Validation Accuracy: 0.7716, Loss: 0.3596\n",
      "Epoch   6 Batch   47/269 - Train Accuracy: 0.7945, Validation Accuracy: 0.7718, Loss: 0.3176\n",
      "Epoch   6 Batch   48/269 - Train Accuracy: 0.7961, Validation Accuracy: 0.7772, Loss: 0.3353\n",
      "Epoch   6 Batch   49/269 - Train Accuracy: 0.7751, Validation Accuracy: 0.7705, Loss: 0.3513\n",
      "Epoch   6 Batch   50/269 - Train Accuracy: 0.7602, Validation Accuracy: 0.7765, Loss: 0.3663\n",
      "Epoch   6 Batch   51/269 - Train Accuracy: 0.7892, Validation Accuracy: 0.7787, Loss: 0.3487\n",
      "Epoch   6 Batch   52/269 - Train Accuracy: 0.7728, Validation Accuracy: 0.7806, Loss: 0.3243\n",
      "Epoch   6 Batch   53/269 - Train Accuracy: 0.7838, Validation Accuracy: 0.7734, Loss: 0.3627\n",
      "Epoch   6 Batch   54/269 - Train Accuracy: 0.7903, Validation Accuracy: 0.7770, Loss: 0.3563\n",
      "Epoch   6 Batch   55/269 - Train Accuracy: 0.8139, Validation Accuracy: 0.7836, Loss: 0.3346\n",
      "Epoch   6 Batch   56/269 - Train Accuracy: 0.7695, Validation Accuracy: 0.7733, Loss: 0.3474\n",
      "Epoch   6 Batch   57/269 - Train Accuracy: 0.7919, Validation Accuracy: 0.7742, Loss: 0.3581\n",
      "Epoch   6 Batch   58/269 - Train Accuracy: 0.7852, Validation Accuracy: 0.7820, Loss: 0.3348\n",
      "Epoch   6 Batch   59/269 - Train Accuracy: 0.8008, Validation Accuracy: 0.7777, Loss: 0.3204\n",
      "Epoch   6 Batch   60/269 - Train Accuracy: 0.7918, Validation Accuracy: 0.7779, Loss: 0.3186\n",
      "Epoch   6 Batch   61/269 - Train Accuracy: 0.7924, Validation Accuracy: 0.7804, Loss: 0.3163\n",
      "Epoch   6 Batch   62/269 - Train Accuracy: 0.8028, Validation Accuracy: 0.7755, Loss: 0.3321\n",
      "Epoch   6 Batch   63/269 - Train Accuracy: 0.7861, Validation Accuracy: 0.7810, Loss: 0.3471\n",
      "Epoch   6 Batch   64/269 - Train Accuracy: 0.7898, Validation Accuracy: 0.7784, Loss: 0.3337\n",
      "Epoch   6 Batch   65/269 - Train Accuracy: 0.7637, Validation Accuracy: 0.7730, Loss: 0.3387\n",
      "Epoch   6 Batch   66/269 - Train Accuracy: 0.7949, Validation Accuracy: 0.7848, Loss: 0.3315\n",
      "Epoch   6 Batch   67/269 - Train Accuracy: 0.7789, Validation Accuracy: 0.7828, Loss: 0.3440\n",
      "Epoch   6 Batch   68/269 - Train Accuracy: 0.7613, Validation Accuracy: 0.7806, Loss: 0.3477\n",
      "Epoch   6 Batch   69/269 - Train Accuracy: 0.7608, Validation Accuracy: 0.7785, Loss: 0.3739\n",
      "Epoch   6 Batch   70/269 - Train Accuracy: 0.7962, Validation Accuracy: 0.7807, Loss: 0.3442\n",
      "Epoch   6 Batch   71/269 - Train Accuracy: 0.7885, Validation Accuracy: 0.7796, Loss: 0.3566\n",
      "Epoch   6 Batch   72/269 - Train Accuracy: 0.7846, Validation Accuracy: 0.7908, Loss: 0.3348\n",
      "Epoch   6 Batch   73/269 - Train Accuracy: 0.7829, Validation Accuracy: 0.7876, Loss: 0.3516\n",
      "Epoch   6 Batch   74/269 - Train Accuracy: 0.7933, Validation Accuracy: 0.7816, Loss: 0.3425\n",
      "Epoch   6 Batch   75/269 - Train Accuracy: 0.7918, Validation Accuracy: 0.7843, Loss: 0.3320\n",
      "Epoch   6 Batch   76/269 - Train Accuracy: 0.7775, Validation Accuracy: 0.7852, Loss: 0.3358\n",
      "Epoch   6 Batch   77/269 - Train Accuracy: 0.7888, Validation Accuracy: 0.7862, Loss: 0.3353\n",
      "Epoch   6 Batch   78/269 - Train Accuracy: 0.8058, Validation Accuracy: 0.7868, Loss: 0.3353\n",
      "Epoch   6 Batch   79/269 - Train Accuracy: 0.7888, Validation Accuracy: 0.7796, Loss: 0.3268\n",
      "Epoch   6 Batch   80/269 - Train Accuracy: 0.7931, Validation Accuracy: 0.7808, Loss: 0.3292\n",
      "Epoch   6 Batch   81/269 - Train Accuracy: 0.7794, Validation Accuracy: 0.7797, Loss: 0.3493\n",
      "Epoch   6 Batch   82/269 - Train Accuracy: 0.7930, Validation Accuracy: 0.7741, Loss: 0.3276\n",
      "Epoch   6 Batch   83/269 - Train Accuracy: 0.7830, Validation Accuracy: 0.7797, Loss: 0.3482\n",
      "Epoch   6 Batch   84/269 - Train Accuracy: 0.7959, Validation Accuracy: 0.7739, Loss: 0.3339\n",
      "Epoch   6 Batch   85/269 - Train Accuracy: 0.7959, Validation Accuracy: 0.7749, Loss: 0.3319\n",
      "Epoch   6 Batch   86/269 - Train Accuracy: 0.7891, Validation Accuracy: 0.7749, Loss: 0.3307\n",
      "Epoch   6 Batch   87/269 - Train Accuracy: 0.7791, Validation Accuracy: 0.7792, Loss: 0.3472\n",
      "Epoch   6 Batch   88/269 - Train Accuracy: 0.7696, Validation Accuracy: 0.7782, Loss: 0.3361\n",
      "Epoch   6 Batch   89/269 - Train Accuracy: 0.8001, Validation Accuracy: 0.7749, Loss: 0.3308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   6 Batch   90/269 - Train Accuracy: 0.7574, Validation Accuracy: 0.7828, Loss: 0.3512\n",
      "Epoch   6 Batch   91/269 - Train Accuracy: 0.8012, Validation Accuracy: 0.7794, Loss: 0.3251\n",
      "Epoch   6 Batch   92/269 - Train Accuracy: 0.7989, Validation Accuracy: 0.7799, Loss: 0.3213\n",
      "Epoch   6 Batch   93/269 - Train Accuracy: 0.7996, Validation Accuracy: 0.7747, Loss: 0.3132\n",
      "Epoch   6 Batch   94/269 - Train Accuracy: 0.7811, Validation Accuracy: 0.7781, Loss: 0.3473\n",
      "Epoch   6 Batch   95/269 - Train Accuracy: 0.7813, Validation Accuracy: 0.7786, Loss: 0.3282\n",
      "Epoch   6 Batch   96/269 - Train Accuracy: 0.7837, Validation Accuracy: 0.7850, Loss: 0.3225\n",
      "Epoch   6 Batch   97/269 - Train Accuracy: 0.8046, Validation Accuracy: 0.7796, Loss: 0.3294\n",
      "Epoch   6 Batch   98/269 - Train Accuracy: 0.8091, Validation Accuracy: 0.7854, Loss: 0.3261\n",
      "Epoch   6 Batch   99/269 - Train Accuracy: 0.7739, Validation Accuracy: 0.7820, Loss: 0.3365\n",
      "Epoch   6 Batch  100/269 - Train Accuracy: 0.8089, Validation Accuracy: 0.7798, Loss: 0.3249\n",
      "Epoch   6 Batch  101/269 - Train Accuracy: 0.7682, Validation Accuracy: 0.7856, Loss: 0.3557\n",
      "Epoch   6 Batch  102/269 - Train Accuracy: 0.7863, Validation Accuracy: 0.7790, Loss: 0.3288\n",
      "Epoch   6 Batch  103/269 - Train Accuracy: 0.8050, Validation Accuracy: 0.7946, Loss: 0.3330\n",
      "Epoch   6 Batch  104/269 - Train Accuracy: 0.7793, Validation Accuracy: 0.7894, Loss: 0.3251\n",
      "Epoch   6 Batch  105/269 - Train Accuracy: 0.7996, Validation Accuracy: 0.7902, Loss: 0.3371\n",
      "Epoch   6 Batch  106/269 - Train Accuracy: 0.7799, Validation Accuracy: 0.7862, Loss: 0.3228\n",
      "Epoch   6 Batch  107/269 - Train Accuracy: 0.7942, Validation Accuracy: 0.7890, Loss: 0.3498\n",
      "Epoch   6 Batch  108/269 - Train Accuracy: 0.7931, Validation Accuracy: 0.7876, Loss: 0.3233\n",
      "Epoch   6 Batch  109/269 - Train Accuracy: 0.7931, Validation Accuracy: 0.7873, Loss: 0.3293\n",
      "Epoch   6 Batch  110/269 - Train Accuracy: 0.8039, Validation Accuracy: 0.7840, Loss: 0.3213\n",
      "Epoch   6 Batch  111/269 - Train Accuracy: 0.7729, Validation Accuracy: 0.7853, Loss: 0.3526\n",
      "Epoch   6 Batch  112/269 - Train Accuracy: 0.7919, Validation Accuracy: 0.7820, Loss: 0.3297\n",
      "Epoch   6 Batch  113/269 - Train Accuracy: 0.7981, Validation Accuracy: 0.7870, Loss: 0.3147\n",
      "Epoch   6 Batch  114/269 - Train Accuracy: 0.7944, Validation Accuracy: 0.7793, Loss: 0.3182\n",
      "Epoch   6 Batch  115/269 - Train Accuracy: 0.7800, Validation Accuracy: 0.7892, Loss: 0.3406\n",
      "Epoch   6 Batch  116/269 - Train Accuracy: 0.8044, Validation Accuracy: 0.7884, Loss: 0.3366\n",
      "Epoch   6 Batch  117/269 - Train Accuracy: 0.8053, Validation Accuracy: 0.7956, Loss: 0.3215\n",
      "Epoch   6 Batch  118/269 - Train Accuracy: 0.8114, Validation Accuracy: 0.7806, Loss: 0.3144\n",
      "Epoch   6 Batch  119/269 - Train Accuracy: 0.7776, Validation Accuracy: 0.7795, Loss: 0.3435\n",
      "Epoch   6 Batch  120/269 - Train Accuracy: 0.7952, Validation Accuracy: 0.7913, Loss: 0.3354\n",
      "Epoch   6 Batch  121/269 - Train Accuracy: 0.7995, Validation Accuracy: 0.7913, Loss: 0.3178\n",
      "Epoch   6 Batch  122/269 - Train Accuracy: 0.7910, Validation Accuracy: 0.7808, Loss: 0.3194\n",
      "Epoch   6 Batch  123/269 - Train Accuracy: 0.7922, Validation Accuracy: 0.7847, Loss: 0.3379\n",
      "Epoch   6 Batch  124/269 - Train Accuracy: 0.8061, Validation Accuracy: 0.7953, Loss: 0.3158\n",
      "Epoch   6 Batch  125/269 - Train Accuracy: 0.8126, Validation Accuracy: 0.8016, Loss: 0.3159\n",
      "Epoch   6 Batch  126/269 - Train Accuracy: 0.7852, Validation Accuracy: 0.7911, Loss: 0.3226\n",
      "Epoch   6 Batch  127/269 - Train Accuracy: 0.7817, Validation Accuracy: 0.7849, Loss: 0.3352\n",
      "Epoch   6 Batch  128/269 - Train Accuracy: 0.8046, Validation Accuracy: 0.7945, Loss: 0.3193\n",
      "Epoch   6 Batch  129/269 - Train Accuracy: 0.7880, Validation Accuracy: 0.7930, Loss: 0.3203\n",
      "Epoch   6 Batch  130/269 - Train Accuracy: 0.7891, Validation Accuracy: 0.7869, Loss: 0.3387\n",
      "Epoch   6 Batch  131/269 - Train Accuracy: 0.7720, Validation Accuracy: 0.7881, Loss: 0.3315\n",
      "Epoch   6 Batch  132/269 - Train Accuracy: 0.7733, Validation Accuracy: 0.7901, Loss: 0.3261\n",
      "Epoch   6 Batch  133/269 - Train Accuracy: 0.8058, Validation Accuracy: 0.7911, Loss: 0.3131\n",
      "Epoch   6 Batch  134/269 - Train Accuracy: 0.7833, Validation Accuracy: 0.7794, Loss: 0.3246\n",
      "Epoch   6 Batch  135/269 - Train Accuracy: 0.7864, Validation Accuracy: 0.7900, Loss: 0.3372\n",
      "Epoch   6 Batch  136/269 - Train Accuracy: 0.7711, Validation Accuracy: 0.7860, Loss: 0.3467\n",
      "Epoch   6 Batch  137/269 - Train Accuracy: 0.7854, Validation Accuracy: 0.7842, Loss: 0.3383\n",
      "Epoch   6 Batch  138/269 - Train Accuracy: 0.7978, Validation Accuracy: 0.7861, Loss: 0.3322\n",
      "Epoch   6 Batch  139/269 - Train Accuracy: 0.8053, Validation Accuracy: 0.7936, Loss: 0.3134\n",
      "Epoch   6 Batch  140/269 - Train Accuracy: 0.7960, Validation Accuracy: 0.7889, Loss: 0.3385\n",
      "Epoch   6 Batch  141/269 - Train Accuracy: 0.7946, Validation Accuracy: 0.7910, Loss: 0.3354\n",
      "Epoch   6 Batch  142/269 - Train Accuracy: 0.7948, Validation Accuracy: 0.7934, Loss: 0.3198\n",
      "Epoch   6 Batch  143/269 - Train Accuracy: 0.7908, Validation Accuracy: 0.7936, Loss: 0.3159\n",
      "Epoch   6 Batch  144/269 - Train Accuracy: 0.8076, Validation Accuracy: 0.7915, Loss: 0.3059\n",
      "Epoch   6 Batch  145/269 - Train Accuracy: 0.8016, Validation Accuracy: 0.7890, Loss: 0.3166\n",
      "Epoch   6 Batch  146/269 - Train Accuracy: 0.7878, Validation Accuracy: 0.7789, Loss: 0.3158\n",
      "Epoch   6 Batch  147/269 - Train Accuracy: 0.8041, Validation Accuracy: 0.7869, Loss: 0.3130\n",
      "Epoch   6 Batch  148/269 - Train Accuracy: 0.7835, Validation Accuracy: 0.7907, Loss: 0.3238\n",
      "Epoch   6 Batch  149/269 - Train Accuracy: 0.7793, Validation Accuracy: 0.7915, Loss: 0.3261\n",
      "Epoch   6 Batch  150/269 - Train Accuracy: 0.7932, Validation Accuracy: 0.7951, Loss: 0.3148\n",
      "Epoch   6 Batch  151/269 - Train Accuracy: 0.8048, Validation Accuracy: 0.7982, Loss: 0.3090\n",
      "Epoch   6 Batch  152/269 - Train Accuracy: 0.7976, Validation Accuracy: 0.7928, Loss: 0.3184\n",
      "Epoch   6 Batch  153/269 - Train Accuracy: 0.8017, Validation Accuracy: 0.8022, Loss: 0.3183\n",
      "Epoch   6 Batch  154/269 - Train Accuracy: 0.8078, Validation Accuracy: 0.7980, Loss: 0.3194\n",
      "Epoch   6 Batch  155/269 - Train Accuracy: 0.8033, Validation Accuracy: 0.7915, Loss: 0.2978\n",
      "Epoch   6 Batch  156/269 - Train Accuracy: 0.7786, Validation Accuracy: 0.7974, Loss: 0.3316\n",
      "Epoch   6 Batch  157/269 - Train Accuracy: 0.7961, Validation Accuracy: 0.7964, Loss: 0.3087\n",
      "Epoch   6 Batch  158/269 - Train Accuracy: 0.7994, Validation Accuracy: 0.7991, Loss: 0.3138\n",
      "Epoch   6 Batch  159/269 - Train Accuracy: 0.7877, Validation Accuracy: 0.8000, Loss: 0.3205\n",
      "Epoch   6 Batch  160/269 - Train Accuracy: 0.8082, Validation Accuracy: 0.7987, Loss: 0.3132\n",
      "Epoch   6 Batch  161/269 - Train Accuracy: 0.7895, Validation Accuracy: 0.8046, Loss: 0.3150\n",
      "Epoch   6 Batch  162/269 - Train Accuracy: 0.8091, Validation Accuracy: 0.8015, Loss: 0.3008\n",
      "Epoch   6 Batch  163/269 - Train Accuracy: 0.7954, Validation Accuracy: 0.7920, Loss: 0.3124\n",
      "Epoch   6 Batch  164/269 - Train Accuracy: 0.8150, Validation Accuracy: 0.7925, Loss: 0.3131\n",
      "Epoch   6 Batch  165/269 - Train Accuracy: 0.7856, Validation Accuracy: 0.7884, Loss: 0.3195\n",
      "Epoch   6 Batch  166/269 - Train Accuracy: 0.8134, Validation Accuracy: 0.7973, Loss: 0.2967\n",
      "Epoch   6 Batch  167/269 - Train Accuracy: 0.8050, Validation Accuracy: 0.7957, Loss: 0.3164\n",
      "Epoch   6 Batch  168/269 - Train Accuracy: 0.7971, Validation Accuracy: 0.7985, Loss: 0.3170\n",
      "Epoch   6 Batch  169/269 - Train Accuracy: 0.8070, Validation Accuracy: 0.7973, Loss: 0.3185\n",
      "Epoch   6 Batch  170/269 - Train Accuracy: 0.8006, Validation Accuracy: 0.8023, Loss: 0.3094\n",
      "Epoch   6 Batch  171/269 - Train Accuracy: 0.8134, Validation Accuracy: 0.7913, Loss: 0.3199\n",
      "Epoch   6 Batch  172/269 - Train Accuracy: 0.8077, Validation Accuracy: 0.7937, Loss: 0.3228\n",
      "Epoch   6 Batch  173/269 - Train Accuracy: 0.8043, Validation Accuracy: 0.7877, Loss: 0.2993\n",
      "Epoch   6 Batch  174/269 - Train Accuracy: 0.7957, Validation Accuracy: 0.7913, Loss: 0.3159\n",
      "Epoch   6 Batch  175/269 - Train Accuracy: 0.8015, Validation Accuracy: 0.7959, Loss: 0.3229\n",
      "Epoch   6 Batch  176/269 - Train Accuracy: 0.7990, Validation Accuracy: 0.7979, Loss: 0.3252\n",
      "Epoch   6 Batch  177/269 - Train Accuracy: 0.8069, Validation Accuracy: 0.7945, Loss: 0.3005\n",
      "Epoch   6 Batch  178/269 - Train Accuracy: 0.8040, Validation Accuracy: 0.7963, Loss: 0.3175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   6 Batch  179/269 - Train Accuracy: 0.7760, Validation Accuracy: 0.7925, Loss: 0.3066\n",
      "Epoch   6 Batch  180/269 - Train Accuracy: 0.8186, Validation Accuracy: 0.7963, Loss: 0.3070\n",
      "Epoch   6 Batch  181/269 - Train Accuracy: 0.7990, Validation Accuracy: 0.7897, Loss: 0.3112\n",
      "Epoch   6 Batch  182/269 - Train Accuracy: 0.8032, Validation Accuracy: 0.7939, Loss: 0.3101\n",
      "Epoch   6 Batch  183/269 - Train Accuracy: 0.8344, Validation Accuracy: 0.7906, Loss: 0.2665\n",
      "Epoch   6 Batch  184/269 - Train Accuracy: 0.7858, Validation Accuracy: 0.7908, Loss: 0.3158\n",
      "Epoch   6 Batch  185/269 - Train Accuracy: 0.8100, Validation Accuracy: 0.7929, Loss: 0.3031\n",
      "Epoch   6 Batch  186/269 - Train Accuracy: 0.7791, Validation Accuracy: 0.7919, Loss: 0.3114\n",
      "Epoch   6 Batch  187/269 - Train Accuracy: 0.7981, Validation Accuracy: 0.7912, Loss: 0.2981\n",
      "Epoch   6 Batch  188/269 - Train Accuracy: 0.8154, Validation Accuracy: 0.7957, Loss: 0.2993\n",
      "Epoch   6 Batch  189/269 - Train Accuracy: 0.7983, Validation Accuracy: 0.7868, Loss: 0.3007\n",
      "Epoch   6 Batch  190/269 - Train Accuracy: 0.8065, Validation Accuracy: 0.7891, Loss: 0.3000\n",
      "Epoch   6 Batch  191/269 - Train Accuracy: 0.7991, Validation Accuracy: 0.7877, Loss: 0.3016\n",
      "Epoch   6 Batch  192/269 - Train Accuracy: 0.8072, Validation Accuracy: 0.7939, Loss: 0.3091\n",
      "Epoch   6 Batch  193/269 - Train Accuracy: 0.8080, Validation Accuracy: 0.7855, Loss: 0.2995\n",
      "Epoch   6 Batch  194/269 - Train Accuracy: 0.8080, Validation Accuracy: 0.7946, Loss: 0.3057\n",
      "Epoch   6 Batch  195/269 - Train Accuracy: 0.7829, Validation Accuracy: 0.7892, Loss: 0.3041\n",
      "Epoch   6 Batch  196/269 - Train Accuracy: 0.8026, Validation Accuracy: 0.7896, Loss: 0.3043\n",
      "Epoch   6 Batch  197/269 - Train Accuracy: 0.7897, Validation Accuracy: 0.7913, Loss: 0.3243\n",
      "Epoch   6 Batch  198/269 - Train Accuracy: 0.8073, Validation Accuracy: 0.8014, Loss: 0.3268\n",
      "Epoch   6 Batch  199/269 - Train Accuracy: 0.7966, Validation Accuracy: 0.7980, Loss: 0.3163\n",
      "Epoch   6 Batch  200/269 - Train Accuracy: 0.7923, Validation Accuracy: 0.7984, Loss: 0.3146\n",
      "Epoch   6 Batch  201/269 - Train Accuracy: 0.8072, Validation Accuracy: 0.8035, Loss: 0.3013\n",
      "Epoch   6 Batch  202/269 - Train Accuracy: 0.7896, Validation Accuracy: 0.7934, Loss: 0.3034\n",
      "Epoch   6 Batch  203/269 - Train Accuracy: 0.8063, Validation Accuracy: 0.8002, Loss: 0.3237\n",
      "Epoch   6 Batch  204/269 - Train Accuracy: 0.8102, Validation Accuracy: 0.7990, Loss: 0.3106\n",
      "Epoch   6 Batch  205/269 - Train Accuracy: 0.8159, Validation Accuracy: 0.7953, Loss: 0.3068\n",
      "Epoch   6 Batch  206/269 - Train Accuracy: 0.7790, Validation Accuracy: 0.7868, Loss: 0.3174\n",
      "Epoch   6 Batch  207/269 - Train Accuracy: 0.8089, Validation Accuracy: 0.7958, Loss: 0.2951\n",
      "Epoch   6 Batch  208/269 - Train Accuracy: 0.8111, Validation Accuracy: 0.7991, Loss: 0.3211\n",
      "Epoch   6 Batch  209/269 - Train Accuracy: 0.8252, Validation Accuracy: 0.7941, Loss: 0.3010\n",
      "Epoch   6 Batch  210/269 - Train Accuracy: 0.8074, Validation Accuracy: 0.7925, Loss: 0.2926\n",
      "Epoch   6 Batch  211/269 - Train Accuracy: 0.7932, Validation Accuracy: 0.8070, Loss: 0.3070\n",
      "Epoch   6 Batch  212/269 - Train Accuracy: 0.7988, Validation Accuracy: 0.7978, Loss: 0.3065\n",
      "Epoch   6 Batch  213/269 - Train Accuracy: 0.8013, Validation Accuracy: 0.8054, Loss: 0.3016\n",
      "Epoch   6 Batch  214/269 - Train Accuracy: 0.7973, Validation Accuracy: 0.7988, Loss: 0.3066\n",
      "Epoch   6 Batch  215/269 - Train Accuracy: 0.8279, Validation Accuracy: 0.8030, Loss: 0.2878\n",
      "Epoch   6 Batch  216/269 - Train Accuracy: 0.7820, Validation Accuracy: 0.7936, Loss: 0.3306\n",
      "Epoch   6 Batch  217/269 - Train Accuracy: 0.8014, Validation Accuracy: 0.7974, Loss: 0.3140\n",
      "Epoch   6 Batch  218/269 - Train Accuracy: 0.8059, Validation Accuracy: 0.7979, Loss: 0.3103\n",
      "Epoch   6 Batch  219/269 - Train Accuracy: 0.8046, Validation Accuracy: 0.7979, Loss: 0.3090\n",
      "Epoch   6 Batch  220/269 - Train Accuracy: 0.7975, Validation Accuracy: 0.8016, Loss: 0.2910\n",
      "Epoch   6 Batch  221/269 - Train Accuracy: 0.8311, Validation Accuracy: 0.8002, Loss: 0.3007\n",
      "Epoch   6 Batch  222/269 - Train Accuracy: 0.8287, Validation Accuracy: 0.8052, Loss: 0.2925\n",
      "Epoch   6 Batch  223/269 - Train Accuracy: 0.7942, Validation Accuracy: 0.8067, Loss: 0.2950\n",
      "Epoch   6 Batch  224/269 - Train Accuracy: 0.8177, Validation Accuracy: 0.8048, Loss: 0.3137\n",
      "Epoch   6 Batch  225/269 - Train Accuracy: 0.7999, Validation Accuracy: 0.8061, Loss: 0.2964\n",
      "Epoch   6 Batch  226/269 - Train Accuracy: 0.8256, Validation Accuracy: 0.8011, Loss: 0.2936\n",
      "Epoch   6 Batch  227/269 - Train Accuracy: 0.8342, Validation Accuracy: 0.7970, Loss: 0.2784\n",
      "Epoch   6 Batch  228/269 - Train Accuracy: 0.8020, Validation Accuracy: 0.8061, Loss: 0.3012\n",
      "Epoch   6 Batch  229/269 - Train Accuracy: 0.8067, Validation Accuracy: 0.8098, Loss: 0.2997\n",
      "Epoch   6 Batch  230/269 - Train Accuracy: 0.8126, Validation Accuracy: 0.8042, Loss: 0.2938\n",
      "Epoch   6 Batch  231/269 - Train Accuracy: 0.8200, Validation Accuracy: 0.8069, Loss: 0.3105\n",
      "Epoch   6 Batch  232/269 - Train Accuracy: 0.8016, Validation Accuracy: 0.8047, Loss: 0.3000\n",
      "Epoch   6 Batch  233/269 - Train Accuracy: 0.8304, Validation Accuracy: 0.8082, Loss: 0.3001\n",
      "Epoch   6 Batch  234/269 - Train Accuracy: 0.8030, Validation Accuracy: 0.8059, Loss: 0.2947\n",
      "Epoch   6 Batch  235/269 - Train Accuracy: 0.8213, Validation Accuracy: 0.8101, Loss: 0.2836\n",
      "Epoch   6 Batch  236/269 - Train Accuracy: 0.8111, Validation Accuracy: 0.8075, Loss: 0.2859\n",
      "Epoch   6 Batch  237/269 - Train Accuracy: 0.8325, Validation Accuracy: 0.8035, Loss: 0.2891\n",
      "Epoch   6 Batch  238/269 - Train Accuracy: 0.8278, Validation Accuracy: 0.8050, Loss: 0.2833\n",
      "Epoch   6 Batch  239/269 - Train Accuracy: 0.8153, Validation Accuracy: 0.8049, Loss: 0.2940\n",
      "Epoch   6 Batch  240/269 - Train Accuracy: 0.8311, Validation Accuracy: 0.8032, Loss: 0.2718\n",
      "Epoch   6 Batch  241/269 - Train Accuracy: 0.8135, Validation Accuracy: 0.8085, Loss: 0.3054\n",
      "Epoch   6 Batch  242/269 - Train Accuracy: 0.8183, Validation Accuracy: 0.8041, Loss: 0.2815\n",
      "Epoch   6 Batch  243/269 - Train Accuracy: 0.8219, Validation Accuracy: 0.8004, Loss: 0.2797\n",
      "Epoch   6 Batch  244/269 - Train Accuracy: 0.8130, Validation Accuracy: 0.7947, Loss: 0.2940\n",
      "Epoch   6 Batch  245/269 - Train Accuracy: 0.7829, Validation Accuracy: 0.7956, Loss: 0.3114\n",
      "Epoch   6 Batch  246/269 - Train Accuracy: 0.7979, Validation Accuracy: 0.7910, Loss: 0.2957\n",
      "Epoch   6 Batch  247/269 - Train Accuracy: 0.7942, Validation Accuracy: 0.7952, Loss: 0.3055\n",
      "Epoch   6 Batch  248/269 - Train Accuracy: 0.8090, Validation Accuracy: 0.8024, Loss: 0.2904\n",
      "Epoch   6 Batch  249/269 - Train Accuracy: 0.8313, Validation Accuracy: 0.8016, Loss: 0.2745\n",
      "Epoch   6 Batch  250/269 - Train Accuracy: 0.8114, Validation Accuracy: 0.8002, Loss: 0.3035\n",
      "Epoch   6 Batch  251/269 - Train Accuracy: 0.8322, Validation Accuracy: 0.7948, Loss: 0.2843\n",
      "Epoch   6 Batch  252/269 - Train Accuracy: 0.8151, Validation Accuracy: 0.8030, Loss: 0.2887\n",
      "Epoch   6 Batch  253/269 - Train Accuracy: 0.7802, Validation Accuracy: 0.8077, Loss: 0.2958\n",
      "Epoch   6 Batch  254/269 - Train Accuracy: 0.8176, Validation Accuracy: 0.8010, Loss: 0.2883\n",
      "Epoch   6 Batch  255/269 - Train Accuracy: 0.8188, Validation Accuracy: 0.7996, Loss: 0.2910\n",
      "Epoch   6 Batch  256/269 - Train Accuracy: 0.7985, Validation Accuracy: 0.8128, Loss: 0.2916\n",
      "Epoch   6 Batch  257/269 - Train Accuracy: 0.8084, Validation Accuracy: 0.8081, Loss: 0.3075\n",
      "Epoch   6 Batch  258/269 - Train Accuracy: 0.8198, Validation Accuracy: 0.7971, Loss: 0.2917\n",
      "Epoch   6 Batch  259/269 - Train Accuracy: 0.8190, Validation Accuracy: 0.8134, Loss: 0.2942\n",
      "Epoch   6 Batch  260/269 - Train Accuracy: 0.8047, Validation Accuracy: 0.8075, Loss: 0.3056\n",
      "Epoch   6 Batch  261/269 - Train Accuracy: 0.7953, Validation Accuracy: 0.7988, Loss: 0.3029\n",
      "Epoch   6 Batch  262/269 - Train Accuracy: 0.8294, Validation Accuracy: 0.8071, Loss: 0.2953\n",
      "Epoch   6 Batch  263/269 - Train Accuracy: 0.8115, Validation Accuracy: 0.8092, Loss: 0.2975\n",
      "Epoch   6 Batch  264/269 - Train Accuracy: 0.7973, Validation Accuracy: 0.8064, Loss: 0.3137\n",
      "Epoch   6 Batch  265/269 - Train Accuracy: 0.8110, Validation Accuracy: 0.8062, Loss: 0.2899\n",
      "Epoch   6 Batch  266/269 - Train Accuracy: 0.8250, Validation Accuracy: 0.8127, Loss: 0.2870\n",
      "Epoch   6 Batch  267/269 - Train Accuracy: 0.8127, Validation Accuracy: 0.8132, Loss: 0.2926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   7 Batch    1/269 - Train Accuracy: 0.8069, Validation Accuracy: 0.8004, Loss: 0.2999\n",
      "Epoch   7 Batch    2/269 - Train Accuracy: 0.8173, Validation Accuracy: 0.8074, Loss: 0.2942\n",
      "Epoch   7 Batch    3/269 - Train Accuracy: 0.8083, Validation Accuracy: 0.8004, Loss: 0.2968\n",
      "Epoch   7 Batch    4/269 - Train Accuracy: 0.7913, Validation Accuracy: 0.8109, Loss: 0.3071\n",
      "Epoch   7 Batch    5/269 - Train Accuracy: 0.7994, Validation Accuracy: 0.8098, Loss: 0.2979\n",
      "Epoch   7 Batch    6/269 - Train Accuracy: 0.8320, Validation Accuracy: 0.8163, Loss: 0.2822\n",
      "Epoch   7 Batch    7/269 - Train Accuracy: 0.8192, Validation Accuracy: 0.8106, Loss: 0.2821\n",
      "Epoch   7 Batch    8/269 - Train Accuracy: 0.8168, Validation Accuracy: 0.8122, Loss: 0.3026\n",
      "Epoch   7 Batch    9/269 - Train Accuracy: 0.8216, Validation Accuracy: 0.8110, Loss: 0.2909\n",
      "Epoch   7 Batch   10/269 - Train Accuracy: 0.8226, Validation Accuracy: 0.8129, Loss: 0.2861\n",
      "Epoch   7 Batch   11/269 - Train Accuracy: 0.8240, Validation Accuracy: 0.8122, Loss: 0.2950\n",
      "Epoch   7 Batch   12/269 - Train Accuracy: 0.8029, Validation Accuracy: 0.8129, Loss: 0.3010\n",
      "Epoch   7 Batch   13/269 - Train Accuracy: 0.8177, Validation Accuracy: 0.8102, Loss: 0.2604\n",
      "Epoch   7 Batch   14/269 - Train Accuracy: 0.8143, Validation Accuracy: 0.8143, Loss: 0.2784\n",
      "Epoch   7 Batch   15/269 - Train Accuracy: 0.8097, Validation Accuracy: 0.8128, Loss: 0.2655\n",
      "Epoch   7 Batch   16/269 - Train Accuracy: 0.8107, Validation Accuracy: 0.8137, Loss: 0.2842\n",
      "Epoch   7 Batch   17/269 - Train Accuracy: 0.8174, Validation Accuracy: 0.8078, Loss: 0.2704\n",
      "Epoch   7 Batch   18/269 - Train Accuracy: 0.8074, Validation Accuracy: 0.8074, Loss: 0.2894\n",
      "Epoch   7 Batch   19/269 - Train Accuracy: 0.8209, Validation Accuracy: 0.8097, Loss: 0.2579\n",
      "Epoch   7 Batch   20/269 - Train Accuracy: 0.8216, Validation Accuracy: 0.8120, Loss: 0.2844\n",
      "Epoch   7 Batch   21/269 - Train Accuracy: 0.7893, Validation Accuracy: 0.8119, Loss: 0.2990\n",
      "Epoch   7 Batch   22/269 - Train Accuracy: 0.8363, Validation Accuracy: 0.8168, Loss: 0.2712\n",
      "Epoch   7 Batch   23/269 - Train Accuracy: 0.8196, Validation Accuracy: 0.8170, Loss: 0.2763\n",
      "Epoch   7 Batch   24/269 - Train Accuracy: 0.8177, Validation Accuracy: 0.8093, Loss: 0.2892\n",
      "Epoch   7 Batch   25/269 - Train Accuracy: 0.8040, Validation Accuracy: 0.8169, Loss: 0.3058\n",
      "Epoch   7 Batch   26/269 - Train Accuracy: 0.8272, Validation Accuracy: 0.8166, Loss: 0.2562\n",
      "Epoch   7 Batch   27/269 - Train Accuracy: 0.8142, Validation Accuracy: 0.8147, Loss: 0.2736\n",
      "Epoch   7 Batch   28/269 - Train Accuracy: 0.7826, Validation Accuracy: 0.8160, Loss: 0.3016\n",
      "Epoch   7 Batch   29/269 - Train Accuracy: 0.8235, Validation Accuracy: 0.8066, Loss: 0.2927\n",
      "Epoch   7 Batch   30/269 - Train Accuracy: 0.8347, Validation Accuracy: 0.8199, Loss: 0.2775\n",
      "Epoch   7 Batch   31/269 - Train Accuracy: 0.8350, Validation Accuracy: 0.8158, Loss: 0.2675\n",
      "Epoch   7 Batch   32/269 - Train Accuracy: 0.8113, Validation Accuracy: 0.8048, Loss: 0.2664\n",
      "Epoch   7 Batch   33/269 - Train Accuracy: 0.8194, Validation Accuracy: 0.8072, Loss: 0.2670\n",
      "Epoch   7 Batch   34/269 - Train Accuracy: 0.8230, Validation Accuracy: 0.8087, Loss: 0.2790\n",
      "Epoch   7 Batch   35/269 - Train Accuracy: 0.8176, Validation Accuracy: 0.8166, Loss: 0.2902\n",
      "Epoch   7 Batch   36/269 - Train Accuracy: 0.8145, Validation Accuracy: 0.8211, Loss: 0.2779\n",
      "Epoch   7 Batch   37/269 - Train Accuracy: 0.8194, Validation Accuracy: 0.8127, Loss: 0.2800\n",
      "Epoch   7 Batch   38/269 - Train Accuracy: 0.8090, Validation Accuracy: 0.8129, Loss: 0.2812\n",
      "Epoch   7 Batch   39/269 - Train Accuracy: 0.8177, Validation Accuracy: 0.8145, Loss: 0.2658\n",
      "Epoch   7 Batch   40/269 - Train Accuracy: 0.8104, Validation Accuracy: 0.8122, Loss: 0.2840\n",
      "Epoch   7 Batch   41/269 - Train Accuracy: 0.8168, Validation Accuracy: 0.8153, Loss: 0.2814\n",
      "Epoch   7 Batch   42/269 - Train Accuracy: 0.8481, Validation Accuracy: 0.8205, Loss: 0.2543\n",
      "Epoch   7 Batch   43/269 - Train Accuracy: 0.8247, Validation Accuracy: 0.8184, Loss: 0.2812\n",
      "Epoch   7 Batch   44/269 - Train Accuracy: 0.7953, Validation Accuracy: 0.8116, Loss: 0.2783\n",
      "Epoch   7 Batch   45/269 - Train Accuracy: 0.8070, Validation Accuracy: 0.8129, Loss: 0.2868\n",
      "Epoch   7 Batch   46/269 - Train Accuracy: 0.8219, Validation Accuracy: 0.8136, Loss: 0.2844\n",
      "Epoch   7 Batch   47/269 - Train Accuracy: 0.8287, Validation Accuracy: 0.8224, Loss: 0.2561\n",
      "Epoch   7 Batch   48/269 - Train Accuracy: 0.8283, Validation Accuracy: 0.8243, Loss: 0.2634\n",
      "Epoch   7 Batch   49/269 - Train Accuracy: 0.8167, Validation Accuracy: 0.8228, Loss: 0.2723\n",
      "Epoch   7 Batch   50/269 - Train Accuracy: 0.7989, Validation Accuracy: 0.8234, Loss: 0.2918\n",
      "Epoch   7 Batch   51/269 - Train Accuracy: 0.8227, Validation Accuracy: 0.8202, Loss: 0.2695\n",
      "Epoch   7 Batch   52/269 - Train Accuracy: 0.8132, Validation Accuracy: 0.8147, Loss: 0.2572\n",
      "Epoch   7 Batch   53/269 - Train Accuracy: 0.8197, Validation Accuracy: 0.8170, Loss: 0.2904\n",
      "Epoch   7 Batch   54/269 - Train Accuracy: 0.8377, Validation Accuracy: 0.8216, Loss: 0.2741\n",
      "Epoch   7 Batch   55/269 - Train Accuracy: 0.8511, Validation Accuracy: 0.8109, Loss: 0.2671\n",
      "Epoch   7 Batch   56/269 - Train Accuracy: 0.8109, Validation Accuracy: 0.8258, Loss: 0.2863\n",
      "Epoch   7 Batch   57/269 - Train Accuracy: 0.8304, Validation Accuracy: 0.8254, Loss: 0.2831\n",
      "Epoch   7 Batch   58/269 - Train Accuracy: 0.8281, Validation Accuracy: 0.8192, Loss: 0.2621\n",
      "Epoch   7 Batch   59/269 - Train Accuracy: 0.8405, Validation Accuracy: 0.8217, Loss: 0.2599\n",
      "Epoch   7 Batch   60/269 - Train Accuracy: 0.8314, Validation Accuracy: 0.8184, Loss: 0.2588\n",
      "Epoch   7 Batch   61/269 - Train Accuracy: 0.8168, Validation Accuracy: 0.8145, Loss: 0.2535\n",
      "Epoch   7 Batch   62/269 - Train Accuracy: 0.8459, Validation Accuracy: 0.8271, Loss: 0.2665\n",
      "Epoch   7 Batch   63/269 - Train Accuracy: 0.8258, Validation Accuracy: 0.8270, Loss: 0.2725\n",
      "Epoch   7 Batch   64/269 - Train Accuracy: 0.8236, Validation Accuracy: 0.8184, Loss: 0.2600\n",
      "Epoch   7 Batch   65/269 - Train Accuracy: 0.8126, Validation Accuracy: 0.8310, Loss: 0.2714\n",
      "Epoch   7 Batch   66/269 - Train Accuracy: 0.8303, Validation Accuracy: 0.8249, Loss: 0.2603\n",
      "Epoch   7 Batch   67/269 - Train Accuracy: 0.8253, Validation Accuracy: 0.8186, Loss: 0.2783\n",
      "Epoch   7 Batch   68/269 - Train Accuracy: 0.7999, Validation Accuracy: 0.8249, Loss: 0.2813\n",
      "Epoch   7 Batch   69/269 - Train Accuracy: 0.8041, Validation Accuracy: 0.8216, Loss: 0.3048\n",
      "Epoch   7 Batch   70/269 - Train Accuracy: 0.8384, Validation Accuracy: 0.8188, Loss: 0.2743\n",
      "Epoch   7 Batch   71/269 - Train Accuracy: 0.8189, Validation Accuracy: 0.8249, Loss: 0.2848\n",
      "Epoch   7 Batch   72/269 - Train Accuracy: 0.8139, Validation Accuracy: 0.8256, Loss: 0.2730\n",
      "Epoch   7 Batch   73/269 - Train Accuracy: 0.8184, Validation Accuracy: 0.8153, Loss: 0.2854\n",
      "Epoch   7 Batch   74/269 - Train Accuracy: 0.8271, Validation Accuracy: 0.8183, Loss: 0.2757\n",
      "Epoch   7 Batch   75/269 - Train Accuracy: 0.8293, Validation Accuracy: 0.8145, Loss: 0.2670\n",
      "Epoch   7 Batch   76/269 - Train Accuracy: 0.8053, Validation Accuracy: 0.8191, Loss: 0.2665\n",
      "Epoch   7 Batch   77/269 - Train Accuracy: 0.8185, Validation Accuracy: 0.8229, Loss: 0.2702\n",
      "Epoch   7 Batch   78/269 - Train Accuracy: 0.8402, Validation Accuracy: 0.8149, Loss: 0.2686\n",
      "Epoch   7 Batch   79/269 - Train Accuracy: 0.8191, Validation Accuracy: 0.8114, Loss: 0.2653\n",
      "Epoch   7 Batch   80/269 - Train Accuracy: 0.8286, Validation Accuracy: 0.8223, Loss: 0.2631\n",
      "Epoch   7 Batch   81/269 - Train Accuracy: 0.8203, Validation Accuracy: 0.8221, Loss: 0.2749\n",
      "Epoch   7 Batch   82/269 - Train Accuracy: 0.8314, Validation Accuracy: 0.8224, Loss: 0.2569\n",
      "Epoch   7 Batch   83/269 - Train Accuracy: 0.8124, Validation Accuracy: 0.8125, Loss: 0.2821\n",
      "Epoch   7 Batch   84/269 - Train Accuracy: 0.8388, Validation Accuracy: 0.8243, Loss: 0.2688\n",
      "Epoch   7 Batch   85/269 - Train Accuracy: 0.8348, Validation Accuracy: 0.8252, Loss: 0.2656\n",
      "Epoch   7 Batch   86/269 - Train Accuracy: 0.8290, Validation Accuracy: 0.8113, Loss: 0.2576\n",
      "Epoch   7 Batch   87/269 - Train Accuracy: 0.8132, Validation Accuracy: 0.8248, Loss: 0.2868\n",
      "Epoch   7 Batch   88/269 - Train Accuracy: 0.8116, Validation Accuracy: 0.8187, Loss: 0.2623\n",
      "Epoch   7 Batch   89/269 - Train Accuracy: 0.8428, Validation Accuracy: 0.8120, Loss: 0.2661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   7 Batch   90/269 - Train Accuracy: 0.8042, Validation Accuracy: 0.8189, Loss: 0.2803\n",
      "Epoch   7 Batch   91/269 - Train Accuracy: 0.8445, Validation Accuracy: 0.8163, Loss: 0.2560\n",
      "Epoch   7 Batch   92/269 - Train Accuracy: 0.8311, Validation Accuracy: 0.8113, Loss: 0.2527\n",
      "Epoch   7 Batch   93/269 - Train Accuracy: 0.8384, Validation Accuracy: 0.8185, Loss: 0.2566\n",
      "Epoch   7 Batch   94/269 - Train Accuracy: 0.8268, Validation Accuracy: 0.8174, Loss: 0.2750\n",
      "Epoch   7 Batch   95/269 - Train Accuracy: 0.8207, Validation Accuracy: 0.8163, Loss: 0.2615\n",
      "Epoch   7 Batch   96/269 - Train Accuracy: 0.8174, Validation Accuracy: 0.8174, Loss: 0.2638\n",
      "Epoch   7 Batch   97/269 - Train Accuracy: 0.8412, Validation Accuracy: 0.8239, Loss: 0.2649\n",
      "Epoch   7 Batch   98/269 - Train Accuracy: 0.8381, Validation Accuracy: 0.8255, Loss: 0.2639\n",
      "Epoch   7 Batch   99/269 - Train Accuracy: 0.8039, Validation Accuracy: 0.8207, Loss: 0.2678\n",
      "Epoch   7 Batch  100/269 - Train Accuracy: 0.8465, Validation Accuracy: 0.8249, Loss: 0.2565\n",
      "Epoch   7 Batch  101/269 - Train Accuracy: 0.8122, Validation Accuracy: 0.8255, Loss: 0.2835\n",
      "Epoch   7 Batch  102/269 - Train Accuracy: 0.8243, Validation Accuracy: 0.8181, Loss: 0.2567\n",
      "Epoch   7 Batch  103/269 - Train Accuracy: 0.8237, Validation Accuracy: 0.8228, Loss: 0.2689\n",
      "Epoch   7 Batch  104/269 - Train Accuracy: 0.8296, Validation Accuracy: 0.8283, Loss: 0.2550\n",
      "Epoch   7 Batch  105/269 - Train Accuracy: 0.8238, Validation Accuracy: 0.8209, Loss: 0.2624\n",
      "Epoch   7 Batch  106/269 - Train Accuracy: 0.8131, Validation Accuracy: 0.8240, Loss: 0.2518\n",
      "Epoch   7 Batch  107/269 - Train Accuracy: 0.8351, Validation Accuracy: 0.8216, Loss: 0.2665\n",
      "Epoch   7 Batch  108/269 - Train Accuracy: 0.8352, Validation Accuracy: 0.8220, Loss: 0.2580\n",
      "Epoch   7 Batch  109/269 - Train Accuracy: 0.8337, Validation Accuracy: 0.8255, Loss: 0.2672\n",
      "Epoch   7 Batch  110/269 - Train Accuracy: 0.8348, Validation Accuracy: 0.8267, Loss: 0.2592\n",
      "Epoch   7 Batch  111/269 - Train Accuracy: 0.8105, Validation Accuracy: 0.8203, Loss: 0.2873\n",
      "Epoch   7 Batch  112/269 - Train Accuracy: 0.8270, Validation Accuracy: 0.8238, Loss: 0.2581\n",
      "Epoch   7 Batch  113/269 - Train Accuracy: 0.8263, Validation Accuracy: 0.8223, Loss: 0.2499\n",
      "Epoch   7 Batch  114/269 - Train Accuracy: 0.8331, Validation Accuracy: 0.8170, Loss: 0.2567\n",
      "Epoch   7 Batch  115/269 - Train Accuracy: 0.8094, Validation Accuracy: 0.8179, Loss: 0.2697\n",
      "Epoch   7 Batch  116/269 - Train Accuracy: 0.8383, Validation Accuracy: 0.8216, Loss: 0.2660\n",
      "Epoch   7 Batch  117/269 - Train Accuracy: 0.8416, Validation Accuracy: 0.8184, Loss: 0.2518\n",
      "Epoch   7 Batch  118/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8241, Loss: 0.2481\n",
      "Epoch   7 Batch  119/269 - Train Accuracy: 0.8130, Validation Accuracy: 0.8183, Loss: 0.2734\n",
      "Epoch   7 Batch  120/269 - Train Accuracy: 0.8363, Validation Accuracy: 0.8213, Loss: 0.2617\n",
      "Epoch   7 Batch  121/269 - Train Accuracy: 0.8385, Validation Accuracy: 0.8163, Loss: 0.2522\n",
      "Epoch   7 Batch  122/269 - Train Accuracy: 0.8228, Validation Accuracy: 0.8213, Loss: 0.2502\n",
      "Epoch   7 Batch  123/269 - Train Accuracy: 0.8397, Validation Accuracy: 0.8232, Loss: 0.2662\n",
      "Epoch   7 Batch  124/269 - Train Accuracy: 0.8473, Validation Accuracy: 0.8218, Loss: 0.2498\n",
      "Epoch   7 Batch  125/269 - Train Accuracy: 0.8407, Validation Accuracy: 0.8170, Loss: 0.2476\n",
      "Epoch   7 Batch  126/269 - Train Accuracy: 0.8161, Validation Accuracy: 0.8169, Loss: 0.2550\n",
      "Epoch   7 Batch  127/269 - Train Accuracy: 0.8093, Validation Accuracy: 0.8082, Loss: 0.2681\n",
      "Epoch   7 Batch  128/269 - Train Accuracy: 0.8379, Validation Accuracy: 0.8287, Loss: 0.2675\n",
      "Epoch   7 Batch  129/269 - Train Accuracy: 0.8066, Validation Accuracy: 0.8069, Loss: 0.2517\n",
      "Epoch   7 Batch  130/269 - Train Accuracy: 0.8304, Validation Accuracy: 0.8114, Loss: 0.2809\n",
      "Epoch   7 Batch  131/269 - Train Accuracy: 0.8132, Validation Accuracy: 0.8199, Loss: 0.2730\n",
      "Epoch   7 Batch  132/269 - Train Accuracy: 0.8237, Validation Accuracy: 0.8256, Loss: 0.2682\n",
      "Epoch   7 Batch  133/269 - Train Accuracy: 0.8355, Validation Accuracy: 0.8200, Loss: 0.2489\n",
      "Epoch   7 Batch  134/269 - Train Accuracy: 0.8410, Validation Accuracy: 0.8228, Loss: 0.2694\n",
      "Epoch   7 Batch  135/269 - Train Accuracy: 0.8180, Validation Accuracy: 0.8247, Loss: 0.2751\n",
      "Epoch   7 Batch  136/269 - Train Accuracy: 0.8115, Validation Accuracy: 0.8224, Loss: 0.2799\n",
      "Epoch   7 Batch  137/269 - Train Accuracy: 0.8216, Validation Accuracy: 0.8254, Loss: 0.2697\n",
      "Epoch   7 Batch  138/269 - Train Accuracy: 0.8382, Validation Accuracy: 0.8195, Loss: 0.2540\n",
      "Epoch   7 Batch  139/269 - Train Accuracy: 0.8333, Validation Accuracy: 0.8235, Loss: 0.2497\n",
      "Epoch   7 Batch  140/269 - Train Accuracy: 0.8359, Validation Accuracy: 0.8192, Loss: 0.2661\n",
      "Epoch   7 Batch  141/269 - Train Accuracy: 0.8300, Validation Accuracy: 0.8296, Loss: 0.2624\n",
      "Epoch   7 Batch  142/269 - Train Accuracy: 0.8364, Validation Accuracy: 0.8244, Loss: 0.2449\n",
      "Epoch   7 Batch  143/269 - Train Accuracy: 0.8393, Validation Accuracy: 0.8174, Loss: 0.2522\n",
      "Epoch   7 Batch  144/269 - Train Accuracy: 0.8419, Validation Accuracy: 0.8269, Loss: 0.2398\n",
      "Epoch   7 Batch  145/269 - Train Accuracy: 0.8392, Validation Accuracy: 0.8300, Loss: 0.2431\n",
      "Epoch   7 Batch  146/269 - Train Accuracy: 0.8299, Validation Accuracy: 0.8184, Loss: 0.2450\n",
      "Epoch   7 Batch  147/269 - Train Accuracy: 0.8404, Validation Accuracy: 0.8205, Loss: 0.2494\n",
      "Epoch   7 Batch  148/269 - Train Accuracy: 0.8249, Validation Accuracy: 0.8350, Loss: 0.2531\n",
      "Epoch   7 Batch  149/269 - Train Accuracy: 0.8196, Validation Accuracy: 0.8327, Loss: 0.2668\n",
      "Epoch   7 Batch  150/269 - Train Accuracy: 0.8363, Validation Accuracy: 0.8215, Loss: 0.2469\n",
      "Epoch   7 Batch  151/269 - Train Accuracy: 0.8409, Validation Accuracy: 0.8309, Loss: 0.2473\n",
      "Epoch   7 Batch  152/269 - Train Accuracy: 0.8404, Validation Accuracy: 0.8336, Loss: 0.2494\n",
      "Epoch   7 Batch  153/269 - Train Accuracy: 0.8351, Validation Accuracy: 0.8322, Loss: 0.2446\n",
      "Epoch   7 Batch  154/269 - Train Accuracy: 0.8550, Validation Accuracy: 0.8301, Loss: 0.2499\n",
      "Epoch   7 Batch  155/269 - Train Accuracy: 0.8447, Validation Accuracy: 0.8295, Loss: 0.2324\n",
      "Epoch   7 Batch  156/269 - Train Accuracy: 0.8084, Validation Accuracy: 0.8284, Loss: 0.2621\n",
      "Epoch   7 Batch  157/269 - Train Accuracy: 0.8388, Validation Accuracy: 0.8284, Loss: 0.2468\n",
      "Epoch   7 Batch  158/269 - Train Accuracy: 0.8397, Validation Accuracy: 0.8407, Loss: 0.2519\n",
      "Epoch   7 Batch  159/269 - Train Accuracy: 0.8193, Validation Accuracy: 0.8388, Loss: 0.2530\n",
      "Epoch   7 Batch  160/269 - Train Accuracy: 0.8404, Validation Accuracy: 0.8406, Loss: 0.2483\n",
      "Epoch   7 Batch  161/269 - Train Accuracy: 0.8367, Validation Accuracy: 0.8414, Loss: 0.2465\n",
      "Epoch   7 Batch  162/269 - Train Accuracy: 0.8489, Validation Accuracy: 0.8368, Loss: 0.2421\n",
      "Epoch   7 Batch  163/269 - Train Accuracy: 0.8432, Validation Accuracy: 0.8438, Loss: 0.2421\n",
      "Epoch   7 Batch  164/269 - Train Accuracy: 0.8414, Validation Accuracy: 0.8392, Loss: 0.2412\n",
      "Epoch   7 Batch  165/269 - Train Accuracy: 0.8405, Validation Accuracy: 0.8351, Loss: 0.2433\n",
      "Epoch   7 Batch  166/269 - Train Accuracy: 0.8469, Validation Accuracy: 0.8350, Loss: 0.2267\n",
      "Epoch   7 Batch  167/269 - Train Accuracy: 0.8533, Validation Accuracy: 0.8363, Loss: 0.2465\n",
      "Epoch   7 Batch  168/269 - Train Accuracy: 0.8429, Validation Accuracy: 0.8338, Loss: 0.2498\n",
      "Epoch   7 Batch  169/269 - Train Accuracy: 0.8448, Validation Accuracy: 0.8346, Loss: 0.2510\n",
      "Epoch   7 Batch  170/269 - Train Accuracy: 0.8408, Validation Accuracy: 0.8306, Loss: 0.2414\n",
      "Epoch   7 Batch  171/269 - Train Accuracy: 0.8619, Validation Accuracy: 0.8316, Loss: 0.2497\n",
      "Epoch   7 Batch  172/269 - Train Accuracy: 0.8445, Validation Accuracy: 0.8362, Loss: 0.2517\n",
      "Epoch   7 Batch  173/269 - Train Accuracy: 0.8457, Validation Accuracy: 0.8414, Loss: 0.2363\n",
      "Epoch   7 Batch  174/269 - Train Accuracy: 0.8308, Validation Accuracy: 0.8322, Loss: 0.2412\n",
      "Epoch   7 Batch  175/269 - Train Accuracy: 0.8414, Validation Accuracy: 0.8351, Loss: 0.2636\n",
      "Epoch   7 Batch  176/269 - Train Accuracy: 0.8441, Validation Accuracy: 0.8435, Loss: 0.2573\n",
      "Epoch   7 Batch  177/269 - Train Accuracy: 0.8501, Validation Accuracy: 0.8381, Loss: 0.2338\n",
      "Epoch   7 Batch  178/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8417, Loss: 0.2423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   7 Batch  179/269 - Train Accuracy: 0.8454, Validation Accuracy: 0.8341, Loss: 0.2378\n",
      "Epoch   7 Batch  180/269 - Train Accuracy: 0.8596, Validation Accuracy: 0.8440, Loss: 0.2384\n",
      "Epoch   7 Batch  181/269 - Train Accuracy: 0.8409, Validation Accuracy: 0.8390, Loss: 0.2443\n",
      "Epoch   7 Batch  182/269 - Train Accuracy: 0.8522, Validation Accuracy: 0.8398, Loss: 0.2470\n",
      "Epoch   7 Batch  183/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8410, Loss: 0.2085\n",
      "Epoch   7 Batch  184/269 - Train Accuracy: 0.8379, Validation Accuracy: 0.8458, Loss: 0.2462\n",
      "Epoch   7 Batch  185/269 - Train Accuracy: 0.8534, Validation Accuracy: 0.8370, Loss: 0.2365\n",
      "Epoch   7 Batch  186/269 - Train Accuracy: 0.8311, Validation Accuracy: 0.8445, Loss: 0.2412\n",
      "Epoch   7 Batch  187/269 - Train Accuracy: 0.8417, Validation Accuracy: 0.8442, Loss: 0.2329\n",
      "Epoch   7 Batch  188/269 - Train Accuracy: 0.8658, Validation Accuracy: 0.8448, Loss: 0.2276\n",
      "Epoch   7 Batch  189/269 - Train Accuracy: 0.8469, Validation Accuracy: 0.8434, Loss: 0.2284\n",
      "Epoch   7 Batch  190/269 - Train Accuracy: 0.8493, Validation Accuracy: 0.8378, Loss: 0.2232\n",
      "Epoch   7 Batch  191/269 - Train Accuracy: 0.8407, Validation Accuracy: 0.8384, Loss: 0.2303\n",
      "Epoch   7 Batch  192/269 - Train Accuracy: 0.8362, Validation Accuracy: 0.8345, Loss: 0.2447\n",
      "Epoch   7 Batch  193/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8342, Loss: 0.2319\n",
      "Epoch   7 Batch  194/269 - Train Accuracy: 0.8468, Validation Accuracy: 0.8400, Loss: 0.2373\n",
      "Epoch   7 Batch  195/269 - Train Accuracy: 0.8263, Validation Accuracy: 0.8384, Loss: 0.2373\n",
      "Epoch   7 Batch  196/269 - Train Accuracy: 0.8421, Validation Accuracy: 0.8377, Loss: 0.2354\n",
      "Epoch   7 Batch  197/269 - Train Accuracy: 0.8380, Validation Accuracy: 0.8419, Loss: 0.2519\n",
      "Epoch   7 Batch  198/269 - Train Accuracy: 0.8430, Validation Accuracy: 0.8405, Loss: 0.2576\n",
      "Epoch   7 Batch  199/269 - Train Accuracy: 0.8401, Validation Accuracy: 0.8481, Loss: 0.2510\n",
      "Epoch   7 Batch  200/269 - Train Accuracy: 0.8442, Validation Accuracy: 0.8468, Loss: 0.2410\n",
      "Epoch   7 Batch  201/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8509, Loss: 0.2364\n",
      "Epoch   7 Batch  202/269 - Train Accuracy: 0.8464, Validation Accuracy: 0.8516, Loss: 0.2435\n",
      "Epoch   7 Batch  203/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8501, Loss: 0.2548\n",
      "Epoch   7 Batch  204/269 - Train Accuracy: 0.8473, Validation Accuracy: 0.8494, Loss: 0.2431\n",
      "Epoch   7 Batch  205/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8462, Loss: 0.2347\n",
      "Epoch   7 Batch  206/269 - Train Accuracy: 0.8422, Validation Accuracy: 0.8417, Loss: 0.2532\n",
      "Epoch   7 Batch  207/269 - Train Accuracy: 0.8541, Validation Accuracy: 0.8453, Loss: 0.2288\n",
      "Epoch   7 Batch  208/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8494, Loss: 0.2474\n",
      "Epoch   7 Batch  209/269 - Train Accuracy: 0.8738, Validation Accuracy: 0.8532, Loss: 0.2310\n",
      "Epoch   7 Batch  210/269 - Train Accuracy: 0.8533, Validation Accuracy: 0.8489, Loss: 0.2286\n",
      "Epoch   7 Batch  211/269 - Train Accuracy: 0.8428, Validation Accuracy: 0.8407, Loss: 0.2488\n",
      "Epoch   7 Batch  212/269 - Train Accuracy: 0.8533, Validation Accuracy: 0.8521, Loss: 0.2408\n",
      "Epoch   7 Batch  213/269 - Train Accuracy: 0.8403, Validation Accuracy: 0.8581, Loss: 0.2320\n",
      "Epoch   7 Batch  214/269 - Train Accuracy: 0.8345, Validation Accuracy: 0.8485, Loss: 0.2413\n",
      "Epoch   7 Batch  215/269 - Train Accuracy: 0.8452, Validation Accuracy: 0.8343, Loss: 0.2241\n",
      "Epoch   7 Batch  216/269 - Train Accuracy: 0.8314, Validation Accuracy: 0.8506, Loss: 0.2647\n",
      "Epoch   7 Batch  217/269 - Train Accuracy: 0.8446, Validation Accuracy: 0.8488, Loss: 0.2428\n",
      "Epoch   7 Batch  218/269 - Train Accuracy: 0.8555, Validation Accuracy: 0.8530, Loss: 0.2511\n",
      "Epoch   7 Batch  219/269 - Train Accuracy: 0.8481, Validation Accuracy: 0.8345, Loss: 0.2438\n",
      "Epoch   7 Batch  220/269 - Train Accuracy: 0.8478, Validation Accuracy: 0.8382, Loss: 0.2249\n",
      "Epoch   7 Batch  221/269 - Train Accuracy: 0.8616, Validation Accuracy: 0.8432, Loss: 0.2350\n",
      "Epoch   7 Batch  222/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8414, Loss: 0.2259\n",
      "Epoch   7 Batch  223/269 - Train Accuracy: 0.8360, Validation Accuracy: 0.8365, Loss: 0.2257\n",
      "Epoch   7 Batch  224/269 - Train Accuracy: 0.8456, Validation Accuracy: 0.8414, Loss: 0.2493\n",
      "Epoch   7 Batch  225/269 - Train Accuracy: 0.8598, Validation Accuracy: 0.8442, Loss: 0.2249\n",
      "Epoch   7 Batch  226/269 - Train Accuracy: 0.8642, Validation Accuracy: 0.8380, Loss: 0.2337\n",
      "Epoch   7 Batch  227/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8517, Loss: 0.2164\n",
      "Epoch   7 Batch  228/269 - Train Accuracy: 0.8394, Validation Accuracy: 0.8522, Loss: 0.2350\n",
      "Epoch   7 Batch  229/269 - Train Accuracy: 0.8528, Validation Accuracy: 0.8517, Loss: 0.2326\n",
      "Epoch   7 Batch  230/269 - Train Accuracy: 0.8638, Validation Accuracy: 0.8516, Loss: 0.2318\n",
      "Epoch   7 Batch  231/269 - Train Accuracy: 0.8520, Validation Accuracy: 0.8516, Loss: 0.2464\n",
      "Epoch   7 Batch  232/269 - Train Accuracy: 0.8348, Validation Accuracy: 0.8511, Loss: 0.2393\n",
      "Epoch   7 Batch  233/269 - Train Accuracy: 0.8698, Validation Accuracy: 0.8526, Loss: 0.2354\n",
      "Epoch   7 Batch  234/269 - Train Accuracy: 0.8518, Validation Accuracy: 0.8555, Loss: 0.2305\n",
      "Epoch   7 Batch  235/269 - Train Accuracy: 0.8723, Validation Accuracy: 0.8502, Loss: 0.2225\n",
      "Epoch   7 Batch  236/269 - Train Accuracy: 0.8580, Validation Accuracy: 0.8533, Loss: 0.2240\n",
      "Epoch   7 Batch  237/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8586, Loss: 0.2306\n",
      "Epoch   7 Batch  238/269 - Train Accuracy: 0.8697, Validation Accuracy: 0.8606, Loss: 0.2273\n",
      "Epoch   7 Batch  239/269 - Train Accuracy: 0.8664, Validation Accuracy: 0.8585, Loss: 0.2250\n",
      "Epoch   7 Batch  240/269 - Train Accuracy: 0.8745, Validation Accuracy: 0.8503, Loss: 0.2074\n",
      "Epoch   7 Batch  241/269 - Train Accuracy: 0.8476, Validation Accuracy: 0.8478, Loss: 0.2416\n",
      "Epoch   7 Batch  242/269 - Train Accuracy: 0.8690, Validation Accuracy: 0.8501, Loss: 0.2109\n",
      "Epoch   7 Batch  243/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.8530, Loss: 0.2140\n",
      "Epoch   7 Batch  244/269 - Train Accuracy: 0.8468, Validation Accuracy: 0.8460, Loss: 0.2262\n",
      "Epoch   7 Batch  245/269 - Train Accuracy: 0.8400, Validation Accuracy: 0.8496, Loss: 0.2445\n",
      "Epoch   7 Batch  246/269 - Train Accuracy: 0.8341, Validation Accuracy: 0.8511, Loss: 0.2346\n",
      "Epoch   7 Batch  247/269 - Train Accuracy: 0.8489, Validation Accuracy: 0.8484, Loss: 0.2333\n",
      "Epoch   7 Batch  248/269 - Train Accuracy: 0.8650, Validation Accuracy: 0.8479, Loss: 0.2188\n",
      "Epoch   7 Batch  249/269 - Train Accuracy: 0.8777, Validation Accuracy: 0.8523, Loss: 0.2116\n",
      "Epoch   7 Batch  250/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8529, Loss: 0.2283\n",
      "Epoch   7 Batch  251/269 - Train Accuracy: 0.8857, Validation Accuracy: 0.8535, Loss: 0.2150\n",
      "Epoch   7 Batch  252/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8612, Loss: 0.2213\n",
      "Epoch   7 Batch  253/269 - Train Accuracy: 0.8391, Validation Accuracy: 0.8556, Loss: 0.2349\n",
      "Epoch   7 Batch  254/269 - Train Accuracy: 0.8584, Validation Accuracy: 0.8523, Loss: 0.2169\n",
      "Epoch   7 Batch  255/269 - Train Accuracy: 0.8611, Validation Accuracy: 0.8478, Loss: 0.2219\n",
      "Epoch   7 Batch  256/269 - Train Accuracy: 0.8537, Validation Accuracy: 0.8509, Loss: 0.2239\n",
      "Epoch   7 Batch  257/269 - Train Accuracy: 0.8491, Validation Accuracy: 0.8517, Loss: 0.2387\n",
      "Epoch   7 Batch  258/269 - Train Accuracy: 0.8605, Validation Accuracy: 0.8518, Loss: 0.2332\n",
      "Epoch   7 Batch  259/269 - Train Accuracy: 0.8517, Validation Accuracy: 0.8516, Loss: 0.2254\n",
      "Epoch   7 Batch  260/269 - Train Accuracy: 0.8504, Validation Accuracy: 0.8571, Loss: 0.2341\n",
      "Epoch   7 Batch  261/269 - Train Accuracy: 0.8598, Validation Accuracy: 0.8641, Loss: 0.2356\n",
      "Epoch   7 Batch  262/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8655, Loss: 0.2230\n",
      "Epoch   7 Batch  263/269 - Train Accuracy: 0.8604, Validation Accuracy: 0.8497, Loss: 0.2304\n",
      "Epoch   7 Batch  264/269 - Train Accuracy: 0.8321, Validation Accuracy: 0.8560, Loss: 0.2437\n",
      "Epoch   7 Batch  265/269 - Train Accuracy: 0.8722, Validation Accuracy: 0.8573, Loss: 0.2231\n",
      "Epoch   7 Batch  266/269 - Train Accuracy: 0.8598, Validation Accuracy: 0.8532, Loss: 0.2136\n",
      "Epoch   7 Batch  267/269 - Train Accuracy: 0.8660, Validation Accuracy: 0.8548, Loss: 0.2267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   8 Batch    1/269 - Train Accuracy: 0.8553, Validation Accuracy: 0.8619, Loss: 0.2242\n",
      "Epoch   8 Batch    2/269 - Train Accuracy: 0.8479, Validation Accuracy: 0.8612, Loss: 0.2301\n",
      "Epoch   8 Batch    3/269 - Train Accuracy: 0.8656, Validation Accuracy: 0.8578, Loss: 0.2258\n",
      "Epoch   8 Batch    4/269 - Train Accuracy: 0.8500, Validation Accuracy: 0.8608, Loss: 0.2317\n",
      "Epoch   8 Batch    5/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8648, Loss: 0.2268\n",
      "Epoch   8 Batch    6/269 - Train Accuracy: 0.8902, Validation Accuracy: 0.8674, Loss: 0.2057\n",
      "Epoch   8 Batch    7/269 - Train Accuracy: 0.8636, Validation Accuracy: 0.8660, Loss: 0.2142\n",
      "Epoch   8 Batch    8/269 - Train Accuracy: 0.8693, Validation Accuracy: 0.8544, Loss: 0.2284\n",
      "Epoch   8 Batch    9/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8613, Loss: 0.2324\n",
      "Epoch   8 Batch   10/269 - Train Accuracy: 0.8571, Validation Accuracy: 0.8604, Loss: 0.2187\n",
      "Epoch   8 Batch   11/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8635, Loss: 0.2318\n",
      "Epoch   8 Batch   12/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8660, Loss: 0.2312\n",
      "Epoch   8 Batch   13/269 - Train Accuracy: 0.8685, Validation Accuracy: 0.8643, Loss: 0.1959\n",
      "Epoch   8 Batch   14/269 - Train Accuracy: 0.8542, Validation Accuracy: 0.8666, Loss: 0.2159\n",
      "Epoch   8 Batch   15/269 - Train Accuracy: 0.8737, Validation Accuracy: 0.8672, Loss: 0.2068\n",
      "Epoch   8 Batch   16/269 - Train Accuracy: 0.8691, Validation Accuracy: 0.8564, Loss: 0.2206\n",
      "Epoch   8 Batch   17/269 - Train Accuracy: 0.8705, Validation Accuracy: 0.8550, Loss: 0.2069\n",
      "Epoch   8 Batch   18/269 - Train Accuracy: 0.8566, Validation Accuracy: 0.8621, Loss: 0.2155\n",
      "Epoch   8 Batch   19/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.8659, Loss: 0.1975\n",
      "Epoch   8 Batch   20/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8604, Loss: 0.2188\n",
      "Epoch   8 Batch   21/269 - Train Accuracy: 0.8632, Validation Accuracy: 0.8534, Loss: 0.2427\n",
      "Epoch   8 Batch   22/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8573, Loss: 0.2097\n",
      "Epoch   8 Batch   23/269 - Train Accuracy: 0.8659, Validation Accuracy: 0.8658, Loss: 0.2177\n",
      "Epoch   8 Batch   24/269 - Train Accuracy: 0.8594, Validation Accuracy: 0.8593, Loss: 0.2198\n",
      "Epoch   8 Batch   25/269 - Train Accuracy: 0.8521, Validation Accuracy: 0.8571, Loss: 0.2315\n",
      "Epoch   8 Batch   26/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8641, Loss: 0.2020\n",
      "Epoch   8 Batch   27/269 - Train Accuracy: 0.8588, Validation Accuracy: 0.8691, Loss: 0.2097\n",
      "Epoch   8 Batch   28/269 - Train Accuracy: 0.8474, Validation Accuracy: 0.8674, Loss: 0.2288\n",
      "Epoch   8 Batch   29/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8669, Loss: 0.2275\n",
      "Epoch   8 Batch   30/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8654, Loss: 0.2143\n",
      "Epoch   8 Batch   31/269 - Train Accuracy: 0.8799, Validation Accuracy: 0.8606, Loss: 0.2158\n",
      "Epoch   8 Batch   32/269 - Train Accuracy: 0.8673, Validation Accuracy: 0.8572, Loss: 0.2081\n",
      "Epoch   8 Batch   33/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8654, Loss: 0.1981\n",
      "Epoch   8 Batch   34/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8587, Loss: 0.2081\n",
      "Epoch   8 Batch   35/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8611, Loss: 0.2231\n",
      "Epoch   8 Batch   36/269 - Train Accuracy: 0.8630, Validation Accuracy: 0.8591, Loss: 0.2132\n",
      "Epoch   8 Batch   37/269 - Train Accuracy: 0.8745, Validation Accuracy: 0.8566, Loss: 0.2173\n",
      "Epoch   8 Batch   38/269 - Train Accuracy: 0.8573, Validation Accuracy: 0.8533, Loss: 0.2154\n",
      "Epoch   8 Batch   39/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8562, Loss: 0.2070\n",
      "Epoch   8 Batch   40/269 - Train Accuracy: 0.8599, Validation Accuracy: 0.8586, Loss: 0.2198\n",
      "Epoch   8 Batch   41/269 - Train Accuracy: 0.8512, Validation Accuracy: 0.8653, Loss: 0.2251\n",
      "Epoch   8 Batch   42/269 - Train Accuracy: 0.8857, Validation Accuracy: 0.8655, Loss: 0.2014\n",
      "Epoch   8 Batch   43/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8548, Loss: 0.2223\n",
      "Epoch   8 Batch   44/269 - Train Accuracy: 0.8540, Validation Accuracy: 0.8548, Loss: 0.2250\n",
      "Epoch   8 Batch   45/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8625, Loss: 0.2209\n",
      "Epoch   8 Batch   46/269 - Train Accuracy: 0.8662, Validation Accuracy: 0.8624, Loss: 0.2171\n",
      "Epoch   8 Batch   47/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8612, Loss: 0.1918\n",
      "Epoch   8 Batch   48/269 - Train Accuracy: 0.8701, Validation Accuracy: 0.8577, Loss: 0.2042\n",
      "Epoch   8 Batch   49/269 - Train Accuracy: 0.8652, Validation Accuracy: 0.8628, Loss: 0.2114\n",
      "Epoch   8 Batch   50/269 - Train Accuracy: 0.8497, Validation Accuracy: 0.8611, Loss: 0.2330\n",
      "Epoch   8 Batch   51/269 - Train Accuracy: 0.8815, Validation Accuracy: 0.8565, Loss: 0.2147\n",
      "Epoch   8 Batch   52/269 - Train Accuracy: 0.8703, Validation Accuracy: 0.8607, Loss: 0.2019\n",
      "Epoch   8 Batch   53/269 - Train Accuracy: 0.8685, Validation Accuracy: 0.8695, Loss: 0.2297\n",
      "Epoch   8 Batch   54/269 - Train Accuracy: 0.8747, Validation Accuracy: 0.8776, Loss: 0.2193\n",
      "Epoch   8 Batch   55/269 - Train Accuracy: 0.8902, Validation Accuracy: 0.8778, Loss: 0.2079\n",
      "Epoch   8 Batch   56/269 - Train Accuracy: 0.8617, Validation Accuracy: 0.8689, Loss: 0.2094\n",
      "Epoch   8 Batch   57/269 - Train Accuracy: 0.8753, Validation Accuracy: 0.8692, Loss: 0.2186\n",
      "Epoch   8 Batch   58/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8708, Loss: 0.2048\n",
      "Epoch   8 Batch   59/269 - Train Accuracy: 0.8916, Validation Accuracy: 0.8658, Loss: 0.1855\n",
      "Epoch   8 Batch   60/269 - Train Accuracy: 0.8805, Validation Accuracy: 0.8663, Loss: 0.2007\n",
      "Epoch   8 Batch   61/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8664, Loss: 0.1899\n",
      "Epoch   8 Batch   62/269 - Train Accuracy: 0.8853, Validation Accuracy: 0.8672, Loss: 0.2042\n",
      "Epoch   8 Batch   63/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8707, Loss: 0.2222\n",
      "Epoch   8 Batch   64/269 - Train Accuracy: 0.8733, Validation Accuracy: 0.8646, Loss: 0.1977\n",
      "Epoch   8 Batch   65/269 - Train Accuracy: 0.8553, Validation Accuracy: 0.8702, Loss: 0.2115\n",
      "Epoch   8 Batch   66/269 - Train Accuracy: 0.8642, Validation Accuracy: 0.8612, Loss: 0.1993\n",
      "Epoch   8 Batch   67/269 - Train Accuracy: 0.8677, Validation Accuracy: 0.8599, Loss: 0.2148\n",
      "Epoch   8 Batch   68/269 - Train Accuracy: 0.8439, Validation Accuracy: 0.8610, Loss: 0.2255\n",
      "Epoch   8 Batch   69/269 - Train Accuracy: 0.8524, Validation Accuracy: 0.8738, Loss: 0.2401\n",
      "Epoch   8 Batch   70/269 - Train Accuracy: 0.8724, Validation Accuracy: 0.8766, Loss: 0.2134\n",
      "Epoch   8 Batch   71/269 - Train Accuracy: 0.8714, Validation Accuracy: 0.8621, Loss: 0.2176\n",
      "Epoch   8 Batch   72/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8580, Loss: 0.2155\n",
      "Epoch   8 Batch   73/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8669, Loss: 0.2301\n",
      "Epoch   8 Batch   74/269 - Train Accuracy: 0.8707, Validation Accuracy: 0.8698, Loss: 0.2122\n",
      "Epoch   8 Batch   75/269 - Train Accuracy: 0.8776, Validation Accuracy: 0.8602, Loss: 0.2128\n",
      "Epoch   8 Batch   76/269 - Train Accuracy: 0.8474, Validation Accuracy: 0.8539, Loss: 0.2106\n",
      "Epoch   8 Batch   77/269 - Train Accuracy: 0.8635, Validation Accuracy: 0.8660, Loss: 0.2070\n",
      "Epoch   8 Batch   78/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8698, Loss: 0.2083\n",
      "Epoch   8 Batch   79/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8590, Loss: 0.2054\n",
      "Epoch   8 Batch   80/269 - Train Accuracy: 0.8693, Validation Accuracy: 0.8477, Loss: 0.2047\n",
      "Epoch   8 Batch   81/269 - Train Accuracy: 0.8743, Validation Accuracy: 0.8648, Loss: 0.2235\n",
      "Epoch   8 Batch   82/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8698, Loss: 0.1948\n",
      "Epoch   8 Batch   83/269 - Train Accuracy: 0.8572, Validation Accuracy: 0.8678, Loss: 0.2236\n",
      "Epoch   8 Batch   84/269 - Train Accuracy: 0.8900, Validation Accuracy: 0.8644, Loss: 0.2010\n",
      "Epoch   8 Batch   85/269 - Train Accuracy: 0.8826, Validation Accuracy: 0.8664, Loss: 0.2023\n",
      "Epoch   8 Batch   86/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8695, Loss: 0.2029\n",
      "Epoch   8 Batch   87/269 - Train Accuracy: 0.8694, Validation Accuracy: 0.8751, Loss: 0.2179\n",
      "Epoch   8 Batch   88/269 - Train Accuracy: 0.8611, Validation Accuracy: 0.8756, Loss: 0.2086\n",
      "Epoch   8 Batch   89/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.8795, Loss: 0.2092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   8 Batch   90/269 - Train Accuracy: 0.8643, Validation Accuracy: 0.8783, Loss: 0.2112\n",
      "Epoch   8 Batch   91/269 - Train Accuracy: 0.9001, Validation Accuracy: 0.8791, Loss: 0.1946\n",
      "Epoch   8 Batch   92/269 - Train Accuracy: 0.8839, Validation Accuracy: 0.8765, Loss: 0.2011\n",
      "Epoch   8 Batch   93/269 - Train Accuracy: 0.8888, Validation Accuracy: 0.8734, Loss: 0.1948\n",
      "Epoch   8 Batch   94/269 - Train Accuracy: 0.8670, Validation Accuracy: 0.8689, Loss: 0.2150\n",
      "Epoch   8 Batch   95/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.8685, Loss: 0.1987\n",
      "Epoch   8 Batch   96/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8631, Loss: 0.2010\n",
      "Epoch   8 Batch   97/269 - Train Accuracy: 0.8610, Validation Accuracy: 0.8596, Loss: 0.2058\n",
      "Epoch   8 Batch   98/269 - Train Accuracy: 0.8885, Validation Accuracy: 0.8742, Loss: 0.2026\n",
      "Epoch   8 Batch   99/269 - Train Accuracy: 0.8696, Validation Accuracy: 0.8801, Loss: 0.2009\n",
      "Epoch   8 Batch  100/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.8738, Loss: 0.1958\n",
      "Epoch   8 Batch  101/269 - Train Accuracy: 0.8609, Validation Accuracy: 0.8681, Loss: 0.2197\n",
      "Epoch   8 Batch  102/269 - Train Accuracy: 0.8861, Validation Accuracy: 0.8651, Loss: 0.2009\n",
      "Epoch   8 Batch  103/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.8720, Loss: 0.2091\n",
      "Epoch   8 Batch  104/269 - Train Accuracy: 0.8841, Validation Accuracy: 0.8760, Loss: 0.1997\n",
      "Epoch   8 Batch  105/269 - Train Accuracy: 0.8666, Validation Accuracy: 0.8705, Loss: 0.2098\n",
      "Epoch   8 Batch  106/269 - Train Accuracy: 0.8751, Validation Accuracy: 0.8704, Loss: 0.1927\n",
      "Epoch   8 Batch  107/269 - Train Accuracy: 0.8870, Validation Accuracy: 0.8860, Loss: 0.2077\n",
      "Epoch   8 Batch  108/269 - Train Accuracy: 0.8924, Validation Accuracy: 0.8782, Loss: 0.1975\n",
      "Epoch   8 Batch  109/269 - Train Accuracy: 0.8725, Validation Accuracy: 0.8761, Loss: 0.2076\n",
      "Epoch   8 Batch  110/269 - Train Accuracy: 0.8788, Validation Accuracy: 0.8673, Loss: 0.1951\n",
      "Epoch   8 Batch  111/269 - Train Accuracy: 0.8579, Validation Accuracy: 0.8745, Loss: 0.2180\n",
      "Epoch   8 Batch  112/269 - Train Accuracy: 0.8759, Validation Accuracy: 0.8730, Loss: 0.2006\n",
      "Epoch   8 Batch  113/269 - Train Accuracy: 0.8764, Validation Accuracy: 0.8771, Loss: 0.1967\n",
      "Epoch   8 Batch  114/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.8639, Loss: 0.1971\n",
      "Epoch   8 Batch  115/269 - Train Accuracy: 0.8631, Validation Accuracy: 0.8685, Loss: 0.2079\n",
      "Epoch   8 Batch  116/269 - Train Accuracy: 0.8864, Validation Accuracy: 0.8760, Loss: 0.2053\n",
      "Epoch   8 Batch  117/269 - Train Accuracy: 0.8862, Validation Accuracy: 0.8739, Loss: 0.1935\n",
      "Epoch   8 Batch  118/269 - Train Accuracy: 0.8989, Validation Accuracy: 0.8764, Loss: 0.1866\n",
      "Epoch   8 Batch  119/269 - Train Accuracy: 0.8665, Validation Accuracy: 0.8743, Loss: 0.2134\n",
      "Epoch   8 Batch  120/269 - Train Accuracy: 0.8947, Validation Accuracy: 0.8760, Loss: 0.2007\n",
      "Epoch   8 Batch  121/269 - Train Accuracy: 0.8855, Validation Accuracy: 0.8801, Loss: 0.1955\n",
      "Epoch   8 Batch  122/269 - Train Accuracy: 0.8887, Validation Accuracy: 0.8780, Loss: 0.1952\n",
      "Epoch   8 Batch  123/269 - Train Accuracy: 0.8841, Validation Accuracy: 0.8806, Loss: 0.2022\n",
      "Epoch   8 Batch  124/269 - Train Accuracy: 0.8932, Validation Accuracy: 0.8834, Loss: 0.1925\n",
      "Epoch   8 Batch  125/269 - Train Accuracy: 0.8888, Validation Accuracy: 0.8714, Loss: 0.1864\n",
      "Epoch   8 Batch  126/269 - Train Accuracy: 0.8602, Validation Accuracy: 0.8765, Loss: 0.2000\n",
      "Epoch   8 Batch  127/269 - Train Accuracy: 0.8704, Validation Accuracy: 0.8878, Loss: 0.2060\n",
      "Epoch   8 Batch  128/269 - Train Accuracy: 0.8874, Validation Accuracy: 0.8825, Loss: 0.2058\n",
      "Epoch   8 Batch  129/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8855, Loss: 0.1986\n",
      "Epoch   8 Batch  130/269 - Train Accuracy: 0.8861, Validation Accuracy: 0.8699, Loss: 0.2046\n",
      "Epoch   8 Batch  131/269 - Train Accuracy: 0.8649, Validation Accuracy: 0.8668, Loss: 0.1935\n",
      "Epoch   8 Batch  132/269 - Train Accuracy: 0.8768, Validation Accuracy: 0.8700, Loss: 0.2050\n",
      "Epoch   8 Batch  133/269 - Train Accuracy: 0.8846, Validation Accuracy: 0.8704, Loss: 0.1891\n",
      "Epoch   8 Batch  134/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8708, Loss: 0.1966\n",
      "Epoch   8 Batch  135/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8642, Loss: 0.2098\n",
      "Epoch   8 Batch  136/269 - Train Accuracy: 0.8622, Validation Accuracy: 0.8748, Loss: 0.2171\n",
      "Epoch   8 Batch  137/269 - Train Accuracy: 0.8850, Validation Accuracy: 0.8801, Loss: 0.2133\n",
      "Epoch   8 Batch  138/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8784, Loss: 0.1932\n",
      "Epoch   8 Batch  139/269 - Train Accuracy: 0.8921, Validation Accuracy: 0.8725, Loss: 0.1949\n",
      "Epoch   8 Batch  140/269 - Train Accuracy: 0.8686, Validation Accuracy: 0.8727, Loss: 0.2183\n",
      "Epoch   8 Batch  141/269 - Train Accuracy: 0.8822, Validation Accuracy: 0.8743, Loss: 0.2042\n",
      "Epoch   8 Batch  142/269 - Train Accuracy: 0.8702, Validation Accuracy: 0.8765, Loss: 0.1931\n",
      "Epoch   8 Batch  143/269 - Train Accuracy: 0.8853, Validation Accuracy: 0.8688, Loss: 0.1950\n",
      "Epoch   8 Batch  144/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.8718, Loss: 0.1853\n",
      "Epoch   8 Batch  145/269 - Train Accuracy: 0.8777, Validation Accuracy: 0.8691, Loss: 0.1885\n",
      "Epoch   8 Batch  146/269 - Train Accuracy: 0.8912, Validation Accuracy: 0.8672, Loss: 0.1897\n",
      "Epoch   8 Batch  147/269 - Train Accuracy: 0.8918, Validation Accuracy: 0.8760, Loss: 0.1970\n",
      "Epoch   8 Batch  148/269 - Train Accuracy: 0.8761, Validation Accuracy: 0.8721, Loss: 0.1962\n",
      "Epoch   8 Batch  149/269 - Train Accuracy: 0.8648, Validation Accuracy: 0.8748, Loss: 0.2064\n",
      "Epoch   8 Batch  150/269 - Train Accuracy: 0.8783, Validation Accuracy: 0.8720, Loss: 0.2012\n",
      "Epoch   8 Batch  151/269 - Train Accuracy: 0.8778, Validation Accuracy: 0.8761, Loss: 0.1913\n",
      "Epoch   8 Batch  152/269 - Train Accuracy: 0.8787, Validation Accuracy: 0.8724, Loss: 0.1970\n",
      "Epoch   8 Batch  153/269 - Train Accuracy: 0.8794, Validation Accuracy: 0.8646, Loss: 0.1991\n",
      "Epoch   8 Batch  154/269 - Train Accuracy: 0.8882, Validation Accuracy: 0.8691, Loss: 0.1954\n",
      "Epoch   8 Batch  155/269 - Train Accuracy: 0.8816, Validation Accuracy: 0.8817, Loss: 0.1860\n",
      "Epoch   8 Batch  156/269 - Train Accuracy: 0.8668, Validation Accuracy: 0.8860, Loss: 0.2048\n",
      "Epoch   8 Batch  157/269 - Train Accuracy: 0.8685, Validation Accuracy: 0.8836, Loss: 0.1894\n",
      "Epoch   8 Batch  158/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.8744, Loss: 0.1961\n",
      "Epoch   8 Batch  159/269 - Train Accuracy: 0.8592, Validation Accuracy: 0.8706, Loss: 0.2015\n",
      "Epoch   8 Batch  160/269 - Train Accuracy: 0.8731, Validation Accuracy: 0.8769, Loss: 0.1932\n",
      "Epoch   8 Batch  161/269 - Train Accuracy: 0.8856, Validation Accuracy: 0.8846, Loss: 0.1915\n",
      "Epoch   8 Batch  162/269 - Train Accuracy: 0.8858, Validation Accuracy: 0.8884, Loss: 0.1903\n",
      "Epoch   8 Batch  163/269 - Train Accuracy: 0.8808, Validation Accuracy: 0.8922, Loss: 0.1936\n",
      "Epoch   8 Batch  164/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8895, Loss: 0.1881\n",
      "Epoch   8 Batch  165/269 - Train Accuracy: 0.8971, Validation Accuracy: 0.8875, Loss: 0.1894\n",
      "Epoch   8 Batch  166/269 - Train Accuracy: 0.8982, Validation Accuracy: 0.8881, Loss: 0.1849\n",
      "Epoch   8 Batch  167/269 - Train Accuracy: 0.8877, Validation Accuracy: 0.8869, Loss: 0.1924\n",
      "Epoch   8 Batch  168/269 - Train Accuracy: 0.8897, Validation Accuracy: 0.8812, Loss: 0.2007\n",
      "Epoch   8 Batch  169/269 - Train Accuracy: 0.8792, Validation Accuracy: 0.8746, Loss: 0.1926\n",
      "Epoch   8 Batch  170/269 - Train Accuracy: 0.8818, Validation Accuracy: 0.8831, Loss: 0.1876\n",
      "Epoch   8 Batch  171/269 - Train Accuracy: 0.8960, Validation Accuracy: 0.8841, Loss: 0.1957\n",
      "Epoch   8 Batch  172/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8745, Loss: 0.2029\n",
      "Epoch   8 Batch  173/269 - Train Accuracy: 0.8980, Validation Accuracy: 0.8858, Loss: 0.1774\n",
      "Epoch   8 Batch  174/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.8775, Loss: 0.1870\n",
      "Epoch   8 Batch  175/269 - Train Accuracy: 0.8873, Validation Accuracy: 0.8809, Loss: 0.2089\n",
      "Epoch   8 Batch  176/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8841, Loss: 0.2027\n",
      "Epoch   8 Batch  177/269 - Train Accuracy: 0.8955, Validation Accuracy: 0.8808, Loss: 0.1835\n",
      "Epoch   8 Batch  178/269 - Train Accuracy: 0.9019, Validation Accuracy: 0.8823, Loss: 0.1838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   8 Batch  179/269 - Train Accuracy: 0.8835, Validation Accuracy: 0.8911, Loss: 0.1879\n",
      "Epoch   8 Batch  180/269 - Train Accuracy: 0.9020, Validation Accuracy: 0.8937, Loss: 0.1860\n",
      "Epoch   8 Batch  181/269 - Train Accuracy: 0.8861, Validation Accuracy: 0.8843, Loss: 0.1966\n",
      "Epoch   8 Batch  182/269 - Train Accuracy: 0.9000, Validation Accuracy: 0.8866, Loss: 0.1910\n",
      "Epoch   8 Batch  183/269 - Train Accuracy: 0.9058, Validation Accuracy: 0.8805, Loss: 0.1589\n",
      "Epoch   8 Batch  184/269 - Train Accuracy: 0.8839, Validation Accuracy: 0.8791, Loss: 0.1931\n",
      "Epoch   8 Batch  185/269 - Train Accuracy: 0.8857, Validation Accuracy: 0.8780, Loss: 0.1911\n",
      "Epoch   8 Batch  186/269 - Train Accuracy: 0.8760, Validation Accuracy: 0.8825, Loss: 0.1865\n",
      "Epoch   8 Batch  187/269 - Train Accuracy: 0.8780, Validation Accuracy: 0.8848, Loss: 0.1932\n",
      "Epoch   8 Batch  188/269 - Train Accuracy: 0.8956, Validation Accuracy: 0.8880, Loss: 0.1784\n",
      "Epoch   8 Batch  189/269 - Train Accuracy: 0.8832, Validation Accuracy: 0.8917, Loss: 0.1795\n",
      "Epoch   8 Batch  190/269 - Train Accuracy: 0.8895, Validation Accuracy: 0.8907, Loss: 0.1762\n",
      "Epoch   8 Batch  191/269 - Train Accuracy: 0.8820, Validation Accuracy: 0.8912, Loss: 0.1812\n",
      "Epoch   8 Batch  192/269 - Train Accuracy: 0.8711, Validation Accuracy: 0.8781, Loss: 0.1910\n",
      "Epoch   8 Batch  193/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.8876, Loss: 0.1813\n",
      "Epoch   8 Batch  194/269 - Train Accuracy: 0.8797, Validation Accuracy: 0.8869, Loss: 0.1885\n",
      "Epoch   8 Batch  195/269 - Train Accuracy: 0.8749, Validation Accuracy: 0.8813, Loss: 0.1888\n",
      "Epoch   8 Batch  196/269 - Train Accuracy: 0.8819, Validation Accuracy: 0.8854, Loss: 0.1810\n",
      "Epoch   8 Batch  197/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8880, Loss: 0.1979\n",
      "Epoch   8 Batch  198/269 - Train Accuracy: 0.8823, Validation Accuracy: 0.8828, Loss: 0.1961\n",
      "Epoch   8 Batch  199/269 - Train Accuracy: 0.8964, Validation Accuracy: 0.8870, Loss: 0.1964\n",
      "Epoch   8 Batch  200/269 - Train Accuracy: 0.8832, Validation Accuracy: 0.8878, Loss: 0.1904\n",
      "Epoch   8 Batch  201/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.8990, Loss: 0.1893\n",
      "Epoch   8 Batch  202/269 - Train Accuracy: 0.8781, Validation Accuracy: 0.8973, Loss: 0.1826\n",
      "Epoch   8 Batch  203/269 - Train Accuracy: 0.8936, Validation Accuracy: 0.8833, Loss: 0.2016\n",
      "Epoch   8 Batch  204/269 - Train Accuracy: 0.8895, Validation Accuracy: 0.8952, Loss: 0.2027\n",
      "Epoch   8 Batch  205/269 - Train Accuracy: 0.8863, Validation Accuracy: 0.8951, Loss: 0.1827\n",
      "Epoch   8 Batch  206/269 - Train Accuracy: 0.8720, Validation Accuracy: 0.8852, Loss: 0.1959\n",
      "Epoch   8 Batch  207/269 - Train Accuracy: 0.8892, Validation Accuracy: 0.8871, Loss: 0.1853\n",
      "Epoch   8 Batch  208/269 - Train Accuracy: 0.8945, Validation Accuracy: 0.8792, Loss: 0.2018\n",
      "Epoch   8 Batch  209/269 - Train Accuracy: 0.8861, Validation Accuracy: 0.8744, Loss: 0.1779\n",
      "Epoch   8 Batch  210/269 - Train Accuracy: 0.8987, Validation Accuracy: 0.8833, Loss: 0.1863\n",
      "Epoch   8 Batch  211/269 - Train Accuracy: 0.8897, Validation Accuracy: 0.8927, Loss: 0.1873\n",
      "Epoch   8 Batch  212/269 - Train Accuracy: 0.8904, Validation Accuracy: 0.8866, Loss: 0.1894\n",
      "Epoch   8 Batch  213/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8850, Loss: 0.1812\n",
      "Epoch   8 Batch  214/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8935, Loss: 0.1926\n",
      "Epoch   8 Batch  215/269 - Train Accuracy: 0.9026, Validation Accuracy: 0.8881, Loss: 0.1714\n",
      "Epoch   8 Batch  216/269 - Train Accuracy: 0.8685, Validation Accuracy: 0.8851, Loss: 0.2088\n",
      "Epoch   8 Batch  217/269 - Train Accuracy: 0.8901, Validation Accuracy: 0.8879, Loss: 0.1876\n",
      "Epoch   8 Batch  218/269 - Train Accuracy: 0.8866, Validation Accuracy: 0.8888, Loss: 0.1849\n",
      "Epoch   8 Batch  219/269 - Train Accuracy: 0.8878, Validation Accuracy: 0.8888, Loss: 0.1952\n",
      "Epoch   8 Batch  220/269 - Train Accuracy: 0.8976, Validation Accuracy: 0.8886, Loss: 0.1718\n",
      "Epoch   8 Batch  221/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.8871, Loss: 0.1812\n",
      "Epoch   8 Batch  222/269 - Train Accuracy: 0.9006, Validation Accuracy: 0.8870, Loss: 0.1758\n",
      "Epoch   8 Batch  223/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8942, Loss: 0.1784\n",
      "Epoch   8 Batch  224/269 - Train Accuracy: 0.8843, Validation Accuracy: 0.8899, Loss: 0.1976\n",
      "Epoch   8 Batch  225/269 - Train Accuracy: 0.8849, Validation Accuracy: 0.8881, Loss: 0.1771\n",
      "Epoch   8 Batch  226/269 - Train Accuracy: 0.9019, Validation Accuracy: 0.8894, Loss: 0.1852\n",
      "Epoch   8 Batch  227/269 - Train Accuracy: 0.9092, Validation Accuracy: 0.8914, Loss: 0.1738\n",
      "Epoch   8 Batch  228/269 - Train Accuracy: 0.8770, Validation Accuracy: 0.8935, Loss: 0.1849\n",
      "Epoch   8 Batch  229/269 - Train Accuracy: 0.8924, Validation Accuracy: 0.8889, Loss: 0.1781\n",
      "Epoch   8 Batch  230/269 - Train Accuracy: 0.8984, Validation Accuracy: 0.8871, Loss: 0.1671\n",
      "Epoch   8 Batch  231/269 - Train Accuracy: 0.8799, Validation Accuracy: 0.8925, Loss: 0.1927\n",
      "Epoch   8 Batch  232/269 - Train Accuracy: 0.8826, Validation Accuracy: 0.8921, Loss: 0.1742\n",
      "Epoch   8 Batch  233/269 - Train Accuracy: 0.8969, Validation Accuracy: 0.8918, Loss: 0.1877\n",
      "Epoch   8 Batch  234/269 - Train Accuracy: 0.8810, Validation Accuracy: 0.8927, Loss: 0.1800\n",
      "Epoch   8 Batch  235/269 - Train Accuracy: 0.9084, Validation Accuracy: 0.9015, Loss: 0.1689\n",
      "Epoch   8 Batch  236/269 - Train Accuracy: 0.8932, Validation Accuracy: 0.9043, Loss: 0.1768\n",
      "Epoch   8 Batch  237/269 - Train Accuracy: 0.8882, Validation Accuracy: 0.8929, Loss: 0.1788\n",
      "Epoch   8 Batch  238/269 - Train Accuracy: 0.8973, Validation Accuracy: 0.8956, Loss: 0.1828\n",
      "Epoch   8 Batch  239/269 - Train Accuracy: 0.8986, Validation Accuracy: 0.8936, Loss: 0.1810\n",
      "Epoch   8 Batch  240/269 - Train Accuracy: 0.9019, Validation Accuracy: 0.8857, Loss: 0.1629\n",
      "Epoch   8 Batch  241/269 - Train Accuracy: 0.8908, Validation Accuracy: 0.8995, Loss: 0.1975\n",
      "Epoch   8 Batch  242/269 - Train Accuracy: 0.9180, Validation Accuracy: 0.8975, Loss: 0.1721\n",
      "Epoch   8 Batch  243/269 - Train Accuracy: 0.9029, Validation Accuracy: 0.8916, Loss: 0.1612\n",
      "Epoch   8 Batch  244/269 - Train Accuracy: 0.8775, Validation Accuracy: 0.8789, Loss: 0.1812\n",
      "Epoch   8 Batch  245/269 - Train Accuracy: 0.8790, Validation Accuracy: 0.8841, Loss: 0.1880\n",
      "Epoch   8 Batch  246/269 - Train Accuracy: 0.8809, Validation Accuracy: 0.8828, Loss: 0.1842\n",
      "Epoch   8 Batch  247/269 - Train Accuracy: 0.8960, Validation Accuracy: 0.8971, Loss: 0.1848\n",
      "Epoch   8 Batch  248/269 - Train Accuracy: 0.8875, Validation Accuracy: 0.8881, Loss: 0.1725\n",
      "Epoch   8 Batch  249/269 - Train Accuracy: 0.9040, Validation Accuracy: 0.8922, Loss: 0.1601\n",
      "Epoch   8 Batch  250/269 - Train Accuracy: 0.9113, Validation Accuracy: 0.8957, Loss: 0.1775\n",
      "Epoch   8 Batch  251/269 - Train Accuracy: 0.9184, Validation Accuracy: 0.8983, Loss: 0.1724\n",
      "Epoch   8 Batch  252/269 - Train Accuracy: 0.8916, Validation Accuracy: 0.8888, Loss: 0.1681\n",
      "Epoch   8 Batch  253/269 - Train Accuracy: 0.8708, Validation Accuracy: 0.8881, Loss: 0.1886\n",
      "Epoch   8 Batch  254/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.8956, Loss: 0.1734\n",
      "Epoch   8 Batch  255/269 - Train Accuracy: 0.9060, Validation Accuracy: 0.8983, Loss: 0.1720\n",
      "Epoch   8 Batch  256/269 - Train Accuracy: 0.8885, Validation Accuracy: 0.8952, Loss: 0.1774\n",
      "Epoch   8 Batch  257/269 - Train Accuracy: 0.8757, Validation Accuracy: 0.8969, Loss: 0.1904\n",
      "Epoch   8 Batch  258/269 - Train Accuracy: 0.8885, Validation Accuracy: 0.8988, Loss: 0.1813\n",
      "Epoch   8 Batch  259/269 - Train Accuracy: 0.8868, Validation Accuracy: 0.8960, Loss: 0.1797\n",
      "Epoch   8 Batch  260/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.8998, Loss: 0.1857\n",
      "Epoch   8 Batch  261/269 - Train Accuracy: 0.8840, Validation Accuracy: 0.8899, Loss: 0.1779\n",
      "Epoch   8 Batch  262/269 - Train Accuracy: 0.9050, Validation Accuracy: 0.8971, Loss: 0.1775\n",
      "Epoch   8 Batch  263/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.8981, Loss: 0.1860\n",
      "Epoch   8 Batch  264/269 - Train Accuracy: 0.8593, Validation Accuracy: 0.8998, Loss: 0.1826\n",
      "Epoch   8 Batch  265/269 - Train Accuracy: 0.9033, Validation Accuracy: 0.9054, Loss: 0.1762\n",
      "Epoch   8 Batch  266/269 - Train Accuracy: 0.8944, Validation Accuracy: 0.8942, Loss: 0.1696\n",
      "Epoch   8 Batch  267/269 - Train Accuracy: 0.8909, Validation Accuracy: 0.8980, Loss: 0.1899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   9 Batch    1/269 - Train Accuracy: 0.8967, Validation Accuracy: 0.8965, Loss: 0.1803\n",
      "Epoch   9 Batch    2/269 - Train Accuracy: 0.8864, Validation Accuracy: 0.8917, Loss: 0.1776\n",
      "Epoch   9 Batch    3/269 - Train Accuracy: 0.8987, Validation Accuracy: 0.8866, Loss: 0.1781\n",
      "Epoch   9 Batch    4/269 - Train Accuracy: 0.8699, Validation Accuracy: 0.8806, Loss: 0.1810\n",
      "Epoch   9 Batch    5/269 - Train Accuracy: 0.8974, Validation Accuracy: 0.8873, Loss: 0.1887\n",
      "Epoch   9 Batch    6/269 - Train Accuracy: 0.9068, Validation Accuracy: 0.8865, Loss: 0.1692\n",
      "Epoch   9 Batch    7/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.8825, Loss: 0.1701\n",
      "Epoch   9 Batch    8/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.8908, Loss: 0.1809\n",
      "Epoch   9 Batch    9/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8789, Loss: 0.1806\n",
      "Epoch   9 Batch   10/269 - Train Accuracy: 0.8952, Validation Accuracy: 0.8875, Loss: 0.1727\n",
      "Epoch   9 Batch   11/269 - Train Accuracy: 0.8959, Validation Accuracy: 0.8852, Loss: 0.1775\n",
      "Epoch   9 Batch   12/269 - Train Accuracy: 0.8758, Validation Accuracy: 0.8865, Loss: 0.1892\n",
      "Epoch   9 Batch   13/269 - Train Accuracy: 0.8910, Validation Accuracy: 0.8846, Loss: 0.1548\n",
      "Epoch   9 Batch   14/269 - Train Accuracy: 0.8861, Validation Accuracy: 0.8949, Loss: 0.1754\n",
      "Epoch   9 Batch   15/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.8857, Loss: 0.1545\n",
      "Epoch   9 Batch   16/269 - Train Accuracy: 0.8891, Validation Accuracy: 0.8862, Loss: 0.1822\n",
      "Epoch   9 Batch   17/269 - Train Accuracy: 0.9128, Validation Accuracy: 0.9005, Loss: 0.1648\n",
      "Epoch   9 Batch   18/269 - Train Accuracy: 0.8833, Validation Accuracy: 0.9011, Loss: 0.1720\n",
      "Epoch   9 Batch   19/269 - Train Accuracy: 0.9154, Validation Accuracy: 0.9007, Loss: 0.1567\n",
      "Epoch   9 Batch   20/269 - Train Accuracy: 0.8962, Validation Accuracy: 0.8923, Loss: 0.1683\n",
      "Epoch   9 Batch   21/269 - Train Accuracy: 0.8802, Validation Accuracy: 0.8858, Loss: 0.1901\n",
      "Epoch   9 Batch   22/269 - Train Accuracy: 0.9116, Validation Accuracy: 0.8974, Loss: 0.1586\n",
      "Epoch   9 Batch   23/269 - Train Accuracy: 0.8928, Validation Accuracy: 0.9020, Loss: 0.1702\n",
      "Epoch   9 Batch   24/269 - Train Accuracy: 0.8984, Validation Accuracy: 0.9036, Loss: 0.1689\n",
      "Epoch   9 Batch   25/269 - Train Accuracy: 0.8795, Validation Accuracy: 0.8983, Loss: 0.1771\n",
      "Epoch   9 Batch   26/269 - Train Accuracy: 0.8993, Validation Accuracy: 0.9016, Loss: 0.1589\n",
      "Epoch   9 Batch   27/269 - Train Accuracy: 0.8887, Validation Accuracy: 0.9053, Loss: 0.1618\n",
      "Epoch   9 Batch   28/269 - Train Accuracy: 0.8679, Validation Accuracy: 0.9081, Loss: 0.1805\n",
      "Epoch   9 Batch   29/269 - Train Accuracy: 0.9067, Validation Accuracy: 0.9094, Loss: 0.1841\n",
      "Epoch   9 Batch   30/269 - Train Accuracy: 0.9089, Validation Accuracy: 0.9042, Loss: 0.1576\n",
      "Epoch   9 Batch   31/269 - Train Accuracy: 0.9055, Validation Accuracy: 0.9039, Loss: 0.1660\n",
      "Epoch   9 Batch   32/269 - Train Accuracy: 0.9047, Validation Accuracy: 0.9123, Loss: 0.1647\n",
      "Epoch   9 Batch   33/269 - Train Accuracy: 0.9007, Validation Accuracy: 0.9133, Loss: 0.1570\n",
      "Epoch   9 Batch   34/269 - Train Accuracy: 0.9028, Validation Accuracy: 0.9061, Loss: 0.1643\n",
      "Epoch   9 Batch   35/269 - Train Accuracy: 0.8951, Validation Accuracy: 0.8991, Loss: 0.1784\n",
      "Epoch   9 Batch   36/269 - Train Accuracy: 0.8872, Validation Accuracy: 0.9041, Loss: 0.1692\n",
      "Epoch   9 Batch   37/269 - Train Accuracy: 0.8968, Validation Accuracy: 0.9100, Loss: 0.1672\n",
      "Epoch   9 Batch   38/269 - Train Accuracy: 0.8949, Validation Accuracy: 0.9018, Loss: 0.1649\n",
      "Epoch   9 Batch   39/269 - Train Accuracy: 0.9009, Validation Accuracy: 0.8912, Loss: 0.1554\n",
      "Epoch   9 Batch   40/269 - Train Accuracy: 0.8804, Validation Accuracy: 0.8969, Loss: 0.1761\n",
      "Epoch   9 Batch   41/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.9094, Loss: 0.1776\n",
      "Epoch   9 Batch   42/269 - Train Accuracy: 0.9067, Validation Accuracy: 0.9059, Loss: 0.1536\n",
      "Epoch   9 Batch   43/269 - Train Accuracy: 0.8976, Validation Accuracy: 0.8996, Loss: 0.1753\n",
      "Epoch   9 Batch   44/269 - Train Accuracy: 0.8933, Validation Accuracy: 0.8936, Loss: 0.1708\n",
      "Epoch   9 Batch   45/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.8969, Loss: 0.1740\n",
      "Epoch   9 Batch   46/269 - Train Accuracy: 0.8851, Validation Accuracy: 0.9002, Loss: 0.1672\n",
      "Epoch   9 Batch   47/269 - Train Accuracy: 0.9069, Validation Accuracy: 0.9013, Loss: 0.1472\n",
      "Epoch   9 Batch   48/269 - Train Accuracy: 0.9004, Validation Accuracy: 0.8979, Loss: 0.1619\n",
      "Epoch   9 Batch   49/269 - Train Accuracy: 0.8934, Validation Accuracy: 0.8941, Loss: 0.1648\n",
      "Epoch   9 Batch   50/269 - Train Accuracy: 0.8762, Validation Accuracy: 0.8918, Loss: 0.1766\n",
      "Epoch   9 Batch   51/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.8857, Loss: 0.1696\n",
      "Epoch   9 Batch   52/269 - Train Accuracy: 0.8890, Validation Accuracy: 0.8968, Loss: 0.1511\n",
      "Epoch   9 Batch   53/269 - Train Accuracy: 0.8924, Validation Accuracy: 0.9004, Loss: 0.1753\n",
      "Epoch   9 Batch   54/269 - Train Accuracy: 0.8995, Validation Accuracy: 0.8991, Loss: 0.1675\n",
      "Epoch   9 Batch   55/269 - Train Accuracy: 0.9096, Validation Accuracy: 0.9001, Loss: 0.1651\n",
      "Epoch   9 Batch   56/269 - Train Accuracy: 0.8867, Validation Accuracy: 0.9034, Loss: 0.1673\n",
      "Epoch   9 Batch   57/269 - Train Accuracy: 0.9058, Validation Accuracy: 0.8994, Loss: 0.1671\n",
      "Epoch   9 Batch   58/269 - Train Accuracy: 0.8984, Validation Accuracy: 0.8966, Loss: 0.1582\n",
      "Epoch   9 Batch   59/269 - Train Accuracy: 0.9169, Validation Accuracy: 0.9015, Loss: 0.1457\n",
      "Epoch   9 Batch   60/269 - Train Accuracy: 0.9009, Validation Accuracy: 0.9039, Loss: 0.1556\n",
      "Epoch   9 Batch   61/269 - Train Accuracy: 0.8978, Validation Accuracy: 0.9020, Loss: 0.1507\n",
      "Epoch   9 Batch   62/269 - Train Accuracy: 0.9004, Validation Accuracy: 0.9044, Loss: 0.1612\n",
      "Epoch   9 Batch   63/269 - Train Accuracy: 0.9027, Validation Accuracy: 0.9042, Loss: 0.1695\n",
      "Epoch   9 Batch   64/269 - Train Accuracy: 0.9029, Validation Accuracy: 0.9018, Loss: 0.1551\n",
      "Epoch   9 Batch   65/269 - Train Accuracy: 0.8876, Validation Accuracy: 0.9069, Loss: 0.1614\n",
      "Epoch   9 Batch   66/269 - Train Accuracy: 0.8928, Validation Accuracy: 0.9017, Loss: 0.1585\n",
      "Epoch   9 Batch   67/269 - Train Accuracy: 0.8972, Validation Accuracy: 0.9030, Loss: 0.1690\n",
      "Epoch   9 Batch   68/269 - Train Accuracy: 0.8862, Validation Accuracy: 0.9057, Loss: 0.1810\n",
      "Epoch   9 Batch   69/269 - Train Accuracy: 0.8822, Validation Accuracy: 0.9059, Loss: 0.1919\n",
      "Epoch   9 Batch   70/269 - Train Accuracy: 0.9026, Validation Accuracy: 0.9013, Loss: 0.1689\n",
      "Epoch   9 Batch   71/269 - Train Accuracy: 0.8967, Validation Accuracy: 0.9035, Loss: 0.1774\n",
      "Epoch   9 Batch   72/269 - Train Accuracy: 0.8919, Validation Accuracy: 0.9006, Loss: 0.1642\n",
      "Epoch   9 Batch   73/269 - Train Accuracy: 0.8924, Validation Accuracy: 0.9008, Loss: 0.1857\n",
      "Epoch   9 Batch   74/269 - Train Accuracy: 0.9090, Validation Accuracy: 0.9052, Loss: 0.1629\n",
      "Epoch   9 Batch   75/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9028, Loss: 0.1670\n",
      "Epoch   9 Batch   76/269 - Train Accuracy: 0.8880, Validation Accuracy: 0.8993, Loss: 0.1569\n",
      "Epoch   9 Batch   77/269 - Train Accuracy: 0.8906, Validation Accuracy: 0.9074, Loss: 0.1616\n",
      "Epoch   9 Batch   78/269 - Train Accuracy: 0.9059, Validation Accuracy: 0.8990, Loss: 0.1659\n",
      "Epoch   9 Batch   79/269 - Train Accuracy: 0.8922, Validation Accuracy: 0.8992, Loss: 0.1577\n",
      "Epoch   9 Batch   80/269 - Train Accuracy: 0.9041, Validation Accuracy: 0.8972, Loss: 0.1546\n",
      "Epoch   9 Batch   81/269 - Train Accuracy: 0.8982, Validation Accuracy: 0.9030, Loss: 0.1731\n",
      "Epoch   9 Batch   82/269 - Train Accuracy: 0.9151, Validation Accuracy: 0.8958, Loss: 0.1436\n",
      "Epoch   9 Batch   83/269 - Train Accuracy: 0.8850, Validation Accuracy: 0.8919, Loss: 0.1829\n",
      "Epoch   9 Batch   84/269 - Train Accuracy: 0.9075, Validation Accuracy: 0.8912, Loss: 0.1554\n",
      "Epoch   9 Batch   85/269 - Train Accuracy: 0.8994, Validation Accuracy: 0.8934, Loss: 0.1633\n",
      "Epoch   9 Batch   86/269 - Train Accuracy: 0.8927, Validation Accuracy: 0.8970, Loss: 0.1576\n",
      "Epoch   9 Batch   87/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8921, Loss: 0.1698\n",
      "Epoch   9 Batch   88/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.8997, Loss: 0.1681\n",
      "Epoch   9 Batch   89/269 - Train Accuracy: 0.9109, Validation Accuracy: 0.9034, Loss: 0.1594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   9 Batch   90/269 - Train Accuracy: 0.9020, Validation Accuracy: 0.9029, Loss: 0.1630\n",
      "Epoch   9 Batch   91/269 - Train Accuracy: 0.9188, Validation Accuracy: 0.8973, Loss: 0.1507\n",
      "Epoch   9 Batch   92/269 - Train Accuracy: 0.9058, Validation Accuracy: 0.8968, Loss: 0.1564\n",
      "Epoch   9 Batch   93/269 - Train Accuracy: 0.9139, Validation Accuracy: 0.8923, Loss: 0.1526\n",
      "Epoch   9 Batch   94/269 - Train Accuracy: 0.8942, Validation Accuracy: 0.8903, Loss: 0.1672\n",
      "Epoch   9 Batch   95/269 - Train Accuracy: 0.9005, Validation Accuracy: 0.8975, Loss: 0.1536\n",
      "Epoch   9 Batch   96/269 - Train Accuracy: 0.8831, Validation Accuracy: 0.8993, Loss: 0.1601\n",
      "Epoch   9 Batch   97/269 - Train Accuracy: 0.8915, Validation Accuracy: 0.8964, Loss: 0.1594\n",
      "Epoch   9 Batch   98/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.8994, Loss: 0.1567\n",
      "Epoch   9 Batch   99/269 - Train Accuracy: 0.9015, Validation Accuracy: 0.9025, Loss: 0.1549\n",
      "Epoch   9 Batch  100/269 - Train Accuracy: 0.9135, Validation Accuracy: 0.9065, Loss: 0.1506\n",
      "Epoch   9 Batch  101/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.9016, Loss: 0.1755\n",
      "Epoch   9 Batch  102/269 - Train Accuracy: 0.9081, Validation Accuracy: 0.9007, Loss: 0.1525\n",
      "Epoch   9 Batch  103/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.9070, Loss: 0.1645\n",
      "Epoch   9 Batch  104/269 - Train Accuracy: 0.9024, Validation Accuracy: 0.9043, Loss: 0.1567\n",
      "Epoch   9 Batch  105/269 - Train Accuracy: 0.8887, Validation Accuracy: 0.9006, Loss: 0.1543\n",
      "Epoch   9 Batch  106/269 - Train Accuracy: 0.9035, Validation Accuracy: 0.9102, Loss: 0.1509\n",
      "Epoch   9 Batch  107/269 - Train Accuracy: 0.9140, Validation Accuracy: 0.8995, Loss: 0.1543\n",
      "Epoch   9 Batch  108/269 - Train Accuracy: 0.9093, Validation Accuracy: 0.9049, Loss: 0.1571\n",
      "Epoch   9 Batch  109/269 - Train Accuracy: 0.8837, Validation Accuracy: 0.8998, Loss: 0.1671\n",
      "Epoch   9 Batch  110/269 - Train Accuracy: 0.8996, Validation Accuracy: 0.8983, Loss: 0.1565\n",
      "Epoch   9 Batch  111/269 - Train Accuracy: 0.8953, Validation Accuracy: 0.8984, Loss: 0.1666\n",
      "Epoch   9 Batch  112/269 - Train Accuracy: 0.9038, Validation Accuracy: 0.9128, Loss: 0.1573\n",
      "Epoch   9 Batch  113/269 - Train Accuracy: 0.8946, Validation Accuracy: 0.9095, Loss: 0.1530\n",
      "Epoch   9 Batch  114/269 - Train Accuracy: 0.8988, Validation Accuracy: 0.8951, Loss: 0.1515\n",
      "Epoch   9 Batch  115/269 - Train Accuracy: 0.8813, Validation Accuracy: 0.9077, Loss: 0.1585\n",
      "Epoch   9 Batch  116/269 - Train Accuracy: 0.9072, Validation Accuracy: 0.9069, Loss: 0.1593\n",
      "Epoch   9 Batch  117/269 - Train Accuracy: 0.9057, Validation Accuracy: 0.8949, Loss: 0.1598\n",
      "Epoch   9 Batch  118/269 - Train Accuracy: 0.9039, Validation Accuracy: 0.8890, Loss: 0.1449\n",
      "Epoch   9 Batch  119/269 - Train Accuracy: 0.8854, Validation Accuracy: 0.8979, Loss: 0.1744\n",
      "Epoch   9 Batch  120/269 - Train Accuracy: 0.9081, Validation Accuracy: 0.9012, Loss: 0.1544\n",
      "Epoch   9 Batch  121/269 - Train Accuracy: 0.9079, Validation Accuracy: 0.8939, Loss: 0.1504\n",
      "Epoch   9 Batch  122/269 - Train Accuracy: 0.9005, Validation Accuracy: 0.8965, Loss: 0.1528\n",
      "Epoch   9 Batch  123/269 - Train Accuracy: 0.9017, Validation Accuracy: 0.8972, Loss: 0.1636\n",
      "Epoch   9 Batch  124/269 - Train Accuracy: 0.9079, Validation Accuracy: 0.9050, Loss: 0.1443\n",
      "Epoch   9 Batch  125/269 - Train Accuracy: 0.9116, Validation Accuracy: 0.9044, Loss: 0.1521\n",
      "Epoch   9 Batch  126/269 - Train Accuracy: 0.8806, Validation Accuracy: 0.8987, Loss: 0.1559\n",
      "Epoch   9 Batch  127/269 - Train Accuracy: 0.8964, Validation Accuracy: 0.9094, Loss: 0.1666\n",
      "Epoch   9 Batch  128/269 - Train Accuracy: 0.8991, Validation Accuracy: 0.9107, Loss: 0.1573\n",
      "Epoch   9 Batch  129/269 - Train Accuracy: 0.8909, Validation Accuracy: 0.9072, Loss: 0.1620\n",
      "Epoch   9 Batch  130/269 - Train Accuracy: 0.9024, Validation Accuracy: 0.9086, Loss: 0.1609\n",
      "Epoch   9 Batch  131/269 - Train Accuracy: 0.8870, Validation Accuracy: 0.9046, Loss: 0.1528\n",
      "Epoch   9 Batch  132/269 - Train Accuracy: 0.8976, Validation Accuracy: 0.9033, Loss: 0.1558\n",
      "Epoch   9 Batch  133/269 - Train Accuracy: 0.9123, Validation Accuracy: 0.9086, Loss: 0.1439\n",
      "Epoch   9 Batch  134/269 - Train Accuracy: 0.9004, Validation Accuracy: 0.9036, Loss: 0.1518\n",
      "Epoch   9 Batch  135/269 - Train Accuracy: 0.8988, Validation Accuracy: 0.9041, Loss: 0.1597\n",
      "Epoch   9 Batch  136/269 - Train Accuracy: 0.8883, Validation Accuracy: 0.9045, Loss: 0.1672\n",
      "Epoch   9 Batch  137/269 - Train Accuracy: 0.9036, Validation Accuracy: 0.9062, Loss: 0.1660\n",
      "Epoch   9 Batch  138/269 - Train Accuracy: 0.8919, Validation Accuracy: 0.8996, Loss: 0.1475\n",
      "Epoch   9 Batch  139/269 - Train Accuracy: 0.9017, Validation Accuracy: 0.9041, Loss: 0.1498\n",
      "Epoch   9 Batch  140/269 - Train Accuracy: 0.8968, Validation Accuracy: 0.9035, Loss: 0.1635\n",
      "Epoch   9 Batch  141/269 - Train Accuracy: 0.8986, Validation Accuracy: 0.9121, Loss: 0.1600\n",
      "Epoch   9 Batch  142/269 - Train Accuracy: 0.8897, Validation Accuracy: 0.8904, Loss: 0.1495\n",
      "Epoch   9 Batch  143/269 - Train Accuracy: 0.9133, Validation Accuracy: 0.9103, Loss: 0.1564\n",
      "Epoch   9 Batch  144/269 - Train Accuracy: 0.9125, Validation Accuracy: 0.9006, Loss: 0.1384\n",
      "Epoch   9 Batch  145/269 - Train Accuracy: 0.9042, Validation Accuracy: 0.9057, Loss: 0.1496\n",
      "Epoch   9 Batch  146/269 - Train Accuracy: 0.9001, Validation Accuracy: 0.9025, Loss: 0.1470\n",
      "Epoch   9 Batch  147/269 - Train Accuracy: 0.9125, Validation Accuracy: 0.9092, Loss: 0.1514\n",
      "Epoch   9 Batch  148/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.9019, Loss: 0.1559\n",
      "Epoch   9 Batch  149/269 - Train Accuracy: 0.8836, Validation Accuracy: 0.9047, Loss: 0.1675\n",
      "Epoch   9 Batch  150/269 - Train Accuracy: 0.8938, Validation Accuracy: 0.9074, Loss: 0.1518\n",
      "Epoch   9 Batch  151/269 - Train Accuracy: 0.9005, Validation Accuracy: 0.9118, Loss: 0.1526\n",
      "Epoch   9 Batch  152/269 - Train Accuracy: 0.9064, Validation Accuracy: 0.9157, Loss: 0.1558\n",
      "Epoch   9 Batch  153/269 - Train Accuracy: 0.8970, Validation Accuracy: 0.9070, Loss: 0.1545\n",
      "Epoch   9 Batch  154/269 - Train Accuracy: 0.9179, Validation Accuracy: 0.9097, Loss: 0.1491\n",
      "Epoch   9 Batch  155/269 - Train Accuracy: 0.8994, Validation Accuracy: 0.9049, Loss: 0.1440\n",
      "Epoch   9 Batch  156/269 - Train Accuracy: 0.8828, Validation Accuracy: 0.9046, Loss: 0.1576\n",
      "Epoch   9 Batch  157/269 - Train Accuracy: 0.8912, Validation Accuracy: 0.9032, Loss: 0.1452\n",
      "Epoch   9 Batch  158/269 - Train Accuracy: 0.9026, Validation Accuracy: 0.9064, Loss: 0.1440\n",
      "Epoch   9 Batch  159/269 - Train Accuracy: 0.8879, Validation Accuracy: 0.9058, Loss: 0.1492\n",
      "Epoch   9 Batch  160/269 - Train Accuracy: 0.8982, Validation Accuracy: 0.9070, Loss: 0.1494\n",
      "Epoch   9 Batch  161/269 - Train Accuracy: 0.9064, Validation Accuracy: 0.9109, Loss: 0.1546\n",
      "Epoch   9 Batch  162/269 - Train Accuracy: 0.9132, Validation Accuracy: 0.9109, Loss: 0.1462\n",
      "Epoch   9 Batch  163/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.9086, Loss: 0.1495\n",
      "Epoch   9 Batch  164/269 - Train Accuracy: 0.9155, Validation Accuracy: 0.9024, Loss: 0.1521\n",
      "Epoch   9 Batch  165/269 - Train Accuracy: 0.9043, Validation Accuracy: 0.9051, Loss: 0.1511\n",
      "Epoch   9 Batch  166/269 - Train Accuracy: 0.9139, Validation Accuracy: 0.9074, Loss: 0.1464\n",
      "Epoch   9 Batch  167/269 - Train Accuracy: 0.9042, Validation Accuracy: 0.9015, Loss: 0.1453\n",
      "Epoch   9 Batch  168/269 - Train Accuracy: 0.9061, Validation Accuracy: 0.9030, Loss: 0.1588\n",
      "Epoch   9 Batch  169/269 - Train Accuracy: 0.8969, Validation Accuracy: 0.9041, Loss: 0.1544\n",
      "Epoch   9 Batch  170/269 - Train Accuracy: 0.9018, Validation Accuracy: 0.9109, Loss: 0.1474\n",
      "Epoch   9 Batch  171/269 - Train Accuracy: 0.9101, Validation Accuracy: 0.9082, Loss: 0.1492\n",
      "Epoch   9 Batch  172/269 - Train Accuracy: 0.9012, Validation Accuracy: 0.9122, Loss: 0.1585\n",
      "Epoch   9 Batch  173/269 - Train Accuracy: 0.9183, Validation Accuracy: 0.9106, Loss: 0.1378\n",
      "Epoch   9 Batch  174/269 - Train Accuracy: 0.9201, Validation Accuracy: 0.9035, Loss: 0.1452\n",
      "Epoch   9 Batch  175/269 - Train Accuracy: 0.8977, Validation Accuracy: 0.9050, Loss: 0.1603\n",
      "Epoch   9 Batch  176/269 - Train Accuracy: 0.8903, Validation Accuracy: 0.8980, Loss: 0.1573\n",
      "Epoch   9 Batch  177/269 - Train Accuracy: 0.9034, Validation Accuracy: 0.9033, Loss: 0.1425\n",
      "Epoch   9 Batch  178/269 - Train Accuracy: 0.9056, Validation Accuracy: 0.8964, Loss: 0.1445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   9 Batch  179/269 - Train Accuracy: 0.8948, Validation Accuracy: 0.9025, Loss: 0.1478\n",
      "Epoch   9 Batch  180/269 - Train Accuracy: 0.9119, Validation Accuracy: 0.9069, Loss: 0.1413\n",
      "Epoch   9 Batch  181/269 - Train Accuracy: 0.9047, Validation Accuracy: 0.9049, Loss: 0.1551\n",
      "Epoch   9 Batch  182/269 - Train Accuracy: 0.9063, Validation Accuracy: 0.9065, Loss: 0.1476\n",
      "Epoch   9 Batch  183/269 - Train Accuracy: 0.9179, Validation Accuracy: 0.9041, Loss: 0.1286\n",
      "Epoch   9 Batch  184/269 - Train Accuracy: 0.9115, Validation Accuracy: 0.9062, Loss: 0.1487\n",
      "Epoch   9 Batch  185/269 - Train Accuracy: 0.9146, Validation Accuracy: 0.9049, Loss: 0.1528\n",
      "Epoch   9 Batch  186/269 - Train Accuracy: 0.9141, Validation Accuracy: 0.9111, Loss: 0.1432\n",
      "Epoch   9 Batch  187/269 - Train Accuracy: 0.9063, Validation Accuracy: 0.9064, Loss: 0.1506\n",
      "Epoch   9 Batch  188/269 - Train Accuracy: 0.9113, Validation Accuracy: 0.9090, Loss: 0.1338\n",
      "Epoch   9 Batch  189/269 - Train Accuracy: 0.8930, Validation Accuracy: 0.9084, Loss: 0.1455\n",
      "Epoch   9 Batch  190/269 - Train Accuracy: 0.9100, Validation Accuracy: 0.9072, Loss: 0.1424\n",
      "Epoch   9 Batch  191/269 - Train Accuracy: 0.8969, Validation Accuracy: 0.9057, Loss: 0.1425\n",
      "Epoch   9 Batch  192/269 - Train Accuracy: 0.9071, Validation Accuracy: 0.9063, Loss: 0.1473\n",
      "Epoch   9 Batch  193/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9053, Loss: 0.1411\n",
      "Epoch   9 Batch  194/269 - Train Accuracy: 0.9001, Validation Accuracy: 0.9044, Loss: 0.1486\n",
      "Epoch   9 Batch  195/269 - Train Accuracy: 0.8943, Validation Accuracy: 0.9082, Loss: 0.1481\n",
      "Epoch   9 Batch  196/269 - Train Accuracy: 0.9080, Validation Accuracy: 0.9142, Loss: 0.1407\n",
      "Epoch   9 Batch  197/269 - Train Accuracy: 0.8939, Validation Accuracy: 0.9142, Loss: 0.1510\n",
      "Epoch   9 Batch  198/269 - Train Accuracy: 0.8981, Validation Accuracy: 0.9106, Loss: 0.1592\n",
      "Epoch   9 Batch  199/269 - Train Accuracy: 0.9004, Validation Accuracy: 0.9070, Loss: 0.1536\n",
      "Epoch   9 Batch  200/269 - Train Accuracy: 0.8965, Validation Accuracy: 0.9079, Loss: 0.1498\n",
      "Epoch   9 Batch  201/269 - Train Accuracy: 0.8937, Validation Accuracy: 0.9089, Loss: 0.1485\n",
      "Epoch   9 Batch  202/269 - Train Accuracy: 0.9062, Validation Accuracy: 0.9094, Loss: 0.1390\n",
      "Epoch   9 Batch  203/269 - Train Accuracy: 0.9110, Validation Accuracy: 0.9090, Loss: 0.1555\n",
      "Epoch   9 Batch  204/269 - Train Accuracy: 0.8989, Validation Accuracy: 0.9106, Loss: 0.1527\n",
      "Epoch   9 Batch  205/269 - Train Accuracy: 0.8991, Validation Accuracy: 0.9112, Loss: 0.1395\n",
      "Epoch   9 Batch  206/269 - Train Accuracy: 0.8856, Validation Accuracy: 0.9085, Loss: 0.1553\n",
      "Epoch   9 Batch  207/269 - Train Accuracy: 0.9023, Validation Accuracy: 0.9058, Loss: 0.1385\n",
      "Epoch   9 Batch  208/269 - Train Accuracy: 0.9129, Validation Accuracy: 0.9109, Loss: 0.1559\n",
      "Epoch   9 Batch  209/269 - Train Accuracy: 0.9112, Validation Accuracy: 0.9003, Loss: 0.1417\n",
      "Epoch   9 Batch  210/269 - Train Accuracy: 0.9095, Validation Accuracy: 0.8978, Loss: 0.1350\n",
      "Epoch   9 Batch  211/269 - Train Accuracy: 0.9119, Validation Accuracy: 0.9088, Loss: 0.1556\n",
      "Epoch   9 Batch  212/269 - Train Accuracy: 0.9019, Validation Accuracy: 0.9102, Loss: 0.1460\n",
      "Epoch   9 Batch  213/269 - Train Accuracy: 0.8979, Validation Accuracy: 0.9119, Loss: 0.1449\n",
      "Epoch   9 Batch  214/269 - Train Accuracy: 0.8885, Validation Accuracy: 0.9068, Loss: 0.1496\n",
      "Epoch   9 Batch  215/269 - Train Accuracy: 0.9208, Validation Accuracy: 0.9060, Loss: 0.1395\n",
      "Epoch   9 Batch  216/269 - Train Accuracy: 0.8937, Validation Accuracy: 0.9136, Loss: 0.1647\n",
      "Epoch   9 Batch  217/269 - Train Accuracy: 0.9014, Validation Accuracy: 0.9141, Loss: 0.1520\n",
      "Epoch   9 Batch  218/269 - Train Accuracy: 0.9096, Validation Accuracy: 0.9079, Loss: 0.1418\n",
      "Epoch   9 Batch  219/269 - Train Accuracy: 0.9068, Validation Accuracy: 0.9044, Loss: 0.1498\n",
      "Epoch   9 Batch  220/269 - Train Accuracy: 0.9102, Validation Accuracy: 0.9106, Loss: 0.1370\n",
      "Epoch   9 Batch  221/269 - Train Accuracy: 0.9101, Validation Accuracy: 0.9036, Loss: 0.1472\n",
      "Epoch   9 Batch  222/269 - Train Accuracy: 0.9266, Validation Accuracy: 0.9021, Loss: 0.1366\n",
      "Epoch   9 Batch  223/269 - Train Accuracy: 0.8988, Validation Accuracy: 0.8980, Loss: 0.1364\n",
      "Epoch   9 Batch  224/269 - Train Accuracy: 0.8968, Validation Accuracy: 0.8999, Loss: 0.1530\n",
      "Epoch   9 Batch  225/269 - Train Accuracy: 0.8973, Validation Accuracy: 0.9023, Loss: 0.1351\n",
      "Epoch   9 Batch  226/269 - Train Accuracy: 0.9161, Validation Accuracy: 0.9047, Loss: 0.1471\n",
      "Epoch   9 Batch  227/269 - Train Accuracy: 0.9227, Validation Accuracy: 0.9093, Loss: 0.1359\n",
      "Epoch   9 Batch  228/269 - Train Accuracy: 0.8884, Validation Accuracy: 0.9110, Loss: 0.1426\n",
      "Epoch   9 Batch  229/269 - Train Accuracy: 0.9072, Validation Accuracy: 0.9025, Loss: 0.1402\n",
      "Epoch   9 Batch  230/269 - Train Accuracy: 0.9179, Validation Accuracy: 0.9104, Loss: 0.1389\n",
      "Epoch   9 Batch  231/269 - Train Accuracy: 0.8968, Validation Accuracy: 0.9102, Loss: 0.1467\n",
      "Epoch   9 Batch  232/269 - Train Accuracy: 0.8888, Validation Accuracy: 0.9111, Loss: 0.1417\n",
      "Epoch   9 Batch  233/269 - Train Accuracy: 0.9064, Validation Accuracy: 0.9153, Loss: 0.1407\n",
      "Epoch   9 Batch  234/269 - Train Accuracy: 0.9068, Validation Accuracy: 0.9163, Loss: 0.1426\n",
      "Epoch   9 Batch  235/269 - Train Accuracy: 0.9280, Validation Accuracy: 0.9186, Loss: 0.1287\n",
      "Epoch   9 Batch  236/269 - Train Accuracy: 0.9102, Validation Accuracy: 0.9142, Loss: 0.1280\n",
      "Epoch   9 Batch  237/269 - Train Accuracy: 0.8979, Validation Accuracy: 0.9169, Loss: 0.1409\n",
      "Epoch   9 Batch  238/269 - Train Accuracy: 0.9054, Validation Accuracy: 0.9080, Loss: 0.1377\n",
      "Epoch   9 Batch  239/269 - Train Accuracy: 0.9195, Validation Accuracy: 0.9063, Loss: 0.1392\n",
      "Epoch   9 Batch  240/269 - Train Accuracy: 0.9172, Validation Accuracy: 0.9009, Loss: 0.1317\n",
      "Epoch   9 Batch  241/269 - Train Accuracy: 0.8964, Validation Accuracy: 0.9039, Loss: 0.1554\n",
      "Epoch   9 Batch  242/269 - Train Accuracy: 0.9197, Validation Accuracy: 0.9091, Loss: 0.1360\n",
      "Epoch   9 Batch  243/269 - Train Accuracy: 0.9187, Validation Accuracy: 0.9097, Loss: 0.1269\n",
      "Epoch   9 Batch  244/269 - Train Accuracy: 0.9004, Validation Accuracy: 0.9104, Loss: 0.1353\n",
      "Epoch   9 Batch  245/269 - Train Accuracy: 0.9014, Validation Accuracy: 0.9129, Loss: 0.1458\n",
      "Epoch   9 Batch  246/269 - Train Accuracy: 0.9025, Validation Accuracy: 0.9155, Loss: 0.1454\n",
      "Epoch   9 Batch  247/269 - Train Accuracy: 0.9147, Validation Accuracy: 0.9104, Loss: 0.1362\n",
      "Epoch   9 Batch  248/269 - Train Accuracy: 0.9083, Validation Accuracy: 0.9099, Loss: 0.1325\n",
      "Epoch   9 Batch  249/269 - Train Accuracy: 0.9159, Validation Accuracy: 0.8994, Loss: 0.1269\n",
      "Epoch   9 Batch  250/269 - Train Accuracy: 0.9168, Validation Accuracy: 0.9058, Loss: 0.1364\n",
      "Epoch   9 Batch  251/269 - Train Accuracy: 0.9325, Validation Accuracy: 0.9110, Loss: 0.1317\n",
      "Epoch   9 Batch  252/269 - Train Accuracy: 0.9052, Validation Accuracy: 0.9043, Loss: 0.1328\n",
      "Epoch   9 Batch  253/269 - Train Accuracy: 0.8874, Validation Accuracy: 0.9031, Loss: 0.1427\n",
      "Epoch   9 Batch  254/269 - Train Accuracy: 0.8971, Validation Accuracy: 0.9033, Loss: 0.1303\n",
      "Epoch   9 Batch  255/269 - Train Accuracy: 0.9119, Validation Accuracy: 0.9047, Loss: 0.1383\n",
      "Epoch   9 Batch  256/269 - Train Accuracy: 0.8952, Validation Accuracy: 0.9044, Loss: 0.1420\n",
      "Epoch   9 Batch  257/269 - Train Accuracy: 0.8913, Validation Accuracy: 0.9081, Loss: 0.1546\n",
      "Epoch   9 Batch  258/269 - Train Accuracy: 0.9068, Validation Accuracy: 0.9050, Loss: 0.1453\n",
      "Epoch   9 Batch  259/269 - Train Accuracy: 0.9049, Validation Accuracy: 0.9095, Loss: 0.1450\n",
      "Epoch   9 Batch  260/269 - Train Accuracy: 0.9015, Validation Accuracy: 0.9153, Loss: 0.1439\n",
      "Epoch   9 Batch  261/269 - Train Accuracy: 0.9053, Validation Accuracy: 0.9168, Loss: 0.1428\n",
      "Epoch   9 Batch  262/269 - Train Accuracy: 0.9142, Validation Accuracy: 0.9083, Loss: 0.1402\n",
      "Epoch   9 Batch  263/269 - Train Accuracy: 0.9000, Validation Accuracy: 0.9092, Loss: 0.1385\n",
      "Epoch   9 Batch  264/269 - Train Accuracy: 0.8771, Validation Accuracy: 0.9163, Loss: 0.1508\n",
      "Epoch   9 Batch  265/269 - Train Accuracy: 0.9200, Validation Accuracy: 0.9174, Loss: 0.1407\n",
      "Epoch   9 Batch  266/269 - Train Accuracy: 0.9134, Validation Accuracy: 0.9166, Loss: 0.1333\n",
      "Epoch   9 Batch  267/269 - Train Accuracy: 0.9182, Validation Accuracy: 0.9182, Loss: 0.1499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "def get_accuracy(target, logits):\n",
    "    \"\"\"\n",
    "    Calculate accuracy\n",
    "    \"\"\"\n",
    "    max_seq = max(target.shape[1], logits.shape[1])\n",
    "    if max_seq - target.shape[1]:\n",
    "        target = np.pad(\n",
    "            target,\n",
    "            [(0,0),(0,max_seq - target.shape[1])],\n",
    "            'constant')\n",
    "    if max_seq - logits.shape[1]:\n",
    "        logits = np.pad(\n",
    "            logits,\n",
    "            [(0,0),(0,max_seq - logits.shape[1])],\n",
    "            'constant')\n",
    "\n",
    "    return np.mean(np.equal(target, logits))\n",
    "\n",
    "# Split data to training and validation sets\n",
    "train_source = source_int_text[batch_size:]\n",
    "train_target = target_int_text[batch_size:]\n",
    "valid_source = source_int_text[:batch_size]\n",
    "valid_target = target_int_text[:batch_size]\n",
    "(valid_sources_batch, valid_targets_batch, valid_sources_lengths, valid_targets_lengths ) = next(get_batches(valid_source,\n",
    "                                                                                                             valid_target,\n",
    "                                                                                                             batch_size,\n",
    "                                                                                                             source_vocab_to_int['<PAD>'],\n",
    "                                                                                                             target_vocab_to_int['<PAD>']))                                                                                                  \n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        for batch_i, (source_batch, target_batch, sources_lengths, targets_lengths) in enumerate(\n",
    "                get_batches(train_source, train_target, batch_size,\n",
    "                            source_vocab_to_int['<PAD>'],\n",
    "                            target_vocab_to_int['<PAD>'])):\n",
    "\n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: source_batch,\n",
    "                 targets: target_batch,\n",
    "                 lr: learning_rate,\n",
    "                 target_sequence_length: targets_lengths,\n",
    "                 source_sequence_length: sources_lengths,\n",
    "                 keep_prob: keep_probability})\n",
    "\n",
    "\n",
    "            if batch_i % display_step == 0 and batch_i > 0:\n",
    "\n",
    "\n",
    "                batch_train_logits = sess.run(\n",
    "                    inference_logits,\n",
    "                    {input_data: source_batch,\n",
    "                     source_sequence_length: sources_lengths,\n",
    "                     target_sequence_length: targets_lengths,\n",
    "                     keep_prob: 1.0})\n",
    "\n",
    "\n",
    "                batch_valid_logits = sess.run(\n",
    "                    inference_logits,\n",
    "                    {input_data: valid_sources_batch,\n",
    "                     source_sequence_length: valid_sources_lengths,\n",
    "                     target_sequence_length: valid_targets_lengths,\n",
    "                     keep_prob: 1.0})\n",
    "\n",
    "                train_acc = get_accuracy(target_batch, batch_train_logits)\n",
    "\n",
    "                valid_acc = get_accuracy(valid_targets_batch, batch_valid_logits)\n",
    "\n",
    "                print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.4f}, Validation Accuracy: {:>6.4f}, Loss: {:>6.4f}'\n",
    "                      .format(epoch_i, batch_i, len(source_int_text) // batch_size, train_acc, valid_acc, loss))\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_path)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Parameters\n",
    "Save the `batch_size` and `save_path` parameters for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Save parameters for checkpoint\n",
    "save_params(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "_, (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab, target_int_to_vocab) = helper.load_preprocess()\n",
    "load_path = helper.load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sentence_to_seq(sentence, vocab_to_int):\n",
    "    \"\"\"\n",
    "    Convert a sentence to a sequence of ids\n",
    "    :param sentence: String\n",
    "    :param vocab_to_int: Dictionary to go from the words to an id\n",
    "    :return: List of word ids\n",
    "    \"\"\"\n",
    "    word_ids = []\n",
    "    for word in sentence.lower().split():\n",
    "        if word in vocab_to_int:\n",
    "            word_ids.append(vocab_to_int[word])\n",
    "        else:\n",
    "            word_ids.append(vocab_to_int['<UNK>'])\n",
    "    return word_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate\n",
    "This will translate `translate_sentence` from English to French."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/dev\n",
      "Input\n",
      "  Word Ids:      [120, 172, 10, 36, 151, 179, 186]\n",
      "  English Words: ['he', 'saw', 'a', 'old', 'yellow', 'truck', '.']\n",
      "\n",
      "Prediction\n",
      "  Word Ids:      [182, 99, 65, 195, 282, 5, 243, 69, 1]\n",
      "  French Words: il a de visiter le camion automne . <EOS>\n"
     ]
    }
   ],
   "source": [
    "translate_sentence = 'he saw a old yellow truck .'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "translate_sentence = sentence_to_seq(translate_sentence, source_vocab_to_int)\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_path + '.meta')\n",
    "    loader.restore(sess, load_path)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('predictions:0')\n",
    "    target_sequence_length = loaded_graph.get_tensor_by_name('target_sequence_length:0')\n",
    "    source_sequence_length = loaded_graph.get_tensor_by_name('source_sequence_length:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "\n",
    "    translate_logits = sess.run(logits, {input_data: [translate_sentence]*batch_size,\n",
    "                                         target_sequence_length: [len(translate_sentence)*2]*batch_size,\n",
    "                                         source_sequence_length: [len(translate_sentence)]*batch_size,\n",
    "                                         keep_prob: 1.0})[0]\n",
    "\n",
    "print('Input')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_sentence]))\n",
    "print('  English Words: {}'.format([source_int_to_vocab[i] for i in translate_sentence]))\n",
    "\n",
    "print('\\nPrediction')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_logits]))\n",
    "print('  French Words: {}'.format(\" \".join([target_int_to_vocab[i] for i in translate_logits])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
